#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ComfyUIå·¥ä½œæµWebæœåŠ¡
ç§»åŠ¨ç«¯å‹å¥½çš„workflowé€‰æ‹©å’Œæ‰§è¡Œç•Œé¢
"""

import os
import json
import logging
import uuid
import requests
from datetime import datetime, timedelta
from flask import Flask, render_template, jsonify, request, send_from_directory
from flask_cors import CORS
from werkzeug.utils import secure_filename
from collections import defaultdict, Counter
import threading
import queue
import time
import random
import subprocess
from typing import Dict, List, Any

# å¯é€‰å›¾åƒå¤„ç†ä¾èµ–ï¼ˆç”¨äºè‡ªåŠ¨ç”Ÿæˆæ‰©å›¾æ©ç ï¼‰
try:
    from PIL import Image, ImageDraw, ImageFilter, ImageOps
except Exception:
    Image = None
    ImageDraw = None

# å¯é€‰ä¾èµ–
try:
    import psutil  # ç”¨äºCPU/å†…å­˜ç›‘æ§
except Exception:
    psutil = None

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

# å·¥ä½œæµä½¿ç”¨ç»Ÿè®¡å­˜å‚¨
BASE_DIR = os.path.dirname(__file__)
OUTPUT_DIR = os.path.join(BASE_DIR, 'output')
WORKFLOW_STATS_FILE = os.path.join(OUTPUT_DIR, 'workflow_stats.json')
LEGACY_WORKFLOW_STATS_FILE = os.path.join(BASE_DIR, 'workflow_stats.json')

def load_workflow_stats():
    """åŠ è½½å·¥ä½œæµä½¿ç”¨ç»Ÿè®¡ï¼ˆæ”¯æŒä»æ ¹ç›®å½•æ—§è·¯å¾„è¿ç§»åˆ°outputç›®å½•ï¼‰"""
    try:
        # ä¼˜å…ˆä»æ–°ä½ç½®è¯»å–
        if os.path.exists(WORKFLOW_STATS_FILE):
            with open(WORKFLOW_STATS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)

        # å…¼å®¹æ—§ä½ç½®ï¼šæ ¹ç›®å½•
        if os.path.exists(LEGACY_WORKFLOW_STATS_FILE):
            with open(LEGACY_WORKFLOW_STATS_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
            # å°è¯•è¿ç§»åˆ°æ–°ç›®å½•
            try:
                os.makedirs(OUTPUT_DIR, exist_ok=True)
                with open(WORKFLOW_STATS_FILE, 'w', encoding='utf-8') as nf:
                    json.dump(data, nf, ensure_ascii=False, indent=2)
                # è¿ç§»æˆåŠŸååˆ é™¤æ—§æ–‡ä»¶
                try:
                    os.remove(LEGACY_WORKFLOW_STATS_FILE)
                except Exception:
                    pass
            except Exception as migrate_error:
                logger.warning(f"è¿ç§»å·¥ä½œæµç»Ÿè®¡åˆ°è¾“å‡ºç›®å½•å¤±è´¥: {migrate_error}")
            return data
    except Exception as e:
        logger.warning(f"åŠ è½½å·¥ä½œæµç»Ÿè®¡å¤±è´¥: {e}")
    return {'usage_count': {}, 'recent_usage': {}}

def save_workflow_stats(stats):
    """ä¿å­˜å·¥ä½œæµä½¿ç”¨ç»Ÿè®¡ï¼ˆä¿å­˜åˆ°outputç›®å½•ï¼‰"""
    try:
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        with open(WORKFLOW_STATS_FILE, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"ä¿å­˜å·¥ä½œæµç»Ÿè®¡å¤±è´¥: {e}")

def record_workflow_usage(workflow_filename):
    """è®°å½•å·¥ä½œæµä½¿ç”¨"""
    stats = load_workflow_stats()
    
    # å¢åŠ ä½¿ç”¨è®¡æ•°
    if workflow_filename not in stats['usage_count']:
        stats['usage_count'][workflow_filename] = 0
    stats['usage_count'][workflow_filename] += 1
    
    # è®°å½•æœ€è¿‘ä½¿ç”¨æ—¶é—´
    stats['recent_usage'][workflow_filename] = datetime.now().isoformat()
    
    save_workflow_stats(stats)

# é…ç½®
WORKFLOW_DIR = os.path.join(os.path.dirname(__file__), 'workflow')
COMFYUI_HOST = os.getenv('COMFYUI_HOST', 'localhost')
COMFYUI_PORT = int(os.getenv('COMFYUI_PORT', 8188))
COMFYUI_API_URL = f"http://{COMFYUI_HOST}:{COMFYUI_PORT}"
HOST = os.getenv('HOST', '::')  # ä½¿ç”¨ :: æ¥æ”¯æŒIPv6
PORT = int(os.getenv('PORT', 5000))

# å…¨å±€å˜é‡å­˜å‚¨è¿è¡ŒçŠ¶æ€
running_tasks = {}
task_queue = queue.Queue()

# å‚æ•°åˆ†ç±»ä½“ç³»ï¼šå®šä¹‰ä¸åŒç±»å‹å‚æ•°çš„å½’å±åŒºåŸŸ
PARAMETER_CATEGORIES = {
    # æ ¸å¿ƒç”Ÿæˆå‚æ•°ï¼šå½±å“é‡‡æ ·è¿‡ç¨‹çš„åŸºç¡€å‚æ•°
    'CORE_GENERATION': {'steps', 'cfg', 'sampler', 'scheduler', 'denoise', 'seed', 'guidance'},
    
    # è¾“å‡ºæ§åˆ¶å‚æ•°ï¼šæ§åˆ¶ç”Ÿæˆç»“æœçš„æ ¼å¼ã€å°ºå¯¸ç­‰
    'OUTPUT_CONTROL': {'width', 'height', 'batch_size', 'output_format', 'size_control_mode'},
    
    # æ¡ä»¶æ§åˆ¶å‚æ•°ï¼šå½±å“ç”Ÿæˆå†…å®¹çš„æ¡ä»¶
    'CONDITIONING': {'strength', 'control_strength', 'style_strength', 'crop'},
    
    # æ¨¡å‹èµ„æºå‚æ•°ï¼šæ¨¡å‹ã€LoRAã€VAEç­‰èµ„æºé…ç½®
    'MODEL_RESOURCES': {'model_path', 'lora_name', 'vae_name', 'clip_name', 'style_model_name'},
    
    # é«˜çº§è®¾ç½®å‚æ•°ï¼šä¼˜åŒ–ã€è®¾å¤‡ç­‰é«˜çº§é…ç½®
    'ADVANCED_SETTINGS': {'attention', 'cpu_offload', 'data_type', 'device', 'cache_threshold', 'i_2_f_mode'},
    
    # æ–‡æœ¬ç›¸å…³å‚æ•°
    'TEXT_INPUTS': {'text', 'positive_prompt', 'negative_prompt'},
    
    # ä¸“ç”¨èŠ‚ç‚¹å‚æ•°ï¼šç”±ä¸“é—¨åŒºåŸŸæˆ–å¡ç‰‡å¤„ç†
    'SPECIALIZED': {'image', 'mask', 'filename_prefix', 'upload'}
}

# æ¨¡å‹åŠ è½½å™¨åˆ°ä¸‹æ¸¸èŠ‚ç‚¹çš„å‚æ•°æ˜ å°„é…ç½®
# æ ¼å¼ï¼š{æºåŠ è½½å™¨ç±»å‹: {ç›®æ ‡èŠ‚ç‚¹ç±»å‹: {æºå‚æ•°: (ç›®æ ‡å‚æ•°, ç›®æ ‡widget_index)}}}
LOADER_PARAM_MAPPING = {
    'StyleModelLoader': {
        'StyleModelApply': {
            'strength': ('strength', 0),
            'strength_type': ('strength_type', 1)
        }
    },
    'CLIPVisionLoader': {
        'CLIPVisionEncode': {
            'crop': ('crop', 0)
        }
    },
    'NunchakuFluxDiTLoader': {
        'ModelSamplingFlux': {
            'max_shift': ('max_shift', 0),
            'base_shift': ('base_shift', 1)
        }
    }
}

# WIDGET_INDEX_MAP - èŠ‚ç‚¹ç±»å‹åˆ°widgetç´¢å¼•çš„æ˜ å°„
WIDGET_INDEX_MAP = {
    "CLIPTextEncode": {"text": 0},
    "LoadImage": {"image": 0},
    "LoadImageOutput": {"image": 0},
    "SaveImage": {"filename_prefix": 0},
    "KSampler": {"seed": 0, "steps": 2, "cfg": 3, "sampler_name": 4, "scheduler": 5, "denoise": 6},
    "KSamplerAdvanced": {"add_noise":0, "noise_seed": 1, "steps": 3, "cfg": 4, "sampler_name": 5, "scheduler": 6},
    "KSamplerSelect": {"sampler_name": 0},
    "EmptyLatentImage": {"width": 0, "height": 1, "batch_size": 2},
    "EmptySD3LatentImage": {"width": 0, "height": 1, "batch_size": 2},
    "NunchakuFluxDiTLoader": {"model_path": 0, "cache_threshold": 1, "attention": 2, "cpu_offload": 3, "device_id": 4, "data_type": 5, "i_2_f_mode": 6},
    "CheckpointLoaderSimple": {"ckpt_name": 0},
    "VAELoader": {"vae_name": 0},
    "LoraLoader": {"lora_name": 0, "strength_model": 1},
    "NunchakuFluxLoraLoader": {"lora_name": 0, "lora_strength": 1},
    "NunchakuTextEncoderLoader": {"model_type": 0, "text_encoder1": 1, "text_encoder2": 2, "t5_min_length": 3, "use_4bit_t5": 4, "int4_model": 5},
    "ControlNetApplyAdvanced": {"strength": 0},
    "ControlNetLoader": {"control_net_name": 0},
    "DepthAnythingPreprocessor": {"resolution": 1},
    "BasicScheduler": {"scheduler": 0, "steps": 1, "denoise": 2},
    "FluxGuidance": {"guidance": 0},
    "ModelSamplingFlux": {"max_shift": 0, "base_shift": 1, "width": 2, "height": 3},
    "RandomNoise": {"noise_seed": 0},
    "PrimitiveNode": {"value": 0},
    "ImageStitch": {"direction": 0, "match_image_size": 1, "spacing_width": 2, "spacing_color": 3, "image1": -1, "image2": -1},
    "DualCLIPLoader": {"clip_name1": 0, "clip_name2": 1, "type": 2},
    "CLIPVisionLoader": {"clip_name": 0},
    "StyleModelLoader": {"style_model_name": 0},
    "CLIPVisionEncode": {"crop": 0},
    "StyleModelApply": {"strength": 0, "strength_type": 1},
    # Inpaint æ˜“ç”¨ç»„ä»¶ï¼šImageAndMaskResizeNode
    "ImageAndMaskResizeNode": {"width": 0, "height": 1, "resize_method": 2, "crop": 3, "mask_blur_radius": 4},
    # Outpaint æ‰©å›¾èŠ‚ç‚¹
    # å¤–è¡¥ç”»æ¿ï¼šComfyUI API æœŸå¾…çš„å…¥å‚åä¸º left/top/right/bottom/feathering
    "ImagePadForOutpaint": {"left": 0, "top": 1, "right": 2, "bottom": 3, "feathering": 4},
    # Inpaint æ¡ä»¶èŠ‚ç‚¹ï¼šæ˜¾å¼ä¼ é€’ noise_mask å¸ƒå°”å¼€å…³
    "InpaintModelConditioning": {"noise_mask": 0},
}

def apply_loader_param_mapping(workflow_data, parameters):
    """
    é€šç”¨çš„æ¨¡å‹åŠ è½½å™¨å‚æ•°æ˜ å°„å¤„ç†
    æ ¹æ®LOADER_PARAM_MAPPINGé…ç½®ï¼Œå°†åŠ è½½å™¨é¢æ¿çš„å‚æ•°åº”ç”¨åˆ°å¯¹åº”çš„ä¸‹æ¸¸èŠ‚ç‚¹
    """
    # æ„å»ºèŠ‚ç‚¹IDåˆ°èŠ‚ç‚¹ç±»å‹çš„æ˜ å°„
    node_type_map = {}
    for node in workflow_data.get('nodes', []):
        node_type_map[str(node.get('id', ''))] = node.get('type', '')
    
    # æ„å»ºèŠ‚ç‚¹è¿æ¥å…³ç³»æ˜ å°„ï¼š{ä¸‹æ¸¸èŠ‚ç‚¹ID: [ä¸Šæ¸¸èŠ‚ç‚¹IDåˆ—è¡¨]}
    connection_map = {}
    for link in workflow_data.get('links', []):
        if len(link) >= 6:
            _lid, src_id, _src_slot, dst_id, dst_slot, _t = link
            src_id, dst_id = str(src_id), str(dst_id)
            if dst_id not in connection_map:
                connection_map[dst_id] = []
            connection_map[dst_id].append(src_id)
    
    model_loaders = parameters.get('model_loaders', {})
    
    # éå†æ‰€æœ‰åŠ è½½å™¨æ˜ å°„é…ç½®
    for loader_type, target_mappings in LOADER_PARAM_MAPPING.items():
        for target_node_type, param_mappings in target_mappings.items():
            # æ‰¾åˆ°è¯¥ç±»å‹çš„ç›®æ ‡èŠ‚ç‚¹
            for node in workflow_data.get('nodes', []):
                node_id = str(node.get('id', ''))
                node_type = node.get('type', '')
                
                if node_type == target_node_type:
                    # æ‰¾åˆ°è¿æ¥åˆ°æ­¤èŠ‚ç‚¹çš„åŠ è½½å™¨èŠ‚ç‚¹
                    connected_loaders = []
                    for upstream_id in connection_map.get(node_id, []):
                        upstream_type = node_type_map.get(upstream_id, '')
                        if upstream_type == loader_type:
                            connected_loaders.append(upstream_id)
                    
                    # åº”ç”¨å‚æ•°æ˜ å°„
                    for loader_node_id in connected_loaders:
                        widgets_values = node.get('widgets_values', []) or []
                        
                        # ç¡®ä¿widgets_valuesæœ‰è¶³å¤Ÿçš„æ§½ä½
                        max_index = max((index for _, index in param_mappings.values()), default=-1)
                        if len(widgets_values) <= max_index:
                            widgets_values = list(widgets_values) + [None] * (max_index + 1 - len(widgets_values))
                        
                        # åº”ç”¨æ¯ä¸ªå‚æ•°æ˜ å°„
                        for source_param, (target_param, target_index) in param_mappings.items():
                            param_key = f'{source_param}_{loader_node_id}'
                            if param_key in model_loaders:
                                try:
                                    value = model_loaders[param_key]
                                    # ç±»å‹è½¬æ¢
                                    if source_param in ['max_shift', 'base_shift', 'strength']:
                                        value = float(value)
                                    else:
                                        value = str(value)
                                    widgets_values[target_index] = value
                                except (ValueError, TypeError):
                                    pass
                        
                        node['widgets_values'] = widgets_values

class WorkflowRunner:
    """å·¥ä½œæµæ‰§è¡Œå™¨"""
    
    def __init__(self):
        self.is_running = False
        
    def get_workflows(self):
        """è·å–æ‰€æœ‰å¯ç”¨çš„workflow"""
        workflows = []
        if not os.path.exists(WORKFLOW_DIR):
            logger.error(f"Workflowç›®å½•ä¸å­˜åœ¨: {WORKFLOW_DIR}")
            return workflows
            
        for filename in os.listdir(WORKFLOW_DIR):
            if filename.endswith('.json'):
                filepath = os.path.join(WORKFLOW_DIR, filename)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        workflow_data = json.load(f)
                    
                    # æå–workflowä¿¡æ¯
                    workflow_info = {
                        'filename': filename,
                        'name': filename.replace('.json', '').replace('-', ' ').title(),
                        'id': workflow_data.get('id', ''),
                        'revision': workflow_data.get('revision', 0),
                        'node_count': len(workflow_data.get('nodes', [])),
                        'description': self.get_workflow_description(filename),
                        'file_size': f"{os.path.getsize(filepath) / 1024:.1f} KB"
                    }
                    workflows.append(workflow_info)
                except Exception as e:
                    logger.error(f"è¯»å–workflowæ–‡ä»¶é”™è¯¯ {filename}: {str(e)}")
                    
        return sorted(workflows, key=lambda x: x['name'])
    
    def _extract_description(self, workflow_data):
        """ä»workflowæ•°æ®ä¸­æå–æè¿°ä¿¡æ¯"""
        return "ComfyUI å·¥ä½œæµ"  # åŸºç¡€æè¿°ï¼Œä¼šè¢« get_workflow_description æ–¹æ³•è¦†ç›–
    
    def get_workflow_description(self, filename):
        """æ ¹æ®æ–‡ä»¶åç”Ÿæˆæ›´æœ‰æ„ä¹‰çš„æè¿°"""
        filename_lower = filename.lower()

        # ç²¾ç¡®æ–‡ä»¶ååˆ°æè¿°çš„æ˜ å°„ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰ï¼Œå‚è€ƒ Nunchaku å®˜æ–¹å·¥ä½œæµç›®å½•
        # https://nunchaku.tech/docs/ComfyUI-nunchaku/workflows/toc.html
        precise_map = {
            # Text-to-Image
            'nunchaku-flux.1-dev.json': 'FLUX.1 Dev æ–‡ç”Ÿå›¾ï¼šæ ‡å‡†é«˜è´¨é‡ç”Ÿæˆï¼Œé€‚åˆå¤§å¤šæ•°é€šç”¨åœºæ™¯ï¼Œæä¾›å®Œæ•´å‚æ•°å¯è°ƒã€‚',
            'nunchaku-flux.1-schnell.json': 'FLUX.1 Schnell æé€Ÿæ–‡ç”Ÿå›¾ï¼šé€Ÿåº¦ä¼˜å…ˆï¼Œå‡ ç§’å†…å‡ºå›¾ï¼Œé€‚åˆå¿«é€Ÿé¢„è§ˆä¸åˆ›æ„è‰å›¾ã€‚',
            'nunchaku-flux.1-dev-qencoder.json': 'FLUX.1 Dev + é‡åŒ–ç¼–ç å™¨ï¼šæ˜¾è‘—é™ä½æ˜¾å­˜å ç”¨ï¼Œåœ¨ä¸­ä½æ˜¾å­˜ç¯å¢ƒä¸‹ä¹Ÿå¯ç¨³å®šå‡ºå›¾ã€‚',

            # Kontext
            'nunchaku-flux.1-dev-kontext.json': 'FLUX.1 Kontext ä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼šå¯¹é•¿æç¤ºè¯ä¸ä¸Šä¸‹æ–‡æ›´æ•æ„Ÿï¼Œé€‚åˆç»“æ„ä¸å™äº‹æ€§æ›´å¼ºçš„å›¾åƒã€‚',
            'nunchaku-flux.1-kontext-dev-turbo_lora.json': 'FLUX.1 Kontext Turbo + LoRAï¼šåœ¨ä¿ç•™ä¸Šä¸‹æ–‡ç†è§£çš„åŒæ—¶æå‡é€Ÿåº¦ï¼Œå¹¶æ”¯æŒåº”ç”¨é£æ ¼ LoRAã€‚',

            # ControlNets
            'nunchaku-flux.1-dev-controlnet-union-pro2.json': 'FLUX.1 + ControlNet Union Pro 2ï¼šå¤šçº¿ç´¢å¯æ§ï¼ˆè¾¹ç¼˜/æ·±åº¦/æ³•çº¿ç­‰ï¼‰è”åˆé©±åŠ¨ï¼Œç²¾ç¡®å¤ç°æ„å›¾ä¸ç»†èŠ‚ã€‚',
            'nunchaku-flux.1-dev-controlnet-upscaler.json': 'FLUX.1 + å¯æ§æ”¾å¤§ï¼šåœ¨æ”¾å¤§ç»†èŠ‚çš„åŒæ—¶ç»´æŒå¯æ§æ€§ï¼Œé€‚åˆé«˜æ¸…ä¿®é¥°ä¸å°åˆ·è¾“å‡ºå‰å¤„ç†ã€‚',

            # PuLID
            'nunchaku-flux.1-dev-pulid.json': 'FLUX.1 + PuLID äººåƒä¸€è‡´æ€§ï¼šåœ¨å¤šå¼ å›¾ä¸­ä¿æŒèº«ä»½ä¸€è‡´ä¸äº”å®˜ç¨³å®šï¼Œé€‚åˆè§’è‰²/è¯ä»¶/å“ç‰Œäººåƒã€‚',

            # Redux
            'nunchaku-flux.1-redux-dev.json': 'FLUX.1 Redux å›¾åƒå†åˆ›ä½œï¼šå¯¹å·²æœ‰å›¾åƒè¿›è¡Œé£æ ¼è¿ç§»/å†æ¸²æŸ“/ç»“æ„ä¿ç•™çš„äºŒæ¬¡åˆ›ä½œã€‚',

            # Canny
            'nunchaku-flux.1-canny.json': 'FLUX.1 Canny è¾¹ç¼˜æ§åˆ¶ï¼šç”¨çº¿ç¨¿/è¾¹ç¼˜å›¾çº¦æŸæ„å›¾ï¼Œç²¾å‡†å¤ç°è½®å»“ä¸é€è§†ã€‚',
            'nunchaku-flux.1-canny-lora.json': 'FLUX.1 Canny + LoRAï¼šåœ¨è¾¹ç¼˜å¯æ§çš„åŸºç¡€ä¸Šå åŠ é£æ ¼ LoRAï¼Œå¿«é€Ÿå¾—åˆ°ç‰¹å®šé£æ ¼æˆå“ã€‚',

            # Depth
            'nunchaku-flux.1-depth.json': 'FLUX.1 Depth æ·±åº¦æ§åˆ¶ï¼šä»¥æ·±åº¦å›¾çº¦æŸä¸‰ç»´ç»“æ„ä¸æ™¯æ·±å…³ç³»ï¼Œæ„å›¾æ›´ç¨³å®šã€‚',
            'nunchaku-flux.1-depth-lora.json': 'FLUX.1 Depth + LoRAï¼šç»“åˆæ·±åº¦æ§åˆ¶ä¸é£æ ¼ LoRAï¼Œå…¼é¡¾ç»“æ„ç¨³å®šä¸é£æ ¼ç»Ÿä¸€ã€‚',

            # Fill / Inpaint
            'nunchaku-flux.1-fill.json': 'FLUX.1 Fill å›¾åƒè¡¥å…¨/ä¿®å¤ï¼šå¯¹é®ç½©åŒºåŸŸè¿›è¡Œæ™ºèƒ½è¡¥å…¨ï¼Œé€‚åˆæ“¦é™¤/æ‰©å›¾/å±€éƒ¨æ”¹å†™ã€‚',
            'nunchaku-flux.1-fill-removalv2.json': 'FLUX.1 Fill + Removal V2ï¼šåœ¨è¡¥å…¨åŸºç¡€ä¸Šå¼ºåŒ–ç§»é™¤èƒ½åŠ›ï¼Œå»ç‰©/å»æ°´å°æ›´å¹²å‡€è‡ªç„¶ã€‚',
        }

        if filename_lower in precise_map:
            return precise_map[filename_lower]
        
        # åŸºäºæ–‡ä»¶åçš„æè¿°æ˜ å°„
        if 'schnell' in filename_lower:
            return "ğŸš€ FLUX.1 Schnell - è¶…å¿«é€Ÿå›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œé€‚åˆå¿«é€ŸåŸå‹è®¾è®¡å’Œé¢„è§ˆ"
        elif 'redux' in filename_lower:
            return "ğŸ¨ FLUX.1 Redux - å›¾åƒå˜æ¢å’Œé£æ ¼è¿ç§»ï¼Œå°†ç°æœ‰å›¾åƒè½¬æ¢ä¸ºæ–°é£æ ¼"
        elif 'kontext' in filename_lower and 'turbo' in filename_lower:
            return "âš¡ FLUX.1 Kontext Turbo LoRA - åŠ é€Ÿç‰ˆä¸Šä¸‹æ–‡æ„ŸçŸ¥ç”Ÿæˆï¼Œæ”¯æŒLoRAå¾®è°ƒ"
        elif 'kontext' in filename_lower:
            return "ğŸ§  FLUX.1 Kontext - ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ™ºèƒ½å›¾åƒç”Ÿæˆ"
        elif 'fill' in filename_lower and 'removal' in filename_lower:
            return "ğŸ”§ FLUX.1 Fill + æ™ºèƒ½ç§»é™¤ - å›¾åƒä¿®å¤å’Œä¸æƒ³è¦å…ƒç´ çš„æ™ºèƒ½ç§»é™¤"
        elif 'fill' in filename_lower:
            return "ğŸ–Œï¸ FLUX.1 Fill - æ™ºèƒ½å›¾åƒä¿®å¤å’Œè¡¥å…¨ç¼ºå¤±åŒºåŸŸ"
        elif 'dev' in filename_lower and 'qencoder' in filename_lower:
            return "ğŸ’» FLUX.1 Dev + é‡åŒ–ç¼–ç å™¨ - å¼€å‘ç‰ˆæœ¬ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨"
        elif 'dev' in filename_lower and 'pulid' in filename_lower:
            return "ğŸ‘¤ FLUX.1 Dev + PuLID - é¢éƒ¨èº«ä»½ä¿æŒçš„å›¾åƒç”Ÿæˆ"
        elif 'dev' in filename_lower and 'controlnet' in filename_lower and 'upscaler' in filename_lower:
            return "ğŸ“ˆ FLUX.1 Dev + ControlNet æ”¾å¤§å™¨ - å¯æ§çš„é«˜è´¨é‡å›¾åƒæ”¾å¤§"
        elif 'dev' in filename_lower and 'controlnet' in filename_lower and 'union' in filename_lower:
            return "ğŸ¯ FLUX.1 Dev + ControlNet Union Pro - å¤šç§æ§åˆ¶æ¡ä»¶çš„ç²¾ç¡®å›¾åƒç”Ÿæˆ"
        elif 'dev' in filename_lower:
            return "ğŸ› ï¸ FLUX.1 Dev - å¼€å‘è€…ç‰ˆæœ¬ï¼Œé«˜è´¨é‡å›¾åƒç”Ÿæˆçš„å®Œæ•´åŠŸèƒ½"
        elif 'depth' in filename_lower and 'lora' in filename_lower:
            return "ğŸ”ï¸ FLUX.1 æ·±åº¦ + LoRA - åŸºäºæ·±åº¦å›¾çš„3Dæ„ŸçŸ¥å›¾åƒç”Ÿæˆ"
        elif 'depth' in filename_lower:
            return "ğŸ“ FLUX.1 æ·±åº¦æ§åˆ¶ - ä½¿ç”¨æ·±åº¦å›¾æ§åˆ¶å›¾åƒçš„3Dç»“æ„"
        elif 'canny' in filename_lower and 'lora' in filename_lower:
            return "âœï¸ FLUX.1 è¾¹ç¼˜ + LoRA - åŸºäºè¾¹ç¼˜æ£€æµ‹çš„ç²¾ç¡®çº¿æ¡æ§åˆ¶ç”Ÿæˆ"
        elif 'canny' in filename_lower:
            return "ğŸ–ï¸ FLUX.1 è¾¹ç¼˜æ§åˆ¶ - ä½¿ç”¨Cannyè¾¹ç¼˜æ£€æµ‹æ§åˆ¶å›¾åƒè½®å»“"
        else:
            return "ğŸ¤– FLUX.1 å·¥ä½œæµ - AIå›¾åƒç”Ÿæˆå·¥ä½œæµ"
    
    def check_comfyui_status(self):
        """æ£€æŸ¥ComfyUIæœåŠ¡çŠ¶æ€"""
        try:
            response = requests.get(f"{COMFYUI_API_URL}/system_stats", timeout=5)
            return response.status_code == 200
        except Exception as e:
            logger.error(f"æ£€æŸ¥ComfyUIçŠ¶æ€å¤±è´¥: {e}")
            return False

    def get_available_node_types(self):
        """è·å–åç«¯ComfyUIå¯ç”¨çš„èŠ‚ç‚¹ç±»å‹é›†åˆï¼ˆæœ€ä½³åŠªåŠ›ï¼‰ã€‚

        ä¼˜å…ˆå°è¯• /object_infoï¼ˆéƒ¨åˆ†ç‰ˆæœ¬æä¾›ï¼‰ï¼Œå¤±è´¥åˆ™è¿”å› None è¡¨ç¤ºæ— æ³•é¢„æ£€ã€‚
        è¿”å›: set[str] | None
        """
        try:
            # å°è¯•è·å–æ‰€æœ‰èŠ‚ç‚¹å®šä¹‰
            resp = requests.get(f"{COMFYUI_API_URL}/object_info", timeout=5)
            if resp.status_code == 200:
                data = resp.json()
                # å¸¸è§æ ¼å¼ï¼š{"nodes": {"ClassName": {...}, ...}} æˆ–ç›´æ¥ {"ClassName": {...}}
                if isinstance(data, dict):
                    if 'nodes' in data and isinstance(data['nodes'], dict):
                        return set(data['nodes'].keys())
                    else:
                        # ç›´æ¥æ˜¯èŠ‚ç‚¹æ˜ å°„
                        return set(k for k, v in data.items() if isinstance(v, dict))
            return None
        except Exception as e:
            logger.debug(f"è·å–å¯ç”¨èŠ‚ç‚¹åˆ—è¡¨å¤±è´¥ï¼ˆå°†è·³è¿‡é¢„æ£€ï¼‰: {e}")
            return None
    
    def run_workflow(self, filename, task_id):
        """ä½¿ç”¨ComfyUI APIè¿è¡Œworkflowï¼ˆåŸå§‹æ–¹æ³•ï¼Œä¿æŒå…¼å®¹æ€§ï¼‰"""
        return self.run_workflow_with_parameters(filename, task_id, {})
    
    def run_workflow_with_parameters(self, filename, task_id, parameters):
        """ä½¿ç”¨ComfyUI APIè¿è¡Œworkflowï¼Œæ”¯æŒå‚æ•°ä¿®æ”¹"""
        return self.run_workflow_with_parameters_and_images(filename, task_id, parameters, {})
    
    def run_workflow_with_parameters_and_images(self, filename, task_id, parameters, selected_images):
        """ä½¿ç”¨ComfyUI APIè¿è¡Œworkflowï¼Œæ”¯æŒå‚æ•°ä¿®æ”¹å’Œå›¾åƒè¾“å…¥"""
        filepath = os.path.join(WORKFLOW_DIR, filename)
        
        if not os.path.exists(filepath):
            return {'success': False, 'error': f'æ–‡ä»¶ä¸å­˜åœ¨: {filename}'}
        
        # æ£€æŸ¥ComfyUIæœåŠ¡çŠ¶æ€
        if not self.check_comfyui_status():
            return {'success': False, 'error': 'ComfyUIæœåŠ¡æœªè¿è¡Œæˆ–æ— æ³•è¿æ¥'}
        
        try:
            # è¯»å–workflowæ–‡ä»¶
            with open(filepath, 'r', encoding='utf-8') as f:
                workflow_data = json.load(f)
            
            # é¢„è®¡ç®—èŠ‚ç‚¹é¡ºåºæ˜ å°„ä¸èŠ‚ç‚¹å…ƒä¿¡æ¯ï¼Œä¾›æ›´ç²¾å‡†è¿›åº¦ä¸å¯è¯»çŠ¶æ€æ˜¾ç¤º
            try:
                nodes = workflow_data.get('nodes', [])
                total_nodes = len(nodes)
                node_index_map = {str(n.get('id')): i for i, n in enumerate(nodes)}
                # èŠ‚ç‚¹å¯è¯»æ ‡ç­¾æ˜ å°„ï¼šid -> "ç±»å‹ - æ ‡é¢˜"/"ç±»å‹"
                node_meta_map = {}
                # æŒ‰é¡ºåºçš„èŠ‚ç‚¹IDåˆ—è¡¨
                node_order_list = []
                for n in nodes:
                    nid = str(n.get('id'))
                    ntype = n.get('type') or n.get('class_type') or 'Node'
                    ntitle = n.get('title') or ''
                    label = f"{ntype} - {ntitle}".strip(' -')
                    node_meta_map[nid] = label
                    node_order_list.append(nid)
                # æ ¹æ® index æ’åºç¡®ä¿é¡ºåºä¸€è‡´
                node_order_list.sort(key=lambda nid: node_index_map.get(nid, 0))
            except Exception:
                total_nodes = 0
                node_index_map = {}
                node_meta_map = {}

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            running_tasks[task_id] = {
                'status': 'running',
                'filename': filename,
                'workflow_filename': filename,  # æ·»åŠ å·¥ä½œæµæ–‡ä»¶å
                'parameters': parameters,  # æ·»åŠ å‚æ•°
                'start_time': datetime.now().isoformat(),
                'progress': 0,
                'prompt_id': None,
                'total_nodes': total_nodes,
                'node_index_map': node_index_map,
                'node_meta_map': node_meta_map,
                'node_order_list': node_order_list,
                'current_node_id': None,
                'current_node_label': None
            }
            
            # ä¿®æ”¹å·¥ä½œæµå‚æ•°å’Œå›¾åƒè¾“å…¥
            modified_workflow = self.modify_workflow_with_parameters_and_images(workflow_data, parameters, selected_images)
            
            # æ£€æŸ¥ä¿®æ”¹æ˜¯å¦æˆåŠŸ
            if modified_workflow is None:
                error_msg = "å¿…é€‰å›¾åƒè¾“å…¥èŠ‚ç‚¹æ²¡æœ‰æä¾›å›¾åƒï¼Œä»»åŠ¡æ— æ³•æ‰§è¡Œ"
                logger.error(error_msg)
                running_tasks[task_id].update({
                    'status': 'failed',
                    'end_time': datetime.now().isoformat(),
                    'error': error_msg,
                    'message': 'ä»»åŠ¡æ— æ³•æ‰§è¡Œï¼šç¼ºå°‘å¿…é€‰å›¾åƒè¾“å…¥'
                })
                return {'success': False, 'error': error_msg}
            
            # å°†UIæ ¼å¼è½¬æ¢ä¸ºAPIæ ¼å¼
            api_workflow = self.convert_ui_to_api_format(modified_workflow)
            if not api_workflow:
                error_msg = "è½¬æ¢workflowæ ¼å¼å¤±è´¥"
                logger.error(error_msg)
                running_tasks[task_id].update({
                    'status': 'failed',
                    'end_time': datetime.now().isoformat(),
                    'error': error_msg
                })
                return {'success': False, 'error': error_msg}
            
            # è°ƒè¯•ï¼šæ£€æŸ¥è½¬æ¢åçš„workflow
            logger.info(f"è½¬æ¢åçš„API workflowåŒ…å« {len(api_workflow.get('prompt', {}))} ä¸ªèŠ‚ç‚¹")
            for node_id, node_data in api_workflow.get('prompt', {}).items():
                logger.info(f"èŠ‚ç‚¹ {node_id}: {node_data.get('class_type', 'unknown')}")
            
            # ç‰¹åˆ«æ£€æŸ¥èŠ‚ç‚¹8
            if '8' in api_workflow.get('prompt', {}):
                logger.info(f"èŠ‚ç‚¹8å­˜åœ¨: {api_workflow['prompt']['8']}")
            else:
                logger.error("èŠ‚ç‚¹8ä¸å­˜åœ¨äºAPI workflowä¸­ï¼")
                logger.error(f"å¯ç”¨çš„èŠ‚ç‚¹ID: {list(api_workflow.get('prompt', {}).keys())}")
            
            # æ£€æŸ¥SaveImageèŠ‚ç‚¹
            save_image_nodes = [node_id for node_id, node_data in api_workflow.get('prompt', {}).items() 
                               if node_data.get('class_type') == 'SaveImage']
            for node_id in save_image_nodes:
                node_data = api_workflow['prompt'][node_id]
                logger.info(f"SaveImageèŠ‚ç‚¹ {node_id}: {node_data}")
                if 'images' in node_data.get('inputs', {}):
                    images_value = node_data['inputs']['images']
                    logger.info(f"SaveImageèŠ‚ç‚¹ {node_id} çš„imageså‚æ•°: {images_value} (ç±»å‹: {type(images_value)})")
            
            # ç”Ÿæˆå®¢æˆ·ç«¯ID
            client_id = str(uuid.uuid4())
            
            # å‡†å¤‡APIè¯·æ±‚æ•°æ®
            prompt_data = {
                "prompt": api_workflow['prompt'],
                "client_id": client_id
            }
            
            # è°ƒè¯•ï¼šæ˜¾ç¤ºå‘é€ç»™ComfyUIçš„æ•°æ®
            logger.info(f"å‘é€ç»™ComfyUIçš„prompt_dataä¸­çš„èŠ‚ç‚¹: {list(prompt_data['prompt'].keys())}")
            if '8' in prompt_data['prompt']:
                logger.info(f"prompt_dataä¸­èŠ‚ç‚¹8å­˜åœ¨: {prompt_data['prompt']['8']}")
            else:
                logger.error("prompt_dataä¸­èŠ‚ç‚¹8ä¸å­˜åœ¨ï¼")
            
            # æäº¤å‰è¿›è¡Œåç«¯èŠ‚ç‚¹å¯ç”¨æ€§é¢„æ£€ï¼ˆè‹¥å¯ç”¨ï¼‰
            try:
                # æ”¶é›†æ­¤æ¬¡æäº¤æ‰€éœ€çš„èŠ‚ç‚¹ç±»å‹
                required_types = set()
                for _nid, _n in api_workflow.get('prompt', {}).items():
                    ctype = _n.get('class_type')
                    if isinstance(ctype, str) and ctype:
                        required_types.add(ctype)

                available_types = self.get_available_node_types()
                if isinstance(available_types, set) and required_types:
                    missing = sorted(list(required_types - available_types))
                    if missing:
                        error_msg = (
                            "åç«¯ComfyUIç¼ºå°‘ä»¥ä¸‹èŠ‚ç‚¹ç±»å‹: " + ", ".join(missing) +
                            f"ã€‚è¯·ç¡®è®¤ç›®æ ‡å®ä¾‹({COMFYUI_API_URL})å·²å®‰è£…ç›¸åº”è‡ªå®šä¹‰èŠ‚ç‚¹ï¼Œæˆ–æ£€æŸ¥ COMFYUI_HOST/COMFYUI_PORT æ˜¯å¦æŒ‡å‘æ­£ç¡®çš„å®ä¾‹ã€‚"
                        )
                        logger.error(error_msg)
                        running_tasks[task_id].update({
                            'status': 'failed',
                            'end_time': datetime.now().isoformat(),
                            'error': error_msg,
                            'message': 'ä»»åŠ¡æäº¤å‰æ£€æŸ¥å¤±è´¥ï¼šåç«¯ç¼ºå°‘èŠ‚ç‚¹'
                        })
                        return {'success': False, 'error': error_msg}
            except Exception as _e:
                logger.debug(f"é¢„æ£€èŠ‚ç‚¹å¯ç”¨æ€§æ—¶å‘ç”Ÿéè‡´å‘½é”™è¯¯ï¼Œç»§ç»­æäº¤: {_e}")

            # å‘é€åˆ°ComfyUI APIï¼ˆè‹¥é¢„æ£€é€šè¿‡æˆ–ä¸å¯ç”¨ï¼‰
            logger.info(f"å‘é€ä¿®æ”¹åçš„workflowåˆ°ComfyUI: {filename}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºæ­£åœ¨æäº¤
            running_tasks[task_id].update({
                'status': 'submitting',
                'progress': 5,
                'message': 'æ­£åœ¨æäº¤ä»»åŠ¡åˆ°ComfyUI...'
            })
            
            response = requests.post(
                f"{COMFYUI_API_URL}/prompt", 
                json=prompt_data,
                timeout=30
            )
            
            if response.status_code == 200:
                result_data = response.json()
                prompt_id = result_data.get('prompt_id')
                
                if not prompt_id:
                    error_msg = "ComfyUIè¿”å›çš„å“åº”ä¸­æ²¡æœ‰prompt_id"
                    logger.error(error_msg)
                    running_tasks[task_id].update({
                        'status': 'failed',
                        'end_time': datetime.now().isoformat(),
                        'error': error_msg,
                        'message': 'æäº¤å¤±è´¥ï¼šæœªè·å¾—ä»»åŠ¡ID'
                    })
                    return {'success': False, 'error': error_msg}
                
                running_tasks[task_id].update({
                    'prompt_id': prompt_id,
                    'client_id': client_id,
                    'status': 'submitted',
                    'progress': 10,
                    'message': 'ä»»åŠ¡å·²æäº¤ï¼Œç­‰å¾…æ‰§è¡Œ...'
                })
                
                logger.info(f"Workflowæäº¤æˆåŠŸ, prompt_id: {prompt_id}")
                
                # å¯åŠ¨çŠ¶æ€ç›‘æ§
                self._monitor_workflow_progress(task_id, prompt_id, client_id)
                
                result = {'success': True, 'prompt_id': prompt_id}
            else:
                error_msg = f"ComfyUI APIé”™è¯¯: {response.status_code} - {response.text}"
                logger.error(error_msg)
                running_tasks[task_id].update({
                    'status': 'failed',
                    'end_time': datetime.now().isoformat(),
                    'error': error_msg,
                    'message': f'æäº¤å¤±è´¥ï¼šHTTP {response.status_code}'
                })
                result = {'success': False, 'error': error_msg}
                
        except Exception as e:
            error_msg = str(e)
            logger.error(f"æ‰§è¡Œworkflowå¤±è´¥: {error_msg}")
            running_tasks[task_id].update({
                'status': 'failed',
                'end_time': datetime.now().isoformat(),
                'error': error_msg
            })
            result = {'success': False, 'error': error_msg}
        
        return result
    
    def apply_output_settings(self, workflow_data, parameters):
        """åº”ç”¨è¾“å‡ºè®¾ç½®å‚æ•°åˆ°PrimitiveNode"""
        output_settings = parameters.get('output_settings', {})
        if not output_settings:
            return
            
        # æŸ¥æ‰¾widthå’Œheightçš„PrimitiveNode
        for node in workflow_data.get('nodes', []):
            if node.get('type') == 'PrimitiveNode':
                title = node.get('title', '').lower()
                widgets_values = node.get('widgets_values', [])
                
                if title == 'width' and 'output_width' in output_settings:
                    if len(widgets_values) >= 1:
                        widgets_values[0] = int(output_settings['output_width'])
                    if len(widgets_values) >= 2 and 'size_control_mode' in output_settings:
                        widgets_values[1] = output_settings['size_control_mode']
                    node['widgets_values'] = widgets_values
                    
                elif title == 'height' and 'output_height' in output_settings:
                    if len(widgets_values) >= 1:
                        widgets_values[0] = int(output_settings['output_height'])
                    if len(widgets_values) >= 2 and 'size_control_mode' in output_settings:
                        widgets_values[1] = output_settings['size_control_mode']
                    node['widgets_values'] = widgets_values
                    
            # å¤„ç†batch_sizeå‚æ•°
            elif 'batch_size' in output_settings:
                node_type = node.get('type', '')
                if node_type in WIDGET_INDEX_MAP and 'batch_size' in WIDGET_INDEX_MAP[node_type]:
                    widgets_values = node.get('widgets_values', [])
                    batch_idx = WIDGET_INDEX_MAP[node_type]['batch_size']
                    if len(widgets_values) > batch_idx:
                        widgets_values[batch_idx] = int(output_settings['batch_size'])
                        node['widgets_values'] = widgets_values

    def modify_workflow_with_parameters(self, workflow_data, parameters):
        """æ ¹æ®ç”¨æˆ·å‚æ•°ä¿®æ”¹å·¥ä½œæµ"""
        return self.modify_workflow_with_parameters_and_images(workflow_data, parameters, {})
    
    def modify_workflow_with_parameters_and_images(self, workflow_data, parameters, selected_images):
        """æ ¹æ®ç”¨æˆ·å‚æ•°å’Œå›¾åƒè¾“å…¥ä¿®æ”¹å·¥ä½œæµï¼ˆUIæ ¼å¼ï¼‰"""
        try:
            # åœ¨å¤„ç†èŠ‚ç‚¹ä¹‹å‰ï¼Œå…ˆåº”ç”¨é€šç”¨çš„æ¨¡å‹åŠ è½½å™¨å‚æ•°æ˜ å°„
            apply_loader_param_mapping(workflow_data, parameters)
            
            # å¤„ç†è¾“å‡ºè®¾ç½®å‚æ•°
            self.apply_output_settings(workflow_data, parameters)
            
            nodes = workflow_data.get('nodes', [])
            modified_nodes = []
            auto_outpaint_mask = bool(parameters.get('auto_outpaint_mask', True))
            # å‰ç«¯é®ç½©ç¼–è¾‘å™¨ä¿å­˜çš„é®ç½©ï¼ˆoutputs/uploaded/xxx.pngï¼‰ã€‚è‹¥æä¾›åˆ™ä¼˜å…ˆä½¿ç”¨è¯¥é®ç½©ï¼Œä¸”ä»æ²¿ç”¨ Fill å·¥ä½œæµé“¾è·¯ã€‚
            mask_image_from_editor = parameters.get('mask_image')
            # è®°å½•ç¬¬ä¸€ä¸ªç”¨æˆ·å®é™…é€‰æ‹©çš„å›¾åƒæ–‡ä»¶ï¼Œä¾›å¯é€‰èŠ‚ç‚¹ç¼ºçœæ—¶ä½¿ç”¨å ä½
            fallback_image_filename = None
            logger.info(f"å¼€å§‹å¤„ç†å·¥ä½œæµï¼Œselected_images: {selected_images}")
            if selected_images:
                # å–ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„ä¸Šä¼ æ–‡ä»¶å
                first_key = next(iter(selected_images))
                fallback_path = selected_images[first_key].get('path', '')
                if fallback_path:
                    # ä½¿ç”¨ ComfyUI input æ ‡è®°ï¼Œä¿è¯æ ¡éªŒè§£ææ­£ç¡®
                    fallback_image_filename = f"{os.path.basename(fallback_path)} [input]"
            else:
                logger.info("æ²¡æœ‰é€‰æ‹©ä»»ä½•å›¾åƒï¼Œå°†æ£€æŸ¥å¿…é€‰èŠ‚ç‚¹")
            
            # è®°å½•å°ºå¯¸ï¼Œä¾›è‡ªåŠ¨æ©ç ä½¿ç”¨ï¼ˆä»…Fillå·¥ä½œæµä½¿ç”¨ï¼‰
            target_width = None
            target_height = None
            has_outpaint_node = False

            for node in nodes:
                modified_node = node.copy()
                # UIæ ¼å¼ä½¿ç”¨typeå­—æ®µï¼ŒAPIæ ¼å¼ä½¿ç”¨class_typeå­—æ®µ
                node_type = node.get('type', '')  # UIæ ¼å¼
                node_id = node.get('id', '')
                
                # æ ¹æ®èŠ‚ç‚¹ç±»å‹ä¿®æ”¹å‚æ•°
                if node_type == 'KSampler':
                    # ä¿®æ”¹KSamplerå‚æ•° - UIæ ¼å¼ä¸­å‚æ•°åœ¨widgets_valuesä¸­
                    widgets_values = modified_node.get('widgets_values', [])
                    # å¤„ç†ç§å­å‚æ•° - KSamplerçš„seedåœ¨widgets_values[0]
                    if 'seed' in parameters and parameters['seed'] != '-1' and len(widgets_values) > 0:
                        try:
                            seed_value = int(parameters['seed'])
                            # ç¡®ä¿seedå€¼ä¸å°äº0
                            if seed_value < 0:
                                seed_value = 0
                            widgets_values[0] = seed_value
                        except (ValueError, TypeError):
                            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼0è€Œä¸æ˜¯-1
                            widgets_values[0] = 0
                    # å¤„ç†é‡‡æ ·å™¨å‚æ•°
                    if 'sampler' in parameters and len(widgets_values) > 4:
                        widgets_values[4] = parameters['sampler']
                    modified_node['widgets_values'] = widgets_values
                
                elif 'KSamplerSelect' in node_type:
                    # ä¿®æ”¹KSamplerSelectå‚æ•° - åªæœ‰sampler_nameå‚æ•°
                    widgets_values = modified_node.get('widgets_values', [])
                    # å¤„ç†é‡‡æ ·å™¨å‚æ•°
                    if 'sampler' in parameters and len(widgets_values) > 0:
                        widgets_values[0] = parameters['sampler']
                    modified_node['widgets_values'] = widgets_values
                
                elif 'RandomNoise' in node_type:
                    # ä¿®æ”¹éšæœºç§å­ - UIæ ¼å¼ä¸­seedåœ¨widgets_valuesä¸­
                    widgets_values = modified_node.get('widgets_values', [])
                    if 'seed' in parameters and parameters['seed'] != '-1':
                        try:
                            seed_value = int(parameters['seed'])
                            # ç¡®ä¿seedå€¼ä¸å°äº0ï¼Œå› ä¸ºComfyUIè¦æ±‚noise_seed >= 0
                            if seed_value < 0:
                                seed_value = 0
                            widgets_values[0] = seed_value
                        except (ValueError, TypeError):
                            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼0è€Œä¸æ˜¯-1
                            widgets_values[0] = 0
                    modified_node['widgets_values'] = widgets_values
                
                elif 'BasicScheduler' in node_type:
                    # ä¿®æ”¹è°ƒåº¦å™¨å‚æ•° - UIæ ¼å¼ä¸­å‚æ•°åœ¨widgets_valuesä¸­
                    widgets_values = modified_node.get('widgets_values', [])
                    if len(widgets_values) >= 3:
                        if 'scheduler' in parameters:
                            widgets_values[0] = parameters['scheduler']
                        if 'steps' in parameters:
                            try:
                                widgets_values[1] = int(parameters['steps'])
                            except (ValueError, TypeError):
                                widgets_values[1] = 20
                        if 'denoise' in parameters:
                            try:
                                widgets_values[2] = float(parameters['denoise'])
                            except (ValueError, TypeError):
                                widgets_values[2] = 1.0
                    modified_node['widgets_values'] = widgets_values
                
                elif 'FluxGuidance' in node_type:
                    # ä¿®æ”¹ FluxGuidance å‚æ•°ï¼ˆguidance å•ç‹¬ç®¡ç†ï¼Œä¸å†å¤ç”¨ cfg åç§°ï¼‰
                    widgets_values = modified_node.get('widgets_values', [])
                    if 'guidance' in parameters and len(widgets_values) > 0:
                        try:
                            widgets_values[0] = float(parameters['guidance'])
                        except (ValueError, TypeError):
                            widgets_values[0] = 7.0
                    modified_node['widgets_values'] = widgets_values

                elif 'KSampler' in node_type:
                    # ä¿®æ”¹ KSampler å‚æ•°
                    widgets_values = modified_node.get('widgets_values', [])
                    # ç¡®ä¿é•¿åº¦è‡³å°‘ä¸º7
                    if len(widgets_values) < 7:
                        widgets_values = (widgets_values + [None] * 7)[:7]
                    try:
                        if 'seed' in parameters and parameters['seed'] not in (None, ''):
                            widgets_values[0] = int(parameters['seed'])
                    except (ValueError, TypeError):
                        pass
                    try:
                        if 'steps' in parameters and parameters['steps'] not in (None, ''):
                            widgets_values[2] = int(parameters['steps'])
                    except (ValueError, TypeError):
                        pass
                    try:
                        if 'cfg' in parameters and parameters['cfg'] not in (None, ''):
                            widgets_values[3] = float(parameters['cfg'])
                    except (ValueError, TypeError):
                        pass
                    if 'sampler' in parameters and parameters['sampler']:
                        widgets_values[4] = parameters['sampler']
                    if 'scheduler' in parameters and parameters['scheduler']:
                        widgets_values[5] = parameters['scheduler']
                    try:
                        if 'denoise' in parameters and parameters['denoise'] not in (None, ''):
                            widgets_values[6] = float(parameters['denoise'])
                    except (ValueError, TypeError):
                        pass
                    modified_node['widgets_values'] = widgets_values
                
                elif 'CLIPTextEncode' in node_type:
                    # ä¿®æ”¹æç¤ºè¯ - UIæ ¼å¼ä¸­æ–‡æœ¬åœ¨widgets_valuesä¸­
                    widgets_values = modified_node.get('widgets_values', [])
                    # æ ¹æ®èŠ‚ç‚¹æ ‡é¢˜åˆ¤æ–­æ˜¯æ­£é¢è¿˜æ˜¯è´Ÿé¢æç¤ºè¯
                    node_title = node.get('title', '').lower()
                    if 'negative' in node_title or 'neg' in node_title:
                        if 'negative_prompt' in parameters and parameters['negative_prompt']:
                            if len(widgets_values) > 0:
                                widgets_values[0] = parameters['negative_prompt']
                    else:
                        if 'positive_prompt' in parameters and parameters['positive_prompt']:
                            if len(widgets_values) > 0:
                                widgets_values[0] = parameters['positive_prompt']
                    modified_node['widgets_values'] = widgets_values

                elif 'InpaintModelConditioning' in node_type:
                    # å™ªå£°æ©ç ï¼šä¼˜å…ˆé‡‡ç”¨ç”¨æˆ·å‚æ•°ï¼›è‹¥æ— ä¸”ä¸º Fillï¼ˆé Outpaintï¼‰è‡ªåŠ¨å¼€å¯
                    widgets_values = modified_node.get('widgets_values', [])
                    if 'noise_mask' in parameters:
                        try:
                            val = bool(parameters.get('noise_mask'))
                            if not widgets_values:
                                widgets_values = [val]
                            else:
                                widgets_values[0] = val
                        except Exception:
                            pass
                    elif auto_outpaint_mask and not has_outpaint_node:
                        if not widgets_values:
                            widgets_values = [True]
                        else:
                            try:
                                widgets_values[0] = True
                            except Exception:
                                widgets_values = [True]
                    modified_node['widgets_values'] = widgets_values

                elif 'ImagePadForOutpaint' in node_type:
                    widgets_values = modified_node.get('widgets_values', [])
                    if len(widgets_values) < 5:
                        widgets_values = (widgets_values + [0, 0, 0, 0, 24])[:5]
                    try:
                        if parameters.get('outpaint_left') is not None:
                            widgets_values[0] = int(parameters['outpaint_left'])
                        if parameters.get('outpaint_right') is not None:
                            widgets_values[1] = int(parameters['outpaint_right'])
                        if parameters.get('outpaint_top') is not None:
                            widgets_values[2] = int(parameters['outpaint_top'])
                        if parameters.get('outpaint_bottom') is not None:
                            widgets_values[3] = int(parameters['outpaint_bottom'])
                        if parameters.get('outpaint_feather') is not None:
                            widgets_values[4] = int(parameters['outpaint_feather'])
                    except Exception:
                        pass
                    modified_node['widgets_values'] = widgets_values
                    has_outpaint_node = True
                
                elif 'PrimitiveNode' in node_type:
                    # ä¿®æ”¹PrimitiveNodeçš„å°ºå¯¸å‚æ•°
                    node_title = node.get('title', '').lower()
                    widgets_values = modified_node.get('widgets_values', [])
                    
                    if node_title == 'width' and 'width' in parameters and len(widgets_values) >= 1:
                        try:
                            width_value = int(parameters['width'])
                            widgets_values[0] = width_value
                        except (ValueError, TypeError):
                            # ä½¿ç”¨JSONæ–‡ä»¶ä¸­çš„åŸå§‹å€¼ä½œä¸ºé»˜è®¤å€¼
                            widgets_values[0] = widgets_values[0] if widgets_values[0] is not None else 1024
                    
                    elif node_title == 'height' and 'height' in parameters and len(widgets_values) >= 1:
                        try:
                            height_value = int(parameters['height'])
                            widgets_values[0] = height_value
                        except (ValueError, TypeError):
                            # ä½¿ç”¨JSONæ–‡ä»¶ä¸­çš„åŸå§‹å€¼ä½œä¸ºé»˜è®¤å€¼
                            widgets_values[0] = widgets_values[0] if widgets_values[0] is not None else 1024
                    
                    modified_node['widgets_values'] = widgets_values
                
                elif 'EmptySD3LatentImage' in node_type:
                    # ä¿®æ”¹EmptySD3LatentImageçš„å°ºå¯¸å‚æ•°
                    widgets_values = modified_node.get('widgets_values', [])
                    if len(widgets_values) >= 2:
                        if 'width' in parameters:
                            try:
                                width_value = int(parameters['width'])
                                widgets_values[0] = width_value
                            except (ValueError, TypeError):
                                # ä½¿ç”¨JSONæ–‡ä»¶ä¸­çš„åŸå§‹å€¼ä½œä¸ºé»˜è®¤å€¼
                                widgets_values[0] = widgets_values[0] if widgets_values[0] is not None else 1024
                        
                        if 'height' in parameters:
                            try:
                                height_value = int(parameters['height'])
                                widgets_values[1] = height_value
                            except (ValueError, TypeError):
                                # ä½¿ç”¨JSONæ–‡ä»¶ä¸­çš„åŸå§‹å€¼ä½œä¸ºé»˜è®¤å€¼
                                widgets_values[1] = widgets_values[1] if widgets_values[1] is not None else 1024
                    
                    modified_node['widgets_values'] = widgets_values
                
                elif 'SaveImage' in node_type:
                    # ä¿®æ”¹SaveImageèŠ‚ç‚¹çš„filename_prefixï¼Œé¿å…ComfyUIå†…éƒ¨ç¼“å­˜
                    widgets_values = modified_node.get('widgets_values', [])
                    if len(widgets_values) > 0:
                        # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åå‰ç¼€ï¼ŒåŒ…å«æ—¶é—´æˆ³å’Œéšæœºæ•°
                        import time
                        timestamp = int(time.time())
                        random_suffix = random.randint(1000, 9999)
                        unique_prefix = f"ComfyUI_{timestamp}_{random_suffix}"
                        widgets_values[0] = unique_prefix
                        logger.info(f"ä¸ºSaveImageèŠ‚ç‚¹ {node_id} è®¾ç½®å”¯ä¸€æ–‡ä»¶åå‰ç¼€: {unique_prefix}")
                    modified_node['widgets_values'] = widgets_values

                elif 'ImageAndMaskResizeNode' in node_type:
                    # è¦†ç›–å¹¶è®°å½•ç›®æ ‡å°ºå¯¸ä¸ç¼©æ”¾ç­–ç•¥ï¼ˆæ¥è‡ªå‚æ•° â†’ widgetsï¼‰ï¼Œå¦åˆ™ä¿æŒJSONé»˜è®¤
                    widgets_values = modified_node.get('widgets_values', [])
                    # ç¡®ä¿é•¿åº¦è‡³å°‘ä¸º5
                    while len(widgets_values) < 5:
                        widgets_values.append(None)
                    # åº”ç”¨å‰ç«¯ä¼ å…¥çš„ width/heightï¼ˆè‹¥æä¾›ï¼‰
                    try:
                        if 'width' in parameters and parameters['width']:
                            widgets_values[0] = int(parameters['width'])
                        if 'height' in parameters and parameters['height']:
                            widgets_values[1] = int(parameters['height'])
                    except Exception:
                        pass
                    # åº”ç”¨å‰ç«¯ä¼ å…¥çš„ resize_method/crop/mask_blur_radiusï¼ˆè‹¥æä¾›ï¼‰
                    try:
                        if parameters.get('resize_method'):
                            widgets_values[2] = parameters['resize_method']
                        if parameters.get('crop'):
                            widgets_values[3] = parameters['crop']
                        if parameters.get('mask_blur_radius') is not None and parameters.get('mask_blur_radius') != '':
                            widgets_values[4] = int(parameters['mask_blur_radius'])
                    except Exception:
                        pass
                    # è®°å½•ç”¨äºè‡ªåŠ¨æ©ç 
                # Outpaintï¼šImagePadForOutpaint å‚æ•°æ³¨å…¥
                elif 'ImagePadForOutpaint' in node_type:
                    widgets_values = modified_node.get('widgets_values', [])
                    # ç¡®ä¿é•¿åº¦è‡³å°‘ä¸º5
                    if len(widgets_values) < 5:
                        widgets_values = (widgets_values + [0, 0, 0, 0, 24])[:5]
                    try:
                        # åŸç”Ÿé¡ºåºï¼šå·¦ã€ä¸Šã€å³ã€ä¸‹ã€ç¾½åŒ–
                        if parameters.get('outpaint_left') is not None:
                            widgets_values[0] = int(parameters['outpaint_left'])
                        if parameters.get('outpaint_top') is not None:
                            widgets_values[1] = int(parameters['outpaint_top'])
                        if parameters.get('outpaint_right') is not None:
                            widgets_values[2] = int(parameters['outpaint_right'])
                        if parameters.get('outpaint_bottom') is not None:
                            widgets_values[3] = int(parameters['outpaint_bottom'])
                        if parameters.get('outpaint_feather') is not None:
                            widgets_values[4] = int(parameters['outpaint_feather'])
                    except Exception:
                        pass
                    modified_node['widgets_values'] = widgets_values
                    has_outpaint_node = True
                    try:
                        target_width = int(widgets_values[0])
                        target_height = int(widgets_values[1])
                    except Exception:
                        target_width = target_width or None
                        target_height = target_height or None
                    modified_node['widgets_values'] = widgets_values
                
                # å¤„ç†æ¨¡å‹åŠ è½½å™¨èŠ‚ç‚¹
                elif 'NunchakuTextEncoderLoader' in node_type:
                    widgets_values = modified_node.get('widgets_values', [])
                    model_loaders = parameters.get('model_loaders', {})
                    
                    if len(widgets_values) >= 6:
                        # æ¨¡å‹ç±»å‹
                        param_key = f'model_type_{node_id}'
                        if param_key in model_loaders:
                            widgets_values[0] = model_loaders[param_key]
                        
                        # æ–‡æœ¬ç¼–ç å™¨1
                        param_key = f'text_encoder1_{node_id}'
                        if param_key in model_loaders and len(widgets_values) > 1:
                            widgets_values[1] = model_loaders[param_key]
                        
                        # æ–‡æœ¬ç¼–ç å™¨2
                        param_key = f'text_encoder2_{node_id}'
                        if param_key in model_loaders and len(widgets_values) > 2:
                            widgets_values[2] = model_loaders[param_key]
                        
                        # T5æœ€å°é•¿åº¦
                        param_key = f't5_min_length_{node_id}'
                        if param_key in model_loaders and len(widgets_values) > 3:
                            try:
                                widgets_values[3] = int(model_loaders[param_key])
                            except (ValueError, TypeError):
                                widgets_values[3] = 512
                        
                        # ä½¿ç”¨4bit T5
                        param_key = f'use_4bit_t5_{node_id}'
                        if param_key in model_loaders and len(widgets_values) > 4:
                            widgets_values[4] = model_loaders[param_key]
                        
                        # INT4æ¨¡å‹
                        param_key = f'int4_model_{node_id}'
                        if param_key in model_loaders and len(widgets_values) > 5:
                            widgets_values[5] = model_loaders[param_key]
                    
                    modified_node['widgets_values'] = widgets_values
                
                elif 'NunchakuFluxDiTLoader' in node_type:
                    widgets_values = modified_node.get('widgets_values', [])
                    model_loaders = parameters.get('model_loaders', {})
                    
                    if len(widgets_values) >= 7:
                        # æ¨¡å‹è·¯å¾„
                        param_key = f'model_path_{node_id}'
                        if param_key in model_loaders:
                            widgets_values[0] = model_loaders[param_key]
                        
                        # ç¼“å­˜é˜ˆå€¼
                        param_key = f'cache_threshold_{node_id}'
                        if param_key in model_loaders and len(widgets_values) > 1:
                            try:
                                widgets_values[1] = int(model_loaders[param_key])
                            except (ValueError, TypeError):
                                widgets_values[1] = 0
                        
                        # æ³¨æ„åŠ›æœºåˆ¶
                        param_key = f'attention_{node_id}'
                        if param_key in model_loaders and len(widgets_values) > 2:
                            widgets_values[2] = model_loaders[param_key]
                        
                        # CPUå¸è½½
                        param_key = f'cpu_offload_{node_id}'
                        if param_key in model_loaders and len(widgets_values) > 3:
                            # å½’ä¸€åŒ–å‰ç«¯ä¼ å…¥çš„å–å€¼ï¼Œé¿å…æ ¡éªŒå¤±è´¥
                            raw_value = str(model_loaders[param_key]).lower()
                            normalization_map = {
                                'enabled': 'enable',
                                'disabled': 'disable'
                            }
                            widgets_values[3] = normalization_map.get(raw_value, raw_value)
                        
                        # è®¾å¤‡ID
                        param_key = f'device_id_{node_id}'
                        if param_key in model_loaders and len(widgets_values) > 4:
                            try:
                                widgets_values[4] = int(model_loaders[param_key])
                            except (ValueError, TypeError):
                                widgets_values[4] = 0
                        
                        # æ•°æ®ç±»å‹
                        param_key = f'data_type_{node_id}'
                        if param_key in model_loaders and len(widgets_values) > 5:
                            widgets_values[5] = model_loaders[param_key]
                        
                        # I2Fæ¨¡å¼ï¼ˆä¿æŒåŸå€¼ï¼Œéƒ¨åˆ†èŠ‚ç‚¹å…è®¸å€¼ä¸º enabled/disabledï¼‰
                        param_key = f'i_2_f_mode_{node_id}'
                        if param_key in model_loaders and len(widgets_values) > 6:
                            widgets_values[6] = model_loaders[param_key]
                    
                    modified_node['widgets_values'] = widgets_values
                
                elif 'NunchakuFluxLoraLoader' in node_type:
                    widgets_values = modified_node.get('widgets_values', [])
                    model_loaders = parameters.get('model_loaders', {})
                    
                    if len(widgets_values) >= 2:
                        # LoRAåç§°
                        param_key = f'lora_name_{node_id}'
                        if param_key in model_loaders:
                            widgets_values[0] = model_loaders[param_key]
                        
                        # LoRAå¼ºåº¦
                        param_key = f'lora_strength_{node_id}'
                        if param_key in model_loaders and len(widgets_values) > 1:
                            try:
                                widgets_values[1] = float(model_loaders[param_key])
                            except (ValueError, TypeError):
                                widgets_values[1] = 1.0
                    
                    modified_node['widgets_values'] = widgets_values
                
                elif 'VAELoader' in node_type:
                    widgets_values = modified_node.get('widgets_values', [])
                    model_loaders = parameters.get('model_loaders', {})
                    
                    if len(widgets_values) >= 1:
                        # VAEåç§°
                        param_key = f'vae_name_{node_id}'
                        if param_key in model_loaders:
                            widgets_values[0] = model_loaders[param_key]
                    
                    modified_node['widgets_values'] = widgets_values
                
                elif 'DualCLIPLoader' in node_type:
                    widgets_values = modified_node.get('widgets_values', [])
                    model_loaders = parameters.get('model_loaders', {})
                    
                    if len(widgets_values) >= 3:
                        # CLIPåç§°1
                        param_key = f'clip_name1_{node_id}'
                        if param_key in model_loaders:
                            widgets_values[0] = model_loaders[param_key]
                        
                        # CLIPåç§°2
                        param_key = f'clip_name2_{node_id}'
                        if param_key in model_loaders and len(widgets_values) > 1:
                            widgets_values[1] = model_loaders[param_key]
                        
                        # CLIPç±»å‹ - éªŒè¯ç±»å‹å€¼æ˜¯å¦æœ‰æ•ˆ
                        param_key = f'clip_type_{node_id}'
                        if param_key in model_loaders and len(widgets_values) > 2:
                            clip_type = model_loaders[param_key]
                            # éªŒè¯ç±»å‹å€¼æ˜¯å¦åœ¨å…è®¸çš„èŒƒå›´å†…
                            valid_types = ['sdxl', 'sd3', 'flux', 'hunyuan_video', 'hidream']
                            if clip_type in valid_types:
                                widgets_values[2] = clip_type
                            else:
                                # å¦‚æœç±»å‹æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼ 'flux'
                                logger.warning(f"æ— æ•ˆçš„CLIPç±»å‹ '{clip_type}'ï¼Œä½¿ç”¨é»˜è®¤å€¼ 'flux'")
                                widgets_values[2] = 'flux'
                    
                    modified_node['widgets_values'] = widgets_values

                elif 'LoraLoader' in node_type:
                    widgets_values = modified_node.get('widgets_values', [])
                    model_loaders = parameters.get('model_loaders', {})
                    if len(widgets_values) >= 2:
                        # LoRA åç§°
                        param_key = f'lora_name_{node_id}'
                        if param_key in model_loaders:
                            widgets_values[0] = model_loaders[param_key]
                        # LoRA å¼ºåº¦ï¼ˆé€šç”¨LoraLoaderå­—æ®µåä¸º strength_modelï¼‰
                        param_key = f'strength_model_{node_id}'
                        if param_key in model_loaders:
                            try:
                                v = float(model_loaders[param_key])
                                widgets_values[1] = v
                            except (ValueError, TypeError):
                                pass
                    modified_node['widgets_values'] = widgets_values

                elif 'CheckpointLoaderSimple' in node_type:
                    widgets_values = modified_node.get('widgets_values', [])
                    model_loaders = parameters.get('model_loaders', {})
                    if len(widgets_values) >= 1:
                        param_key = f'ckpt_name_{node_id}'
                        if param_key in model_loaders:
                            widgets_values[0] = model_loaders[param_key]
                    modified_node['widgets_values'] = widgets_values

                elif 'CLIPVisionLoader' in node_type:
                    # å…è®¸å‰ç«¯è¦†ç›–è§†è§‰CLIPæ¨¡å‹åç§°
                    widgets_values = modified_node.get('widgets_values', [])
                    model_loaders = parameters.get('model_loaders', {})
                    if len(widgets_values) >= 1:
                        param_key = f'clip_name_{node_id}'
                        if param_key in model_loaders:
                            widgets_values[0] = model_loaders[param_key]
                    # é€ä¼ å‰ç«¯å¯èƒ½æä¾›çš„ cropï¼ˆä¸ CLIPVisionEncode å¯¹é½ï¼‰
                    extra_crop_key = f'crop_{node_id}'
                    if extra_crop_key in model_loaders:
                        # å¦‚æœè¯¥ Loader èŠ‚ç‚¹æ²¡æœ‰ crop çš„ widgets_values æ§½ä½ï¼Œåˆ™å¿½ç•¥ï¼Œä»…ä¾› encode èŠ‚ç‚¹ä½¿ç”¨
                        pass
                    modified_node['widgets_values'] = widgets_values

                elif 'StyleModelLoader' in node_type:
                    # å…è®¸å‰ç«¯è¦†ç›–é£æ ¼æ¨¡å‹åç§°
                    widgets_values = modified_node.get('widgets_values', [])
                    model_loaders = parameters.get('model_loaders', {})
                    if len(widgets_values) >= 1:
                        param_key = f'style_model_name_{node_id}'
                        if param_key in model_loaders:
                            widgets_values[0] = model_loaders[param_key]
                    # Style strength ä¸ type å®é™…åº”ç”¨åœ¨ StyleModelApply èŠ‚ç‚¹ï¼Œè¿™é‡Œä»…ä¿ç•™ä¾›åç»­èŠ‚ç‚¹è¯»å–
                    # ä¸ä¿®æ”¹ widgets_values é•¿åº¦é¿å…ç´¢å¼•é”™ä½
                    modified_node['widgets_values'] = widgets_values

                # æ³¨æ„ï¼šæ¨¡å‹åŠ è½½å™¨å‚æ•°æ˜ å°„ç°åœ¨ç”±é€šç”¨å‡½æ•° apply_loader_param_mapping å¤„ç†
                # åŸæœ‰çš„ StyleModelApplyã€CLIPVisionEncodeã€ModelSamplingFlux ç‰¹å®šå¤„ç†é€»è¾‘å·²ç§»é™¤
                
                # é€šç”¨å…œåº•ï¼šä»»æ„åŒ…å« Loader çš„èŠ‚ç‚¹ä½œä¸ºæ½œåœ¨æ¨¡å‹åŠ è½½å™¨
                elif 'Loader' in node_type:
                    widgets_values = modified_node.get('widgets_values', [])
                    model_loaders = parameters.get('model_loaders', {})
                    widget_inputs = [
                        (inp.get('widget', {}) or {}).get('name')
                        for inp in node.get('inputs', [])
                        if isinstance(inp, dict) and 'widget' in inp and isinstance(inp.get('widget'), dict)
                    ]
                    if isinstance(widgets_values, list) and widget_inputs:
                        for idx, pname in enumerate(widget_inputs):
                            if not pname:
                                continue
                            key = f"{pname}_{node_id}"
                            if key in model_loaders and idx < len(widgets_values):
                                widgets_values[idx] = model_loaders[key]
                        modified_node['widgets_values'] = widgets_values
                
                elif 'EmptyLatentImage' in node_type or 'EmptySD3LatentImage' in node_type:
                    # ä¿®æ”¹å›¾åƒå°ºå¯¸ - UIæ ¼å¼ä¸­å°ºå¯¸åœ¨widgets_valuesä¸­
                    widgets_values = modified_node.get('widgets_values', [])
                    if 'width' in parameters and 'height' in parameters and len(widgets_values) >= 2:
                        try:
                            widgets_values[0] = int(parameters['width'])
                        except (ValueError, TypeError):
                            # ä½¿ç”¨JSONæ–‡ä»¶ä¸­çš„åŸå§‹å€¼ä½œä¸ºé»˜è®¤å€¼
                            widgets_values[0] = widgets_values[0] if widgets_values[0] is not None else 1024
                        try:
                            widgets_values[1] = int(parameters['height'])
                        except (ValueError, TypeError):
                            # ä½¿ç”¨JSONæ–‡ä»¶ä¸­çš„åŸå§‹å€¼ä½œä¸ºé»˜è®¤å€¼
                            widgets_values[1] = widgets_values[1] if widgets_values[1] is not None else 1024
                        modified_node['widgets_values'] = widgets_values
                
                # å¤„ç†ControlNeté…ç½®èŠ‚ç‚¹
                elif 'ControlNetLoader' in node_type:
                    widgets_values = modified_node.get('widgets_values', [])
                    controlnet_configs = parameters.get('controlnet_configs', {})
                    
                    if len(widgets_values) >= 1:
                        # ControlNetæ¨¡å‹åç§°
                        param_key = f'control_net_name_{node_id}'
                        if param_key in controlnet_configs:
                            widgets_values[0] = controlnet_configs[param_key]
                    
                    modified_node['widgets_values'] = widgets_values
                
                elif 'ControlNetApplyAdvanced' in node_type:
                    widgets_values = modified_node.get('widgets_values', [])
                    controlnet_configs = parameters.get('controlnet_configs', {})
                    
                    if len(widgets_values) >= 3:
                        # ControlNetå¼ºåº¦
                        param_key = f'strength_{node_id}'
                        if param_key in controlnet_configs:
                            try:
                                widgets_values[0] = float(controlnet_configs[param_key])
                            except (ValueError, TypeError):
                                widgets_values[0] = 1.0
                        
                        # å¼€å§‹ç™¾åˆ†æ¯”
                        param_key = f'start_percent_{node_id}'
                        if param_key in controlnet_configs:
                            try:
                                widgets_values[1] = float(controlnet_configs[param_key])
                            except (ValueError, TypeError):
                                widgets_values[1] = 0.0
                        
                        # ç»“æŸç™¾åˆ†æ¯”
                        param_key = f'end_percent_{node_id}'
                        if param_key in controlnet_configs:
                            try:
                                widgets_values[2] = float(controlnet_configs[param_key])
                            except (ValueError, TypeError):
                                widgets_values[2] = 1.0
                    
                    modified_node['widgets_values'] = widgets_values
                
                elif 'SetUnionControlNetType' in node_type:
                    widgets_values = modified_node.get('widgets_values', [])
                    controlnet_configs = parameters.get('controlnet_configs', {})
                    
                    if len(widgets_values) >= 1:
                        # è”åˆç±»å‹
                        param_key = f'union_type_{node_id}'
                        if param_key in controlnet_configs:
                            widgets_values[0] = controlnet_configs[param_key]
                    
                    modified_node['widgets_values'] = widgets_values
                
                # å¤„ç†å›¾åƒè¾“å…¥èŠ‚ç‚¹
                elif 'LoadImage' in node_type or 'ImageLoader' in node_type:
                    if str(node_id) in selected_images:
                        image_info = selected_images[str(node_id)]
                        image_path = image_info.get('path', '')
                        image_source = image_info.get('source', 'uploaded')
                        logger.info(f"LoadImageèŠ‚ç‚¹ {node_id} æœ‰é€‰æ‹©çš„å›¾åƒ: {image_path}, æ¥æº: {image_source}")
                        
                        # æ„å»ºå®Œæ•´çš„å›¾åƒè·¯å¾„
                        output_dir = os.path.join(os.path.dirname(__file__), 'outputs')
                        
                        # æ ¹æ®å›¾ç‰‡æ¥æºç¡®å®šæºæ–‡ä»¶è·¯å¾„
                        if image_source == 'uploaded':
                            # ä¸Šä¼ çš„å›¾ç‰‡åœ¨ outputs/uploaded/ ç›®å½•
                            full_image_path = os.path.join(output_dir, image_path)
                        else:
                            # ç”Ÿæˆçš„å›¾ç‰‡åœ¨ outputs/ æ ¹ç›®å½•
                            full_image_path = os.path.join(output_dir, image_path)
                        
                        if os.path.exists(full_image_path):
                            # å°†å›¾ç‰‡å¤åˆ¶åˆ°ComfyUIçš„inputç›®å½•
                            comfyui_input_dir = '/home/wjx/ComfyUI/input'
                            
                            # ç¡®ä¿ComfyUI inputç›®å½•å­˜åœ¨
                            if not os.path.exists(comfyui_input_dir):
                                logger.error(f"ComfyUI inputç›®å½•ä¸å­˜åœ¨: {comfyui_input_dir}")
                                continue
                            
                            # æ™ºèƒ½æ–‡ä»¶åç®¡ç†ï¼šé¿å…é‡å¤å¤åˆ¶ç›¸åŒæ–‡ä»¶
                            original_filename = os.path.basename(image_path)
                            name, ext = os.path.splitext(original_filename)
                            
                            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»å­˜åœ¨äºComfyUI inputç›®å½•
                            comfyui_image_path = os.path.join(comfyui_input_dir, original_filename)
                            final_filename = original_filename
                            
                            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæˆ–è€…æ–‡ä»¶å†…å®¹ä¸åŒï¼Œæ‰å¤åˆ¶
                            need_copy = True
                            if os.path.exists(comfyui_image_path):
                                # æ¯”è¾ƒæ–‡ä»¶å¤§å°å’Œä¿®æ”¹æ—¶é—´
                                source_stat = os.stat(full_image_path)
                                target_stat = os.stat(comfyui_image_path)
                                if (source_stat.st_size == target_stat.st_size and 
                                    abs(source_stat.st_mtime - target_stat.st_mtime) < 1):
                                    need_copy = False
                                    logger.info(f"æ–‡ä»¶å·²å­˜åœ¨ä¸”ç›¸åŒï¼Œè·³è¿‡å¤åˆ¶: {original_filename}")
                                else:
                                    # æ–‡ä»¶ä¸åŒï¼Œç”Ÿæˆæ–°çš„å”¯ä¸€æ–‡ä»¶å
                                    import time
                                    timestamp = int(time.time())
                                    final_filename = f"{name}_{timestamp}{ext}"
                                    comfyui_image_path = os.path.join(comfyui_input_dir, final_filename)
                            
                            if need_copy:
                                try:
                                    import shutil
                                    
                                    # å¤åˆ¶æ–‡ä»¶åˆ°ComfyUI inputç›®å½•
                                    shutil.copy2(full_image_path, comfyui_image_path)
                                    logger.info(f"å›¾ç‰‡å·²å¤åˆ¶åˆ°ComfyUI inputç›®å½•: {comfyui_image_path}")
                                    
                                except Exception as e:
                                    logger.error(f"å¤„ç†å›¾ç‰‡åˆ°ComfyUI inputç›®å½•å¤±è´¥: {e}")
                                    # å¦‚æœå¤åˆ¶å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨åŸå§‹æ–‡ä»¶å
                                    final_filename = original_filename
                            
                            # ä¿®æ”¹å›¾åƒè·¯å¾„ - UIæ ¼å¼ä¸­widgets_valuesåŒ…å«å›¾åƒæ–‡ä»¶å
                            widgets_values = modified_node.get('widgets_values', [])
                            if len(widgets_values) > 0:
                                widgets_values[0] = final_filename
                                modified_node['widgets_values'] = widgets_values
                                logger.info(f"è®¾ç½®LoadImageå›¾åƒè¾“å…¥ {node_id}: {final_filename}")
                        else:
                            logger.warning(f"LoadImageå›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}")
                    # è‡ªåŠ¨æ‰©å›¾æ©ç ï¼šè‹¥å¼€å¯ã€ä¸”è¯¥èŠ‚ç‚¹è¾“å‡ºæœ‰ MASK ä¸”æœªæä¾›æ©ç ï¼Œåˆ™è®°å½•åŸå›¾å°ºå¯¸ç”¨äºåç»­ç”Ÿæˆæ©ç 
                    try:
                        if auto_outpaint_mask and any(o.get('type') == 'MASK' for o in (node.get('outputs') or [])):
                            # è¯»å–åŸå›¾å°ºå¯¸
                            img_path = None
                            wv = modified_node.get('widgets_values', [])
                            if wv and isinstance(wv[0], str):
                                img_path = wv[0].replace(' [input]', '')
                            if img_path:
                                input_dir = '/home/wjx/ComfyUI/input'
                                abs_img = os.path.join(input_dir, os.path.basename(img_path))
                                if os.path.exists(abs_img) and Image is not None:
                                    with Image.open(abs_img) as im:
                                        orig_w, orig_h = im.size
                                    # è‹¥ç›®æ ‡å°ºå¯¸æ›´å¤§ä¸”æœªæ˜¾å¼æä¾›æ©ç ï¼Œåˆ™æ ‡è®°éœ€è¦è‡ªåŠ¨ç”Ÿæˆ
                                    modified_node.setdefault('_auto_mask_meta', {})
                                    modified_node['_auto_mask_meta']['orig_w'] = orig_w
                                    modified_node['_auto_mask_meta']['orig_h'] = orig_h
                    except Exception as _e:
                        logger.debug(f"è‡ªåŠ¨æ‰©å›¾æ©ç å°ºå¯¸é¢„è¯»å¤±è´¥: {_e}")
                    else:
                        # æœªä¸ºè¯¥ LoadImage èŠ‚ç‚¹æ˜¾å¼æä¾›å›¾ç‰‡ï¼Œå°è¯•ä½¿ç”¨ä»»æ„å¯ç”¨çš„å·²é€‰å›¾ç‰‡ä½œä¸ºå…œåº•
                        fallback_info = None
                        # ä»…åœ¨â€œå…¨å±€å®Œå…¨æœªé€‰æ‹©ä»»ä½•å›¾ç‰‡â€æ—¶ï¼Œæ‰å¯ç”¨å…œåº•ï¼Œé¿å…è¯¯ç”¨
                        if isinstance(selected_images, dict) and len(selected_images) == 0:
                            try:
                                fallback_key = next(iter(selected_images.keys()))
                                fallback_info = selected_images.get(fallback_key)
                            except Exception:
                                fallback_info = None
                        if fallback_info:
                            fb_path = fallback_info.get('path', '')
                            fb_source = fallback_info.get('source', 'uploaded')
                            logger.info(f"LoadImageèŠ‚ç‚¹ {node_id} æ— æ˜¾å¼è¾“å…¥ï¼Œå›é€€ä½¿ç”¨å·²é€‰å›¾ç‰‡: {fb_path} (æ¥æº: {fb_source})")
                            output_dir = os.path.join(os.path.dirname(__file__), 'outputs')
                            full_image_path = os.path.join(output_dir, fb_path)
                            if os.path.exists(full_image_path):
                                comfyui_input_dir = '/home/wjx/ComfyUI/input'
                                if os.path.exists(comfyui_input_dir):
                                    try:
                                        import shutil, time
                                        original_filename = os.path.basename(fb_path)
                                        name, ext = os.path.splitext(original_filename)
                                        comfyui_image_path = os.path.join(comfyui_input_dir, original_filename)
                                        final_filename = original_filename
                                        need_copy = True
                                        if os.path.exists(comfyui_image_path):
                                            source_stat = os.stat(full_image_path)
                                            target_stat = os.stat(comfyui_image_path)
                                            if (source_stat.st_size == target_stat.st_size and 
                                                abs(source_stat.st_mtime - target_stat.st_mtime) < 1):
                                                need_copy = False
                                            else:
                                                ts = int(time.time())
                                                final_filename = f"{name}_{ts}{ext}"
                                                comfyui_image_path = os.path.join(comfyui_input_dir, final_filename)
                                        if need_copy:
                                            shutil.copy2(full_image_path, comfyui_image_path)
                                        widgets_values = modified_node.get('widgets_values', [])
                                        if len(widgets_values) > 0:
                                            widgets_values[0] = final_filename
                                            modified_node['widgets_values'] = widgets_values
                                            logger.info(f"å…œåº•è®¾ç½®LoadImageå›¾åƒè¾“å…¥ {node_id}: {final_filename}")
                                    except Exception as e:
                                        logger.error(f"LoadImageå…œåº•è®¾ç½®å¤±è´¥: {e}")
                                else:
                                    logger.error(f"ComfyUI inputç›®å½•ä¸å­˜åœ¨: {comfyui_input_dir}")
                            else:
                                logger.warning(f"LoadImageå…œåº•æ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}")
                        else:
                            # é¡¶éƒ¨ç»Ÿä¸€è¦†ç›–ï¼šè‹¥æ— æ˜¾å¼é€‰æ‹©ï¼Œåˆ™ä¿æŒåŸæœ‰ widgetsï¼Œä¸å†ç”Ÿæˆå…œåº•ï¼Œé¿å…è¯¯è¿
                            logger.info(f"LoadImage èŠ‚ç‚¹ {node_id} æœªé€‰æ‹©å›¾ç‰‡ï¼Œä¿æŒåŸé…ç½®")
                
                # å¤„ç†LoadImageOutputèŠ‚ç‚¹ï¼ˆKontextå·¥ä½œæµä¸­çš„å›¾åƒè¾“å…¥ï¼‰
                elif 'LoadImageOutput' in node_type:
                    logger.info(f"å¤„ç†LoadImageOutputèŠ‚ç‚¹ {node_id}ï¼Œselected_images: {selected_images}")
                    if str(node_id) in selected_images:
                        image_info = selected_images[str(node_id)]
                        image_path = image_info.get('path', '')
                        image_source = image_info.get('source', 'uploaded')
                        logger.info(f"LoadImageOutputèŠ‚ç‚¹ {node_id} æœ‰é€‰æ‹©çš„å›¾åƒ: {image_path}, æ¥æº: {image_source}")
                        
                        # æ„å»ºå®Œæ•´çš„å›¾åƒè·¯å¾„
                        output_dir = os.path.join(os.path.dirname(__file__), 'outputs')
                        
                        # æ ¹æ®å›¾ç‰‡æ¥æºç¡®å®šæºæ–‡ä»¶è·¯å¾„
                        if image_source == 'uploaded':
                            # ä¸Šä¼ çš„å›¾ç‰‡åœ¨ outputs/uploaded/ ç›®å½•
                            full_image_path = os.path.join(output_dir, image_path)
                        else:
                            # ç”Ÿæˆçš„å›¾ç‰‡åœ¨ outputs/ æ ¹ç›®å½•
                            full_image_path = os.path.join(output_dir, image_path)
                        
                        if os.path.exists(full_image_path):
                            # å°†å›¾ç‰‡å¤åˆ¶åˆ°ComfyUIçš„inputç›®å½•ï¼ˆæ™ºèƒ½å¤åˆ¶ï¼‰
                            comfyui_input_dir = '/home/wjx/ComfyUI/input'
                            
                            # ç¡®ä¿ComfyUI inputç›®å½•å­˜åœ¨
                            if not os.path.exists(comfyui_input_dir):
                                logger.error(f"ComfyUI inputç›®å½•ä¸å­˜åœ¨: {comfyui_input_dir}")
                                continue
                            
                            # æ™ºèƒ½æ–‡ä»¶åç®¡ç†ï¼šé¿å…é‡å¤å¤åˆ¶ç›¸åŒæ–‡ä»¶
                            original_filename = os.path.basename(image_path)
                            name, ext = os.path.splitext(original_filename)
                            
                            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»å­˜åœ¨äºComfyUI inputç›®å½•
                            comfyui_image_path = os.path.join(comfyui_input_dir, original_filename)
                            final_filename = original_filename
                            
                            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæˆ–è€…æ–‡ä»¶å†…å®¹ä¸åŒï¼Œæ‰å¤åˆ¶
                            need_copy = True
                            if os.path.exists(comfyui_image_path):
                                # æ¯”è¾ƒæ–‡ä»¶å¤§å°å’Œä¿®æ”¹æ—¶é—´
                                source_stat = os.stat(full_image_path)
                                target_stat = os.stat(comfyui_image_path)
                                if (source_stat.st_size == target_stat.st_size and 
                                    abs(source_stat.st_mtime - target_stat.st_mtime) < 1):
                                    need_copy = False
                                    logger.info(f"æ–‡ä»¶å·²å­˜åœ¨ä¸”ç›¸åŒï¼Œè·³è¿‡å¤åˆ¶: {original_filename}")
                                else:
                                    # æ–‡ä»¶ä¸åŒï¼Œç”Ÿæˆæ–°çš„å”¯ä¸€æ–‡ä»¶å
                                    import time
                                    timestamp = int(time.time())
                                    final_filename = f"{name}_{timestamp}{ext}"
                                    comfyui_image_path = os.path.join(comfyui_input_dir, final_filename)
                            
                            if need_copy:
                                try:
                                    import shutil
                                    
                                    # å¤åˆ¶æ–‡ä»¶åˆ°ComfyUI inputç›®å½•
                                    shutil.copy2(full_image_path, comfyui_image_path)
                                    logger.info(f"å›¾ç‰‡å·²å¤åˆ¶åˆ°ComfyUI inputç›®å½•: {comfyui_image_path}")
                                    
                                except Exception as e:
                                    logger.error(f"å¤„ç†å›¾ç‰‡åˆ°ComfyUI inputç›®å½•å¤±è´¥: {e}")
                                    # å¦‚æœå¤åˆ¶å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨åŸå§‹æ–‡ä»¶å
                                    final_filename = original_filename
                            
                            # ä¿®æ”¹å›¾åƒè·¯å¾„ - UIæ ¼å¼ä¸­widgets_valuesåŒ…å«å›¾åƒæ–‡ä»¶å
                            widgets_values = modified_node.get('widgets_values', [])
                            if len(widgets_values) > 0:
                                # ä½¿ç”¨å¸¦æœ‰ [input] æ ‡è®°çš„æ–‡ä»¶å
                                widgets_values[0] = f"{final_filename} [input]"
                                modified_node['widgets_values'] = widgets_values
                                logger.info(f"è®¾ç½®LoadImageOutputå›¾åƒè¾“å…¥ {node_id}: {final_filename} [input]")
                        else:
                            logger.warning(f"LoadImageOutputå›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}")
                    else:
                            # é¡¶éƒ¨ç»Ÿä¸€è¦†ç›–ï¼šæœªé€‰æ‹©åˆ™ä¿æŒï¼Œä¸å†å¼ºåˆ¤å¿…éœ€/ç¦ç”¨ï¼Œäº¤ç”±ç”¨æˆ·åœ¨é¡¶å±‚é€‰æ‹©
                            logger.info(f"LoadImageOutput èŠ‚ç‚¹ {node_id} æœªé€‰æ‹©å›¾ç‰‡ï¼Œä¿æŒåŸé…ç½®")

                # é€šç”¨èŠ‚ç‚¹å‚æ•°æ³¨å…¥ï¼ˆå…œåº•ï¼‰ï¼šæ¥è‡ªå‰ç«¯ node_generic_params çš„é”® "nodeId:widgetIndex"
                try:
                    generic_params = parameters.get('node_generic_params') or {}
                    if isinstance(generic_params, dict):
                        wv = modified_node.get('widgets_values', [])
                        if not isinstance(wv, list):
                            wv = []
                        for key, val in generic_params.items():
                            try:
                                nid_str, idx_str = str(key).split(':', 1)
                            except ValueError:
                                continue
                            if str(nid_str) != str(node_id):
                                continue
                            try:
                                idx = int(idx_str)
                            except Exception:
                                continue
                            # æ‰©å®¹åˆ°å¯å†™å…¥ä½ç½®
                            if idx >= 0 and idx >= len(wv):
                                wv.extend([None] * (idx + 1 - len(wv)))
                            if idx >= 0:
                                orig = wv[idx]
                                new_val = val
                                # ç±»å‹æ„ŸçŸ¥è½¬æ¢ï¼ˆè‹¥æœ‰åŸå€¼åˆ™æŒ‰åŸå€¼ç±»å‹è½¬æ¢ï¼‰
                                try:
                                    if isinstance(orig, bool):
                                        new_val = (str(val).lower() in ('1','true','yes','on')) if isinstance(val, str) else bool(val)
                                    elif isinstance(orig, int):
                                        new_val = int(float(val))
                                    elif isinstance(orig, float):
                                        new_val = float(val)
                                except Exception:
                                    pass
                                wv[idx] = new_val
                        modified_node['widgets_values'] = wv
                except Exception as _e:
                    logger.debug(f"é€šç”¨å‚æ•°æ³¨å…¥å¤±è´¥ node#{node_id}: {_e}")

                modified_nodes.append(modified_node)
            
            # è‡ªåŠ¨æ‰©å›¾æ©ç ï¼šä»…åœ¨Fillç±»å‹ï¼ˆæ— ImagePadForOutpaintï¼‰å·¥ä½œæµå¯ç”¨
            if (auto_outpaint_mask or mask_image_from_editor) and Image is not None and not has_outpaint_node:
                try:
                    # æŸ¥æ‰¾ LoadImage èŠ‚ç‚¹ï¼ˆå¸¦ _auto_mask_metaï¼‰ä¸ Resize èŠ‚ç‚¹åŠå…¶ mask è¾“å…¥é“¾æ¥
                    resize_node = next((n for n in modified_nodes if 'ImageAndMaskResizeNode' in n.get('type','')), None)
                    load_node = next((n for n in modified_nodes if n.get('_auto_mask_meta')), None)
                    links = workflow_data.get('links', [])
                    if resize_node and load_node and isinstance(links, list):
                        meta = load_node['_auto_mask_meta']
                        orig_w, orig_h = meta.get('orig_w'), meta.get('orig_h')
                        # æ˜¯å¦éœ€è¦åˆ›å»º/æ›¿æ¢é®ç½©èŠ‚ç‚¹ï¼š
                        need_mask_node = bool(mask_image_from_editor) or (
                            orig_w and orig_h and target_width and target_height and (target_width > orig_w or target_height > orig_h)
                        )
                        if need_mask_node:
                            input_dir = '/home/wjx/ComfyUI/input'
                            os.makedirs(input_dir, exist_ok=True)
                            if mask_image_from_editor:
                                # å°†ç¼–è¾‘å™¨é®ç½©å¤åˆ¶åˆ° ComfyUI/input
                                try:
                                    # å‰ç«¯ä¸Šä¼ åˆ° outputs/uploaded/xxxï¼Œæ‰€ä»¥è¿™é‡Œéœ€è¦è§£æ path
                                    rel_path = mask_image_from_editor.replace(' [input]', '')
                                    if rel_path.startswith('masks/'):
                                        src_mask = os.path.join(os.path.dirname(__file__), 'outputs', rel_path)
                                    elif rel_path.startswith('uploaded/'):
                                        src_mask = os.path.join(os.path.dirname(__file__), 'outputs', rel_path)
                                    else:
                                        src_mask = os.path.join(os.path.dirname(__file__), 'outputs', mask_image_from_editor)
                                    mask_filename = os.path.basename(src_mask)
                                    abs_mask = os.path.join(input_dir, mask_filename)
                                    import shutil
                                    if os.path.exists(src_mask) and os.path.abspath(src_mask) != os.path.abspath(abs_mask):
                                        shutil.copy2(src_mask, abs_mask)
                                except Exception as _e:
                                    logger.debug(f"å¤åˆ¶é®ç½©åˆ°è¾“å…¥ç›®å½•å¤±è´¥: {_e}")
                            else:
                                # è‡ªåŠ¨ç”Ÿæˆæ‰©å›¾é®ç½©
                                # ç”Ÿæˆæ©ç å›¾ç‰‡ï¼ˆRGBA Alphaï¼‰ï¼š
                                #  - å¤–åœˆï¼šalpha=0ï¼ˆé€æ˜ â†’ éœ€è¦é‡å»ºï¼‰
                                #  - åŸå›¾åŒºåŸŸï¼šalpha=255ï¼ˆä¸é€æ˜ â†’ ä¿ç•™ï¼‰
                                offset_x = (target_width - orig_w) // 2
                                offset_y = (target_height - orig_h) // 2
                                mask_rgba = Image.new('RGBA', (target_width, target_height), color=(0, 0, 0, 0))
                                draw = ImageDraw.Draw(mask_rgba)
                                draw.rectangle([offset_x, offset_y, offset_x + orig_w - 1, offset_y + orig_h - 1], fill=(0, 0, 0, 255))
                                try:
                                    blur_param = 24
                                    try:
                                        if isinstance(parameters.get('mask_blur_radius'), (int, float)):
                                            blur_param = max(0, min(int(parameters.get('mask_blur_radius')), 128))
                                    except Exception:
                                        pass
                                    alpha = mask_rgba.split()[-1]
                                    alpha = alpha.filter(ImageFilter.GaussianBlur(radius=max(6, blur_param // 2)))
                                    mask_rgba.putalpha(alpha)
                                except Exception:
                                    pass
                                mask_filename = f"auto_outpaint_mask_{target_width}x{target_height}.png"
                                abs_mask = os.path.join(input_dir, mask_filename)
                                mask_rgba.save(abs_mask)

                            # ç”Ÿæˆé¢„å¡«å……ï¼ˆpadï¼‰åçš„ç›®æ ‡å°ºå¯¸å›¾åƒï¼Œé¿å…è¢« Resize èŠ‚ç‚¹è£å‰ª
                            try:
                                # è¯»å–å½“å‰ LoadImage ä½¿ç”¨çš„æºæ–‡ä»¶å
                                wv = load_node.get('widgets_values', [])
                                src_name = None
                                if wv and isinstance(wv[0], str):
                                    src_name = wv[0].replace(' [input]', '')
                                if src_name:
                                    abs_src = os.path.join(input_dir, os.path.basename(src_name))
                                    if os.path.exists(abs_src):
                                        with Image.open(abs_src) as simg:
                                            # å»ºç«‹ä¸åŸå›¾ç›¸åŒmodeçš„ç”»å¸ƒï¼›è‹¥éRGBåˆ™è½¬RGB
                                            base_mode = 'RGB'
                                            try:
                                                if simg.mode in ['RGB', 'RGBA']:
                                                    base_mode = 'RGB'
                                                else:
                                                    base_mode = 'RGB'
                                            except Exception:
                                                base_mode = 'RGB'
                                            # ç”Ÿæˆæ›´è‡ªç„¶çš„é¢„å¡«å……åº•å›¾ï¼šå°†åŸå›¾ç¼©æ”¾åˆ°ç›®æ ‡å°ºå¯¸å¹¶é«˜æ–¯æ¨¡ç³Šï¼Œå†å±…ä¸­ç²˜è´´åŸå›¾
                                            if simg.mode not in ['RGB']:
                                                simg = simg.convert('RGB')
                                            # èƒŒæ™¯ï¼šç¼©æ”¾+æ¨¡ç³Šï¼ŒåŠå¾„å¯åŸºäº mask_blur_radius æ”¾å¤§
                                            blur_bg_radius = 24
                                            try:
                                                if isinstance(parameters.get('mask_blur_radius'), (int, float)):
                                                    blur_bg_radius = max(8, min(int(parameters.get('mask_blur_radius')) * 2, 96))
                                            except Exception:
                                                pass
                                            blurred_bg = simg.resize((target_width, target_height), Image.LANCZOS).filter(ImageFilter.GaussianBlur(radius=blur_bg_radius))
                                            canvas = blurred_bg.copy()
                                            # ä»¥ç¾½åŒ–é®ç½©è´´å›åŸå›¾ï¼Œè¿›ä¸€æ­¥è½¯åŒ–ç²˜è´´è¾¹ç•Œ
                                            feather = max(6, min(64, int((parameters.get('mask_blur_radius') or 24))))
                                            placement_mask_full = Image.new('L', (target_width, target_height), color=0)
                                            pm_draw = ImageDraw.Draw(placement_mask_full)
                                            pm_draw.rectangle([offset_x, offset_y, offset_x + orig_w - 1, offset_y + orig_h - 1], fill=255)
                                            placement_mask_full = placement_mask_full.filter(ImageFilter.GaussianBlur(radius=feather))
                                            placement_mask = placement_mask_full.crop((offset_x, offset_y, offset_x + orig_w, offset_y + orig_h))
                                            canvas.paste(simg, (offset_x, offset_y), placement_mask)
                                            padded_filename = f"auto_outpaint_image_{target_width}x{target_height}_" + os.path.basename(src_name)
                                            abs_padded = os.path.join(input_dir, padded_filename)
                                            canvas.save(abs_padded)
                                            # è¦†ç›– LoadImage çš„å›¾åƒè¾“å…¥ä¸ºé¢„å¡«å……åçš„æ–°å›¾ï¼ˆå¸¦ [input] åç¼€ï¼‰
                                            load_node['widgets_values'][0] = f"{padded_filename} [input]"
                                            logger.info(f"å·²ç”Ÿæˆå¹¶ä½¿ç”¨é¢„å¡«å……å›¾åƒ: {padded_filename}")
                            except Exception as _pe:
                                logger.debug(f"è‡ªåŠ¨ç”Ÿæˆé¢„å¡«å……å›¾åƒå¤±è´¥: {_pe}")

                            # åŠ¨æ€åˆ›å»ºä¸€ä¸ª LoadImage èŠ‚ç‚¹åŠ è½½è¯¥æ©ç ï¼ˆä»…è¾“å‡º MASKï¼‰
                            new_node_id = max(int(n.get('id', 0)) for n in modified_nodes) + 1
                            mask_node = {
                                'id': new_node_id,
                                'type': 'LoadImage',
                                'pos': [resize_node.get('pos', [0,0])[0] - 200, resize_node.get('pos', [0,0])[1] + 100],
                                'size': [300, 100],
                                'flags': {},
                                'order': resize_node.get('order', 0),
                                'mode': 0,
                                'inputs': [
                                    { 'localized_name': 'image', 'name': 'image', 'type': 'COMBO', 'widget': { 'name': 'image' }, 'link': None },
                                    { 'localized_name': 'choose file to upload', 'name': 'upload', 'type': 'IMAGEUPLOAD', 'widget': { 'name': 'upload' }, 'link': None }
                                ],
                                'outputs': [
                                    { 'localized_name': 'IMAGE', 'name': 'IMAGE', 'type': 'IMAGE', 'slot_index': 0, 'links': [] },
                                    { 'localized_name': 'MASK', 'name': 'MASK', 'type': 'MASK', 'slot_index': 1, 'links': [] }
                                ],
                                'properties': { 'Node name for S&R': 'LoadImage', 'cnr_id': 'comfy-core', 'ver': '0.3.27' },
                                'widgets_values': [ f"{os.path.basename(abs_mask)} [input]", 'image' ]
                            }
                            modified_nodes.append(mask_node)

                            # é‡è¿ï¼šå°† Resize çš„ mask è¾“å…¥è¿åˆ°æ–°èŠ‚ç‚¹çš„ MASK è¾“å‡ºï¼›
                            # åŒæ—¶å°† InpaintModelConditioning çš„ pixels è¾“å…¥æ”¹ä¸ºä½¿ç”¨ Resize åçš„å›¾åƒï¼Œç¡®ä¿æ©ç ç”Ÿæ•ˆ
                            # æ‰¾åˆ° Resize çš„ mask è¾“å…¥æ§½ä½ç´¢å¼•
                            resize_inputs = resize_node.get('inputs', [])
                            mask_slot_index = None
                            for idx, inp in enumerate(resize_inputs):
                                if inp.get('name') == 'mask':
                                    mask_slot_index = idx
                                    break
                            if mask_slot_index is not None:
                                # ç§»é™¤åŸæœ‰æŒ‡å‘è¯¥ mask è¾“å…¥æ§½ä½çš„æ—§é“¾æ¥ï¼Œé¿å…åŒé“¾æ¥å†²çª
                                try:
                                    old_links = []
                                    for li in range(len(links)):
                                        if len(links[li]) >= 6:
                                            link_id, src_id, src_slot, dst_id, dst_slot, ltype = links[li]
                                            if str(dst_id) == str(resize_node.get('id')) and dst_slot == mask_slot_index:
                                                old_links.append(links[li])
                                    for ol in old_links:
                                        links.remove(ol)
                                except Exception:
                                    pass
                                # æ„é€ æ–° linkï¼ˆä½¿ç”¨æ–°çš„å”¯ä¸€ link idï¼‰
                                new_link_id = max(l[0] for l in links) + 1 if links else 1000
                                links.append([new_link_id, new_node_id, 1, resize_node.get('id'), mask_slot_index, 'MASK'])
                                # æ›´æ–°èŠ‚ç‚¹æœ¬ä½“çš„ inputs/outputs é“¾æ¥æ•°ç»„
                                resize_node_inputs = resize_node.get('inputs', [])
                                if 0 <= mask_slot_index < len(resize_node_inputs):
                                    resize_node_inputs[mask_slot_index]['link'] = new_link_id
                                mask_node['outputs'][1]['links'].append(new_link_id)

                            # ç¡®ä¿ InpaintModelConditioning çš„ pixels æ¥è‡ª Resize è¾“å‡ºï¼ˆè€ŒéåŸå›¾ï¼‰
                            try:
                                inpaint_node = next((n for n in modified_nodes if 'InpaintModelConditioning' in n.get('type','')), None)
                                if inpaint_node is not None:
                                    # æ‰¾åˆ° Resize çš„ image è¾“å‡º link id
                                    resize_outputs = resize_node.get('outputs', [])
                                    image_out_link = None
                                    if resize_outputs and resize_outputs[0].get('links'):
                                        # ä½¿ç”¨ç¬¬ä¸€ä¸ª image è¾“å‡ºé“¾æ¥ id
                                        image_out_link = resize_outputs[0]['links'][0]
                                    if image_out_link is not None:
                                        # æ›´æ–° links ä¸­æŒ‡å‘ Inpaint.pixels çš„é“¾æ¥ä¸ºæ¥è‡ª Resize çš„è¾“å‡º
                                        # å…ˆæ‰¾åˆ° Inpaint.pixels è¾“å…¥æ§½ä½ç´¢å¼•
                                        pixels_slot = None
                                        for idx, inp in enumerate(inpaint_node.get('inputs', []) or []):
                                            if inp.get('name') == 'pixels':
                                                pixels_slot = idx
                                                break
                                        if pixels_slot is not None:
                                            # æ›¿æ¢ links é‡Œ dst=Inpaint, dst_slot=pixels_slot çš„æ¡ç›®ï¼ˆæˆ–æ–°å¢ï¼‰
                                            replaced = False
                                            for li in range(len(links)):
                                                if len(links[li]) >= 6:
                                                    _, src_id, src_slot, dst_id, dst_slot, _t = links[li]
                                                    if str(dst_id) == str(inpaint_node.get('id')) and dst_slot == pixels_slot:
                                                        # æ›¿æ¢ä¸ºæ¥è‡ª Resize çš„è¾“å‡ºï¼ˆéœ€è¦æ‰¾åˆ° Resize çš„ node_id ä¸å¯¹åº”è¾“å‡ºslot=0ï¼‰
                                                        links[li] = [links[li][0], resize_node.get('id'), 0, inpaint_node.get('id'), pixels_slot, 'IMAGE']
                                                        replaced = True
                                                        break
                                            if not replaced:
                                                # æ–°å¢ä¸€ä¸ª link id
                                                new_link2 = (max(l[0] for l in links) + 1) if links else 1001
                                                links.append([new_link2, resize_node.get('id'), 0, inpaint_node.get('id'), pixels_slot, 'IMAGE'])
                            except Exception as _re:
                                logger.debug(f"ä¿®æ­£ Inpaint pixels é“¾æ¥å¤±è´¥: {_re}")

                            # å†™å› links åˆ°å·¥ä½œæµ
                            workflow_data['links'] = links
                except Exception as e:
                    logger.error(f"è‡ªåŠ¨æ‰©å›¾æ©ç ç”Ÿæˆå¤±è´¥: {e}")

            # è¿”å›ä¿®æ”¹åçš„å·¥ä½œæµ
            modified_workflow = workflow_data.copy()
            modified_workflow['nodes'] = modified_nodes
            
            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            modified_params = []
            for param_name, param_value in parameters.items():
                if param_value and str(param_value).strip():
                    modified_params.append(f"{param_name}: {param_value}")
            
            if modified_params:
                logger.info(f"å·¥ä½œæµå‚æ•°ä¿®æ”¹å®Œæˆ: {modified_params}")
            
            return modified_workflow
            
        except Exception as e:
            logger.error(f"ä¿®æ”¹å·¥ä½œæµå‚æ•°å¤±è´¥: {e}")
            # å¦‚æœä¿®æ”¹å¤±è´¥ï¼Œè¿”å›åŸå§‹å·¥ä½œæµ
            return workflow_data
    
    def convert_ui_to_api_format(self, ui_workflow):
        """å°†UIæ ¼å¼çš„workflowè½¬æ¢ä¸ºAPIæ ¼å¼"""
        try:
            # ä½¿ç”¨ä½ æä¾›çš„åŸå§‹è½¬æ¢é€»è¾‘
            api_prompt = {}
            nodes_by_id = {str(n['id']): n for n in ui_workflow.get('nodes', [])}
            primitive_values = {nid: n['widgets_values'][0] for nid, n in nodes_by_id.items() if n.get('type') == 'PrimitiveNode' and n.get('widgets_values')}
            NODE_TYPES_TO_IGNORE = ["PrimitiveNode", "Note", "MarkdownNote"]
            
            # è®°å½•è¢«è·³è¿‡çš„LoadImageOutputèŠ‚ç‚¹
            skipped_loadimage_nodes = set()

            for node_id, node in nodes_by_id.items():
                if node.get('type') in NODE_TYPES_TO_IGNORE: continue
                node_type = node.get('type')
                
                # LoadImageOutputèŠ‚ç‚¹ç‰¹æ®Šå¤„ç†ï¼šæ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡æ•´ä¸ªèŠ‚ç‚¹
                if node_type == 'LoadImageOutput':
                    node_mode = node.get('mode', 0)
                    is_disabled = node_mode == 4
                    
                    if is_disabled:
                        # å¯é€‰èŠ‚ç‚¹è¢«ç¦ç”¨ï¼Œè·³è¿‡è¯¥èŠ‚ç‚¹
                        logger.info(f"å¯é€‰LoadImageOutputèŠ‚ç‚¹ {node_id} è¢«ç¦ç”¨ï¼Œè·³è¿‡è¯¥èŠ‚ç‚¹")
                        skipped_loadimage_nodes.add(str(node_id))
                        continue  # è·³è¿‡è¿™ä¸ªèŠ‚ç‚¹ï¼Œä¸æ·»åŠ åˆ°API workflowä¸­
                
                api_node = {"class_type": node_type, "inputs": {}}
                
                # å¤„ç†widgets_values
                if node_type in WIDGET_INDEX_MAP and 'widgets_values' in node:
                    for w_name, w_idx in WIDGET_INDEX_MAP[node_type].items():
                        if w_idx >= 0 and len(node['widgets_values']) > w_idx:
                            value = node['widgets_values'][w_idx]
                            # æ¸…ç†æ¨¡å‹åç§°ä¸­çš„çŠ¶æ€æ ‡è®°
                            if isinstance(value, str):
                                cleaned_value = value.replace(' âœ…', '').replace(' âŒ (æ–‡ä»¶ä¸å­˜åœ¨)', '')
                                # ä¿®æ­£æ–‡ä»¶åä¸åŒ¹é…é—®é¢˜
                                if cleaned_value == 'flux1-turbo-alpha.safetensors':
                                    cleaned_value = 'flux.1-turbo-alpha.safetensors'
                                # LoadImageOutputèŠ‚ç‚¹ç‰¹æ®Šå¤„ç†
                                if node_type == 'LoadImageOutput':
                                    # ç›´æ¥å†™å…¥å›¾åƒè·¯å¾„ï¼Œè®©ComfyUIå¤„ç†
                                    api_node['inputs'][w_name] = cleaned_value
                                else:
                                    api_node['inputs'][w_name] = cleaned_value
                            else:
                                api_node['inputs'][w_name] = value
                    # å…œåº•ï¼šå¯¹ CLIPVisionEncode å’Œ StyleModelApply å¡«å……é»˜è®¤å€¼ï¼ˆè‹¥æœªåœ¨ widgets_values ä¸­å–åˆ°ï¼‰
                    if node_type == 'CLIPVisionEncode':
                        api_node['inputs'].setdefault('crop', 'center')
                    if node_type == 'StyleModelApply':
                        api_node['inputs'].setdefault('strength', 1.0)
                        api_node['inputs'].setdefault('strength_type', 'multiply')
                    if node_type == 'InpaintModelConditioning':
                        # å…œåº•ï¼šè‹¥æœªä» widgets è¯»å–åˆ°ï¼Œé»˜è®¤ false
                        api_node['inputs'].setdefault('noise_mask', False)
                    
                    # æ·»åŠ è°ƒè¯•æ—¥å¿—
                    if node_type in ['CLIPTextEncode', 'RandomNoise', 'FluxGuidance', 'BasicScheduler']:
                        logger.info(f"èŠ‚ç‚¹ {node_id} ({node_type}) è½¬æ¢ç»“æœ: {api_node['inputs']}")
                    
                    # ç‰¹åˆ«è°ƒè¯•LoadImageOutputèŠ‚ç‚¹
                    if node_type == 'LoadImageOutput':
                        logger.info(f"LoadImageOutputèŠ‚ç‚¹ {node_id} widgets_values: {node.get('widgets_values', [])}")
                        logger.info(f"LoadImageOutputèŠ‚ç‚¹ {node_id} è½¬æ¢ç»“æœ: {api_node['inputs']}")
                
                # å¤„ç†inputsè¿æ¥
                if 'inputs' in node:
                    for i, input_data in enumerate(node['inputs']):
                        if input_data.get('link') is not None:
                            for link in ui_workflow.get('links', []):
                                # æ”¯æŒæ–°æ ¼å¼ï¼šlinks = [link_id, src_node_id, src_slot, dst_node_id, dst_slot, type]
                                # æ”¯æŒæ—§æ ¼å¼ï¼šlinks = [link_id, src_node_id, src_slot, dst_node_id]
                                if len(link) >= 4:
                                    if len(link) == 6:  # æ–°æ ¼å¼
                                        link_id, src_id, src_slot, dst_id, dst_slot, link_type = link
                                        if str(dst_id) == node_id and dst_slot == i:
                                            # æ£€æŸ¥æºèŠ‚ç‚¹æ˜¯å¦è¢«è·³è¿‡
                                            if str(src_id) in skipped_loadimage_nodes:
                                                logger.info(f"è·³è¿‡æ¥è‡ªè¢«ç¦ç”¨èŠ‚ç‚¹ {src_id} çš„è¿æ¥åˆ°èŠ‚ç‚¹ {node_id}")
                                                continue
                                            
                                            in_name = input_data['name']
                                            api_node['inputs'][in_name] = primitive_values.get(str(src_id), [str(src_id), src_slot])
                                            break
                                    else:  # æ—§æ ¼å¼
                                        link_id, src_id, src_slot, dst_id = link
                                        if str(dst_id) == node_id and i == 0:  # æ—§æ ¼å¼å‡è®¾dst_slotä¸º0
                                            # æ£€æŸ¥æºèŠ‚ç‚¹æ˜¯å¦è¢«è·³è¿‡
                                            if str(src_id) in skipped_loadimage_nodes:
                                                logger.info(f"è·³è¿‡æ¥è‡ªè¢«ç¦ç”¨èŠ‚ç‚¹ {src_id} çš„è¿æ¥åˆ°èŠ‚ç‚¹ {node_id}")
                                                continue
                                            
                                            in_name = input_data['name']
                                            api_node['inputs'][in_name] = primitive_values.get(str(src_id), [str(src_id), src_slot])
                                            break
                api_prompt[node_id] = api_node
            
            api_workflow = {
                'prompt': api_prompt,
                'extra_data': {
                    'extra_pnginfo': {
                        'workflow': ui_workflow
                    }
                }
            }
            
            return api_workflow
            
        except Exception as e:
            logger.error(f"è½¬æ¢UIæ ¼å¼åˆ°APIæ ¼å¼å¤±è´¥: {e}")
            return None
    
    def _monitor_workflow_progress(self, task_id, prompt_id, client_id):
        """ç›‘æ§workflowæ‰§è¡Œè¿›åº¦"""
        def monitor():
            try:
                last_progress = 0
                while True:
                    time.sleep(1)  # æ¯1ç§’æ£€æŸ¥ä¸€æ¬¡ï¼Œæé«˜å“åº”é€Ÿåº¦
                    
                    if task_id not in running_tasks:
                        break
                    
                    # æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
                    try:
                        queue_response = requests.get(f"{COMFYUI_API_URL}/queue", timeout=10)
                        if queue_response.status_code == 200:
                            queue_data = queue_response.json()
                            
                            # æ£€æŸ¥æ˜¯å¦åœ¨æ‰§è¡Œé˜Ÿåˆ—ä¸­
                            running_queue = queue_data.get('queue_running', [])
                            pending_queue = queue_data.get('queue_pending', [])
                            
                            found_in_running = any(item[1] == prompt_id for item in running_queue)
                            found_in_pending = any(item[1] == prompt_id for item in pending_queue)
                            
                            if found_in_running:
                                # ä»»åŠ¡æ­£åœ¨æ‰§è¡Œä¸­ï¼Œè·å–æ›´è¯¦ç»†çš„è¿›åº¦ä¿¡æ¯
                                progress = self._get_detailed_progress(task_id, prompt_id, client_id)
                                current_label = running_tasks[task_id].get('current_node_label')
                                status_msg = f"æ­£åœ¨æ‰§è¡Œ: {current_label}" if current_label else 'æ­£åœ¨æ‰§è¡Œå·¥ä½œæµ...'
                                running_tasks[task_id].update({
                                    'status': 'running',
                                    'progress': progress,
                                    'message': status_msg
                                })
                            elif found_in_pending:
                                # è®¡ç®—æ’é˜Ÿä½ç½®
                                queue_position = self._get_queue_position(prompt_id, pending_queue)
                                progress = max(5, min(15, 15 - queue_position * 2))  # æ’é˜Ÿæ—¶æ˜¾ç¤º5-15%çš„è¿›åº¦
                                running_tasks[task_id].update({
                                    'status': 'pending',
                                    'progress': progress,
                                    'message': f'æ’é˜Ÿä¸­... (ä½ç½®: {queue_position + 1})'
                                })
                            else:
                                # ä»»åŠ¡å®Œæˆæˆ–å¤±è´¥ - æ£€æŸ¥å†å²è®°å½•
                                self._check_task_completion(task_id, prompt_id)
                                break
                        else:
                            # é˜Ÿåˆ—APIè°ƒç”¨å¤±è´¥ï¼Œä½†ä»»åŠ¡å¯èƒ½ä»åœ¨è¿è¡Œ
                            if last_progress < 90:  # é¿å…æ— é™å¢é•¿
                                last_progress += 1
                            running_tasks[task_id].update({
                                'status': 'running',
                                'progress': last_progress,
                                'message': 'æ­£åœ¨æ‰§è¡Œ...'
                            })
                    except Exception as e:
                        logger.error(f"ç›‘æ§è¿›åº¦å¤±è´¥: {e}")
                        # å‡ºé”™æ—¶ä¿æŒå½“å‰è¿›åº¦ï¼Œä¸è¦é‡ç½®
                        if task_id in running_tasks and running_tasks[task_id]['status'] == 'running':
                            current_progress = running_tasks[task_id].get('progress', 0)
                            running_tasks[task_id].update({
                                'progress': current_progress,
                                'message': 'æ­£åœ¨æ‰§è¡Œ...'
                            })
                        time.sleep(3)  # å‡ºé”™æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
                        
            except Exception as e:
                logger.error(f"ç›‘æ§çº¿ç¨‹å¼‚å¸¸: {e}")
                if task_id in running_tasks:
                    running_tasks[task_id].update({
                        'status': 'failed',
                        'end_time': datetime.now().isoformat(),
                        'error': f"ç›‘æ§å¤±è´¥: {str(e)}"
                    })
        
        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œç›‘æ§
        monitor_thread = threading.Thread(target=monitor)
        monitor_thread.daemon = True
        monitor_thread.start()
    
    def _get_detailed_progress(self, task_id, prompt_id, client_id):
        """è·å–è¯¦ç»†çš„æ‰§è¡Œè¿›åº¦ï¼šåŸºäºå½“å‰æ‰§è¡ŒèŠ‚ç‚¹åœ¨å·¥ä½œæµä¸­çš„ä½ç½®ä¼°ç®—"""
        try:
            task_info = running_tasks.get(task_id, {})
            total_nodes = int(task_info.get('total_nodes') or 0)
            node_index_map = task_info.get('node_index_map') or {}

            # å°è¯•è·å–æ‰§è¡ŒçŠ¶æ€ï¼ˆå…è®¸ /executing çŸ­æ—¶é—´æ— æ•°æ®ï¼‰
            execution_response = requests.get(f"{COMFYUI_API_URL}/executing", timeout=5)
            if execution_response.status_code == 200:
                execution_data = execution_response.json()
                # æŸäº›ç‰ˆæœ¬executingä¸ºåˆ—è¡¨ï¼Œå–æœ€åä¸€é¡¹ï¼›æˆ–ä¸ºdict
                if isinstance(execution_data, list) and execution_data:
                    execution_data = execution_data[-1]
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹ï¼ˆä¼˜å…ˆä¸¥æ ¼åŒ¹é… prompt_idï¼Œè‹¥æ— åˆ™å®½æ¾åŒ¹é… node å±äºæœ¬workflowï¼‰
                exec_node = execution_data.get('node')
                exec_pid = execution_data.get('prompt_id')
                is_our_prompt = (exec_pid == prompt_id)
                belongs_to_workflow = exec_node is not None and str(exec_node) in node_index_map
                if exec_node is not None and (is_our_prompt or belongs_to_workflow):
                    current_node = exec_node
                    # èŠ‚ç‚¹IDå¯èƒ½ä¸ºå­—ç¬¦ä¸²/æ•°å­—ï¼Œç»Ÿä¸€ä¸ºå­—ç¬¦ä¸²é”®
                    node_key = str(current_node)
                    idx = node_index_map.get(node_key)
                    # æ›´æ–°å½“å‰èŠ‚ç‚¹å¯è¯»ä¿¡æ¯ä¸ç›¸é‚»å¾…æ‰§è¡ŒèŠ‚ç‚¹ï¼Œä¾›å‰ç«¯æ˜¾ç¤º
                    task_state = running_tasks.get(task_id, {})
                    current_label = (task_state.get('node_meta_map') or {}).get(node_key)
                    order_list = task_state.get('node_order_list') or []
                    next_label = None
                    if node_key in order_list:
                        idx_in_order = order_list.index(node_key)
                        if idx_in_order + 1 < len(order_list):
                            next_id = order_list[idx_in_order + 1]
                            next_label = (task_state.get('node_meta_map') or {}).get(next_id)
                    if task_id in running_tasks:
                        running_tasks[task_id]['current_node_id'] = node_key
                        running_tasks[task_id]['current_node_label'] = current_label or f"Node {node_key}"
                        running_tasks[task_id]['next_node_label'] = next_label
                    if idx is not None and total_nodes > 0:
                        # 15%~95%åŒºé—´æ ¹æ®èŠ‚ç‚¹ç´¢å¼•çº¿æ€§æ˜ å°„
                        frac = max(0.0, min(1.0, idx / max(1, total_nodes - 1)))
                        base = int(15 + frac * 80)
                        # è‹¥æ‰§è¡Œæ•°æ®åŒ…å«æ¨è¿›åº¦çš„ç»†ç²’åº¦ä¿¡æ¯ï¼ˆå¦‚æ‰§è¡Œæ­¥/æ€»æ­¥ï¼‰ï¼Œè¿›ä¸€æ­¥ç»†åŒ–
                        try:
                            # æŸäº›æ‰©å±•ä¼šè¿”å› 'execution' æˆ– 'step' å­—æ®µï¼›æœ€ä½³åŠªåŠ›è¯»å–
                            exec_block = execution_data.get('execution') or {}
                            step = execution_data.get('step') or execution_data.get('current_step') or exec_block.get('step')
                            total = execution_data.get('total_steps') or execution_data.get('max_step') or exec_block.get('total_steps')
                            if step is not None and total:
                                fine = max(0.0, min(1.0, float(step) / float(total)))
                                base = min(95, max(base, int(base + fine * 2)))
                        except Exception:
                            pass
                        return base
                    # æ²¡æœ‰æ˜ å°„ä¿¡æ¯ï¼Œè¿”å›ä¿å®ˆä¸­é—´å€¼
                    return 55
                
                # æ£€æŸ¥å†å²è®°å½•ä¸­çš„è¿›åº¦
                history_response = requests.get(f"{COMFYUI_API_URL}/history/{prompt_id}", timeout=5)
                if history_response.status_code == 200:
                    history_data = history_response.json()
                    if prompt_id in history_data:
                        task_info = history_data[prompt_id]
                        outputs = task_info.get('outputs', {})
                        # å°è¯•åŸºäºå·²å®ŒæˆèŠ‚ç‚¹æ•°ä¸æ€»èŠ‚ç‚¹æ•°ç»†åŒ–
                        try:
                            executed = task_info.get('executed', [])
                            if executed and total_nodes:
                                done_ratio = max(0.0, min(1.0, len(executed) / float(total_nodes)))
                                return max(60, min(95, int(15 + done_ratio * 80)))
                        except Exception:
                            pass
                        
                        # æ ¹æ®è¾“å‡ºèŠ‚ç‚¹æ•°é‡ä¼°ç®—è¿›åº¦
                        if outputs:
                            # æœ‰è¾“å‡ºè¡¨ç¤ºä»»åŠ¡æ¥è¿‘å®Œæˆ
                            return 90
                        else:
                            # æ²¡æœ‰è¾“å‡ºä½†ä»»åŠ¡åœ¨è¿è¡Œä¸­
                            return 60
            
            # é»˜è®¤è¿›åº¦
            return 50
            
        except Exception as e:
            logger.error(f"è·å–è¯¦ç»†è¿›åº¦å¤±è´¥: {e}")
            return 50
    
    def _get_queue_position(self, prompt_id, pending_queue):
        """è·å–åœ¨é˜Ÿåˆ—ä¸­çš„ä½ç½®"""
        try:
            for i, item in enumerate(pending_queue):
                if item[1] == prompt_id:
                    return i
            return 0
        except Exception as e:
            logger.error(f"è·å–é˜Ÿåˆ—ä½ç½®å¤±è´¥: {e}")
            return 0
    
    def _check_task_completion(self, task_id, prompt_id):
        """æ£€æŸ¥ä»»åŠ¡å®ŒæˆçŠ¶æ€å¹¶å¤„ç†è¾“å‡º"""
        try:
            history_response = requests.get(f"{COMFYUI_API_URL}/history/{prompt_id}", timeout=10)
            if history_response.status_code != 200:
                logger.warning(f"æ— æ³•è·å–ä»»åŠ¡å†å²è®°å½•: {prompt_id}")
                running_tasks[task_id].update({
                    'status': 'completed',
                    'end_time': datetime.now().isoformat(),
                    'progress': 100,
                    'output': "ä»»åŠ¡å¯èƒ½å·²å®Œæˆï¼Œä½†æ— æ³•è·å–è¯¦ç»†ä¿¡æ¯"
                })
                return
                
            history_data = history_response.json()
            if prompt_id not in history_data:
                logger.warning(f"ä»»åŠ¡ {prompt_id} ä¸åœ¨å†å²è®°å½•ä¸­")
                running_tasks[task_id].update({
                    'status': 'completed',
                    'end_time': datetime.now().isoformat(),
                    'progress': 100,
                    'output': "ä»»åŠ¡å®Œæˆä½†è®°å½•ç¼ºå¤±"
                })
                return
            
            task_info = history_data[prompt_id]
            task_status = task_info.get('status', {})
            
            # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
            if task_status.get('status_str') == 'error':
                # å¤„ç†é”™è¯¯çŠ¶æ€
                messages = task_status.get('messages', [])
                user_error_msg = 'å·¥ä½œæµæ‰§è¡Œå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æœåŠ¡å™¨æ—¥å¿—'
                error_msg_detail = 'æœªçŸ¥é”™è¯¯'
                for msg_type, msg_data in messages:
                    if msg_type == 'execution_error':
                        raw_error = msg_data.get('exception_message', 'æœªçŸ¥é”™è¯¯')
                        node_type = msg_data.get('node_type', 'æœªçŸ¥èŠ‚ç‚¹')
                        node_id = msg_data.get('node_id', 'æœªçŸ¥')
                        error_msg_detail = f"èŠ‚ç‚¹ {node_id} ({node_type}): {raw_error}"
                        break
                
                # åªåœ¨æœåŠ¡å™¨æ—¥å¿—ä¸­è®°å½•è¯¦ç»†é”™è¯¯ï¼Œä¸ç›´æ¥è¿”å›ç»™å‰ç«¯
                logger.error(f"ä»»åŠ¡ {prompt_id} æ‰§è¡Œå¤±è´¥: {error_msg_detail}")
                running_tasks[task_id].update({
                    'status': 'failed',
                    'end_time': datetime.now().isoformat(),
                    'error': user_error_msg
                })
            elif task_status.get('status_str') == 'success':
                # å¤„ç†æˆåŠŸå®Œæˆçš„ä»»åŠ¡
                logger.info(f"ä»»åŠ¡ {prompt_id} å·²å®Œæˆï¼Œæ£€æŸ¥è¾“å‡º")
                
                # å¤„ç†è¾“å‡ºå›¾ç‰‡
                # æ·»åŠ ä»»åŠ¡å…ƒæ•°æ®åˆ°task_info
                task_info['task_id'] = task_id
                task_info['workflow_filename'] = running_tasks[task_id].get('workflow_filename', 'unknown')
                task_info['parameters'] = running_tasks[task_id].get('parameters', {})
                
                output_info = self._process_task_outputs(task_info)
                
                running_tasks[task_id].update({
                    'status': 'completed',
                    'end_time': datetime.now().isoformat(),
                    'progress': 100,
                    'output': output_info.get('message', 'ä»»åŠ¡å®Œæˆ'),
                    'image_url': output_info.get('image_url'),
                    'metadata_url': output_info.get('metadata_url')
                })
            else:
                # å…¶ä»–çŠ¶æ€
                logger.info(f"ä»»åŠ¡ {prompt_id} çŠ¶æ€: {task_status.get('status_str', 'unknown')}")
                running_tasks[task_id].update({
                    'status': 'completed',
                    'end_time': datetime.now().isoformat(),
                    'progress': 100,
                    'output': "ä»»åŠ¡å®Œæˆ"
                })
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥ä»»åŠ¡å®ŒæˆçŠ¶æ€å¤±è´¥: {e}")
            running_tasks[task_id].update({
                'status': 'failed',
                'end_time': datetime.now().isoformat(),
                'error': f"æ£€æŸ¥ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}"
            })
    
    def _process_task_outputs(self, task_info):
        """å¤„ç†ä»»åŠ¡è¾“å‡ºï¼Œå®‰å…¨åœ°å¤„ç†å›¾ç‰‡è¾“å‡º"""
        try:
            outputs = task_info.get('outputs', {})
            if not outputs:
                return {'message': 'ä»»åŠ¡å®Œæˆï¼Œä½†æ²¡æœ‰è¾“å‡º'}
            
            logger.info(f"ä»»åŠ¡è¾“å‡º: {outputs}")
            
            # è·å–ä»»åŠ¡å…ƒæ•°æ®
            task_id = task_info.get('task_id', 'unknown')
            workflow_filename = task_info.get('workflow_filename', 'unknown')
            parameters = task_info.get('parameters', {})
            
            # ç”¨äºå­˜å‚¨æœ€åå¤„ç†çš„å›¾ç‰‡ä¿¡æ¯
            last_processed_image = None
            output_images = []  # å­˜å‚¨æ‰€æœ‰æ‰¾åˆ°çš„å›¾ç‰‡ä¿¡æ¯
            
            # éå†è¾“å‡ºèŠ‚ç‚¹
            for node_id, node_output in outputs.items():
                if not node_output or not isinstance(node_output, dict):
                    logger.warning(f"èŠ‚ç‚¹ {node_id} è¾“å‡ºä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯")
                    continue
                
                if 'images' not in node_output:
                    continue
                    
                images = node_output.get('images', [])
                if not images or not isinstance(images, list):
                    logger.warning(f"èŠ‚ç‚¹ {node_id} å›¾ç‰‡åˆ—è¡¨ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯")
                    continue
                
                # å®‰å…¨åœ°å¤„ç†å›¾ç‰‡åˆ—è¡¨
                for i, img in enumerate(images):
                    if img is None:
                        logger.warning(f"èŠ‚ç‚¹ {node_id} ç¬¬ {i} ä¸ªå›¾ç‰‡ä¸ºnullï¼Œè·³è¿‡")
                        continue
                    
                    if not isinstance(img, dict):
                        logger.warning(f"èŠ‚ç‚¹ {node_id} ç¬¬ {i} ä¸ªå›¾ç‰‡æ ¼å¼é”™è¯¯: {type(img)}")
                        continue
                    
                    filename = img.get('filename')
                    if not filename:
                        logger.warning(f"èŠ‚ç‚¹ {node_id} ç¬¬ {i} ä¸ªå›¾ç‰‡ç¼ºå°‘filenameå­—æ®µ: {img}")
                        continue
                    
                    # å°è¯•è·å–å›¾ç‰‡
                    try:
                        subfolder = img.get('subfolder', '')
                        img_type = img.get('type', 'output')
                        
                        logger.info(f"å°è¯•è·å–å›¾ç‰‡: filename={filename}, subfolder={subfolder}, type={img_type}")
                        
                        # ä»…å¤„ç†è¾“å‡ºç±»å‹çš„å›¾ç‰‡ï¼Œè·³è¿‡ä¸´æ—¶é¢„è§ˆå›¾
                        if img_type != 'output':
                            continue
                        img_data = self._get_image_from_comfyui(filename, subfolder, img_type)
                        if img_data:
                            # ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°è¾“å‡ºç›®å½•
                            output_dir = os.path.join(os.path.dirname(__file__), 'outputs')
                            os.makedirs(output_dir, exist_ok=True)
                            
                            # ç”Ÿæˆäººç±»å¯è¯»çš„æ–‡ä»¶å
                            # æ ¼å¼ï¼šå·¥ä½œæµåç§°_YYYY-MM-DD_HH-MM-SS_åºå·.æ‰©å±•å
                            now = datetime.now()
                            date_str = now.strftime("%Y-%m-%d")
                            time_str = now.strftime("%H-%M-%S")
                            
                            # ä»å·¥ä½œæµæ–‡ä»¶åä¸­æå–ä¸»è¦åç§°ï¼ˆå»æ‰.jsonï¼‰
                            workflow_base_name = workflow_filename.replace('.json', '').replace('workflow_', '')
                            
                            # å¤„ç†åŸæ–‡ä»¶åï¼šæå–æ‰©å±•å
                            name_part, ext = os.path.splitext(filename)
                            if not ext:
                                ext = '.png'  # é»˜è®¤æ‰©å±•å
                            
                            # æŸ¥æ‰¾å½“å‰æ—¥æœŸçš„æœ€å¤§åºå·ï¼Œé¿å…é‡å¤
                            prefix = f"{workflow_base_name}_{date_str}_{time_str}"
                            existing_files = [f for f in os.listdir(output_dir) if f.startswith(prefix)]
                            sequence = len(existing_files) + 1
                            
                            output_filename = f"{prefix}_{sequence:03d}{ext}"
                            output_path = os.path.join(output_dir, output_filename)
                            
                            # ä¿å­˜å›¾ç‰‡æ–‡ä»¶
                            with open(output_path, 'wb') as f:
                                f.write(img_data)
                            
                            # ä»ComfyUIå†å²è®°å½•ä¸­æå–å®é™…ç§å­å€¼
                            actual_seed = self._extract_actual_seed(task_info, parameters)
                            
                            # æ›´æ–°å‚æ•°ä¸­çš„ç§å­å€¼
                            if actual_seed is not None:
                                parameters['actual_seed'] = actual_seed
                                # å¦‚æœç”¨æˆ·è®¾ç½®çš„æ˜¯-1ï¼Œä¹Ÿè®°å½•ç”¨æˆ·è¾“å…¥
                                if parameters.get('seed') == -1:
                                    parameters['user_seed'] = -1
                            
                            # ä¿å­˜å…ƒæ•°æ®
                            metadata = {
                                'task_id': task_id,
                                'workflow_filename': workflow_filename,
                                'original_filename': filename,
                                'output_filename': output_filename,
                                'parameters': parameters,
                                'created_time': datetime.now().isoformat(),
                                'node_id': node_id,
                                'subfolder': subfolder,
                                'img_type': img_type
                            }

                            # è¡¥å……ï¼šä»å®é™…æ‰§è¡Œçš„ prompt ä¸­æå–æ¨¡å‹åŠ è½½ä¿¡æ¯ï¼Œä¾¿äºç”»å»Šå±•ç¤º
                            try:
                                model_info = self._extract_model_loaders(task_info)
                                if model_info:
                                    metadata['model_loaders'] = model_info.get('by_node')
                                    # åŒæ—¶å†™å…¥æ‘˜è¦ï¼Œå‰ç«¯å¯ç›´æ¥è¯»å–ä¸»è¦æ¨¡å‹
                                    metadata['model_summary'] = model_info.get('summary')
                            except Exception as _e:
                                logger.warning(f"æå–æ¨¡å‹ä¿¡æ¯å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰: {_e}")

                            # è¡¥å……ï¼šä»å®é™…æ‰§è¡Œçš„ prompt ä¸­è¡¥é½é€šç”¨ç”Ÿæˆå‚æ•°ï¼ˆsteps/cfg/sampler/width/height...ï¼‰
                            try:
                                auto_params = self._extract_generation_parameters(task_info)
                                if auto_params:
                                    # ä¸è¦†ç›–ç”¨æˆ·æ˜ç¡®è®¾ç½®çš„å­—æ®µï¼Œä»…åœ¨ç¼ºå¤±æ—¶å¡«å……
                                    for k, v in auto_params.items():
                                        parameters.setdefault(k, v)
                            except Exception as _e:
                                logger.warning(f"æå–ç”Ÿæˆå‚æ•°å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰: {_e}")
                            
                            # ä¿å­˜å…ƒæ•°æ®åˆ°JSONæ–‡ä»¶ï¼ˆä¸å›¾ç‰‡æ–‡ä»¶åå¯¹åº”ï¼‰
                            metadata_filename = output_filename.replace(ext, '.json')
                            metadata_path = os.path.join(output_dir, metadata_filename)
                            with open(metadata_path, 'w', encoding='utf-8') as f:
                                json.dump(metadata, f, ensure_ascii=False, indent=2)
                            
                            logger.info(f"å›¾ç‰‡å’Œå…ƒæ•°æ®å·²ä¿å­˜: {output_filename}")
                            
                            # å­˜å‚¨å›¾ç‰‡ä¿¡æ¯ï¼ŒæŒ‰ç±»å‹åˆ†ç±»
                            image_info = {
                                'message': f'ä»»åŠ¡å®Œæˆï¼Œå›¾ç‰‡å·²ç”Ÿæˆ: {filename}',
                                'image_url': f'/outputs/{output_filename}',
                                'metadata_url': f'/outputs/{metadata_filename}',
                                'img_type': img_type,
                                'filename': filename
                            }
                            output_images.append(image_info)
                    except Exception as e:
                        logger.error(f"å¤„ç†å›¾ç‰‡å¤±è´¥ {filename}: {e}")
                        continue
            
            # ä¼˜å…ˆè¿”å› output ç±»å‹çš„å›¾ç‰‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å› temp ç±»å‹çš„å›¾ç‰‡
            if output_images:
                # æŒ‰ç±»å‹æ’åºï¼šoutput ç±»å‹ä¼˜å…ˆ
                output_images.sort(key=lambda x: x['img_type'] != 'output')
                # å–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼ˆä¼˜å…ˆçº§æœ€é«˜çš„ï¼‰
                last_processed_image = output_images[0]
                logger.info(f"è¿”å›å›¾ç‰‡: {last_processed_image['filename']} (ç±»å‹: {last_processed_image['img_type']})")
                return last_processed_image
            else:
                return {'message': 'ä»»åŠ¡å®Œæˆï¼Œä½†æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å›¾ç‰‡è¾“å‡º'}
            
        except Exception as e:
            logger.error(f"å¤„ç†ä»»åŠ¡è¾“å‡ºå¤±è´¥: {e}")
            return {'message': f'ä»»åŠ¡å®Œæˆï¼Œä½†å¤„ç†è¾“å‡ºæ—¶å‡ºé”™: {str(e)}'}
    
    def _extract_actual_seed(self, task_info, parameters):
        """ä»ComfyUIå†å²è®°å½•ä¸­æå–å®é™…ä½¿ç”¨çš„ç§å­å€¼"""
        try:
            # è·å–promptæ•°æ®ï¼ŒåŒ…å«å®é™…æ‰§è¡Œçš„èŠ‚ç‚¹ä¿¡æ¯
            prompt_data = task_info.get('prompt', [])
            if not prompt_data or len(prompt_data) < 3:
                return None
            
            # prompt_data[2]åŒ…å«èŠ‚ç‚¹é…ç½®
            nodes_config = prompt_data[2]
            
            # æŸ¥æ‰¾RandomNoiseèŠ‚ç‚¹
            for node_id, node_data in nodes_config.items():
                if node_data.get('class_type') == 'RandomNoise':
                    # æ£€æŸ¥inputsä¸­çš„noise_seed
                    inputs = node_data.get('inputs', {})
                    if 'noise_seed' in inputs:
                        actual_seed = inputs['noise_seed']
                        logger.info(f"æ‰¾åˆ°RandomNoiseèŠ‚ç‚¹ {node_id} çš„å®é™…ç§å­å€¼: {actual_seed}")
                        return actual_seed
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°RandomNoiseèŠ‚ç‚¹ï¼Œå°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„ç§å­èŠ‚ç‚¹
            # æ¯”å¦‚KSamplerèŠ‚ç‚¹
            for node_id, node_data in nodes_config.items():
                if node_data.get('class_type') == 'KSampler':
                    inputs = node_data.get('inputs', {})
                    if 'seed' in inputs:
                        actual_seed = inputs['seed']
                        logger.info(f"æ‰¾åˆ°KSamplerèŠ‚ç‚¹ {node_id} çš„å®é™…ç§å­å€¼: {actual_seed}")
                        return actual_seed
            
            logger.warning("æœªæ‰¾åˆ°åŒ…å«ç§å­å€¼çš„èŠ‚ç‚¹")
            return None
            
        except Exception as e:
            logger.error(f"æå–å®é™…ç§å­å€¼æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None

    def _extract_model_loaders(self, task_info):
        """ä»ComfyUIå†å²è®°å½•çš„promptä¸­æå–å®é™…ç”Ÿæ•ˆçš„æ¨¡å‹åŠ è½½ç›¸å…³é…ç½®ã€‚
        è¿”å›å½¢å¦‚ï¼š{
          'by_node': {
             'model_path_45': 'flux.1-dev-fp8.safetensors',
             'vae_name_10': 'flux_vae.safetensors',
             'lora_name_46': 'some_lora.safetensors',
             ...
          },
          'summary': {
             'main_model': 'flux.1-dev-fp8.safetensors',
             'vae': 'flux_vae.safetensors',
             'loras': ['some_lora.safetensors']
          }
        }
        """
        try:
            prompt_data = task_info.get('prompt', [])
            if not prompt_data or len(prompt_data) < 3:
                return None
            nodes_config = prompt_data[2]  # dict: node_id -> {class_type, inputs}
            if not isinstance(nodes_config, dict):
                return None

            by_node = {}
            loras = []
            main_model_candidate = None
            vae_candidate = None

            for node_id, node_data in nodes_config.items():
                try:
                    class_type = node_data.get('class_type')
                    inputs = node_data.get('inputs', {}) or {}
                    sid = str(node_id)

                    # ç»Ÿä¸€é‡‡é›†æ‰€æœ‰ inputs çš„åŸºç¡€é”®ï¼Œå¸¦ä¸Š node åç¼€
                    for k, v in inputs.items():
                        key = f"{k}_{sid}"
                        by_node[key] = v

                    # æ ¹æ®èŠ‚ç‚¹ç±»å‹æ¨æ–­ä¸»æ¨¡å‹/vae/lora
                    if class_type == 'NunchakuFluxDiTLoader':
                        # ä¸»æ¨¡å‹ä¼˜å…ˆ model_path
                        if not main_model_candidate and inputs.get('model_path'):
                            main_model_candidate = inputs.get('model_path')
                    elif class_type == 'CheckpointLoaderSimple':
                        if not main_model_candidate and inputs.get('ckpt_name'):
                            main_model_candidate = inputs.get('ckpt_name')
                    elif class_type == 'NunchakuTextEncoderLoader':
                        # ä½œä¸ºå…œåº•å±•ç¤º
                        if not main_model_candidate and inputs.get('model_type'):
                            main_model_candidate = inputs.get('model_type')
                    elif class_type == 'VAELoader':
                        if not vae_candidate and inputs.get('vae_name'):
                            vae_candidate = inputs.get('vae_name')
                    elif class_type in ('NunchakuFluxLoraLoader', 'LoraLoader'):
                        lname = inputs.get('lora_name') or inputs.get('lora_name_1')
                        if lname:
                            loras.append(lname)
                except Exception:
                    continue

            summary = {
                'main_model': main_model_candidate,
                'vae': vae_candidate,
                'loras': loras or None
            }

            return {'by_node': by_node, 'summary': summary}
        except Exception as e:
            logger.error(f"æå–æ¨¡å‹åŠ è½½ä¿¡æ¯å¤±è´¥: {e}")
            return None

    def _extract_generation_parameters(self, task_info):
        """ä»æ‰§è¡Œçš„ prompt é…ç½®ä¸­æå–é€šç”¨ç”Ÿæˆå‚æ•°ï¼ˆsteps/cfg/sampler/scheduler/denoise/width/heightï¼‰ã€‚
        è¿”å› dictï¼Œä»…åŒ…å«è§£ææˆåŠŸçš„é”®ã€‚"""
        try:
            prompt_data = task_info.get('prompt', [])
            if not prompt_data or len(prompt_data) < 3:
                return {}
            nodes_config = prompt_data[2]
            if not isinstance(nodes_config, dict):
                return {}

            out = {}
            for node_id, node_data in nodes_config.items():
                try:
                    class_type = node_data.get('class_type')
                    inputs = node_data.get('inputs', {}) or {}
                    if class_type == 'KSampler':
                        if 'seed' in inputs and inputs['seed'] is not None:
                            out.setdefault('seed', inputs['seed'])
                        if 'sampler_name' in inputs and inputs['sampler_name']:
                            out.setdefault('sampler', inputs['sampler_name'])
                    if class_type == 'BasicScheduler':
                        if 'steps' in inputs and inputs['steps'] is not None:
                            out.setdefault('steps', inputs['steps'])
                        if 'scheduler' in inputs and inputs['scheduler']:
                            out.setdefault('scheduler', inputs['scheduler'])
                        if 'denoise' in inputs and inputs['denoise'] is not None:
                            out.setdefault('denoise', inputs['denoise'])
                    if class_type == 'FluxGuidance':
                        if 'guidance' in inputs and inputs['guidance'] is not None:
                            out.setdefault('cfg', inputs['guidance'])
                    if class_type in ('EmptyLatentImage', 'EmptySD3LatentImage'):
                        if 'width' in inputs and inputs['width'] is not None:
                            out.setdefault('width', inputs['width'])
                        if 'height' in inputs and inputs['height'] is not None:
                            out.setdefault('height', inputs['height'])
                    if class_type == 'ModelSamplingFlux':
                        # æŸäº›å·¥ä½œæµå®½é«˜åœ¨è¯¥èŠ‚ç‚¹
                        if 'width' in inputs and inputs['width'] is not None:
                            out.setdefault('width', inputs['width'])
                        if 'height' in inputs and inputs['height'] is not None:
                            out.setdefault('height', inputs['height'])
                except Exception:
                    continue
            return out
        except Exception as e:
            logger.error(f"æå–ç”Ÿæˆå‚æ•°å¤±è´¥: {e}")
            return {}

    def _get_image_from_comfyui(self, filename, subfolder='', img_type='output'):
        """ä»ComfyUIè·å–å›¾ç‰‡æ•°æ®"""
        try:
            params = {
                'filename': filename,
                'type': img_type
            }
            if subfolder:
                params['subfolder'] = subfolder
            
            response = requests.get(f"{COMFYUI_API_URL}/view", params=params, timeout=30)
            if response.status_code == 200:
                return response.content
            else:
                logger.error(f"è·å–å›¾ç‰‡å¤±è´¥: {response.status_code} - {response.text}")
                return None
        except Exception as e:
            logger.error(f"ä»ComfyUIè·å–å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None

# åˆ›å»ºå…¨å±€runnerå®ä¾‹
runner = WorkflowRunner()

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html', cache_bust=int(time.time()))

@app.route('/test')
def test():
    """æµ‹è¯•é¡µé¢"""
    return send_from_directory('.', 'test.html')

@app.route('/debug')
def debug():
    """è°ƒè¯•é¡µé¢"""
    return render_template('debug.html')

@app.route('/test-simple')
def test_simple():
    """ç®€åŒ–æµ‹è¯•é¡µé¢"""
    return render_template('test_simple.html')

@app.route('/test_image_display')
def test_image_display():
    """æµ‹è¯•å›¾ç‰‡æ˜¾ç¤ºé¡µé¢"""
    return send_from_directory('.', 'test_image_display.html')

@app.route('/test_frontend')
def test_frontend():
    """å‰ç«¯åŠŸèƒ½æµ‹è¯•é¡µé¢"""
    return send_from_directory('.', 'test_frontend.html')

@app.route('/debug_workflow_loading')
def debug_workflow_loading():
    """å·¥ä½œæµåŠ è½½è°ƒè¯•é¡µé¢"""
    return send_from_directory('.', 'debug_workflow_loading.html')

@app.route('/test_simple_loading')
def test_simple_loading():
    """ç®€å•å·¥ä½œæµåŠ è½½æµ‹è¯•é¡µé¢"""
    return send_from_directory('.', 'test_simple_loading.html')

@app.route('/test_js_loading')
def test_js_loading():
    """JavaScriptåŠ è½½æµ‹è¯•é¡µé¢"""
    return send_from_directory('.', 'test_js_loading.html')

@app.route('/debug_main_page')
def debug_main_page():
    """ä¸»é¡µè°ƒè¯•é¡µé¢"""
    return send_from_directory('.', 'debug_main_page.html')

@app.route('/gallery')
def gallery():
    """å›¾ç‰‡ç”»å»Šé¡µé¢"""
    return render_template('gallery.html')

@app.route('/prompt-manager')
def prompt_manager():
    """æç¤ºè¯ç®¡ç†å™¨é¡µé¢"""
    return render_template('prompt-manager.html')

@app.route('/api/workflow-stats')
def get_workflow_stats():
    """è·å–å·¥ä½œæµä½¿ç”¨ç»Ÿè®¡"""
    try:
        stats = load_workflow_stats()
        
        # è·å–æœ€è¿‘7å¤©ä½¿ç”¨çš„å·¥ä½œæµ
        recent_cutoff = datetime.now() - timedelta(days=7)
        recent_workflows = []
        
        for workflow, usage_time_str in stats['recent_usage'].items():
            try:
                usage_time = datetime.fromisoformat(usage_time_str)
                if usage_time >= recent_cutoff:
                    recent_workflows.append({
                        'workflow': workflow,
                        'last_used': usage_time_str,
                        'usage_count': stats['usage_count'].get(workflow, 0)
                    })
            except Exception:
                continue
        
        # æŒ‰æœ€åä½¿ç”¨æ—¶é—´æ’åº
        recent_workflows.sort(key=lambda x: x['last_used'], reverse=True)
        
        # è·å–ä½¿ç”¨æ¬¡æ•°æœ€å¤šçš„å·¥ä½œæµ
        popular_workflows = []
        for workflow, count in sorted(stats['usage_count'].items(), key=lambda x: x[1], reverse=True):
            popular_workflows.append({
                'workflow': workflow,
                'usage_count': count,
                'last_used': stats['recent_usage'].get(workflow, '')
            })
        
        return jsonify({
            'success': True,
            'recent_workflows': recent_workflows[:10],  # æœ€è¿‘10ä¸ª
            'popular_workflows': popular_workflows[:10]  # æœ€çƒ­é—¨10ä¸ª
        })
    except Exception as e:
        logger.error(f"è·å–å·¥ä½œæµç»Ÿè®¡å¤±è´¥: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/workflows')
def get_workflows():
    """è·å–æ‰€æœ‰workflowåˆ—è¡¨"""
    try:
        workflows = runner.get_workflows()
        return jsonify({'success': True, 'workflows': workflows})
    except Exception as e:
        logger.error(f"è·å–workflowså¤±è´¥: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/workflow/<path:filename>')
def get_workflow_details(filename):
    """è·å–ç‰¹å®šå·¥ä½œæµçš„è¯¦ç»†ä¿¡æ¯"""
    try:
        filepath = os.path.join(WORKFLOW_DIR, filename)
        if not os.path.exists(filepath):
            return jsonify({'success': False, 'error': 'å·¥ä½œæµæ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        with open(filepath, 'r', encoding='utf-8') as f:
            workflow_data = json.load(f)
        
        return jsonify({'success': True, 'workflow': workflow_data})
    except Exception as e:
        logger.error(f"è·å–å·¥ä½œæµè¯¦æƒ…å¤±è´¥: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/run', methods=['POST'])
def run_workflow():
    """è¿è¡Œé€‰å®šçš„workflow"""
    data = request.get_json()
    filename = data.get('filename')
    parameters = data.get('parameters', {})
    
    if not filename:
        return jsonify({'success': False, 'error': 'ç¼ºå°‘filenameå‚æ•°'}), 400
    
    # å…ˆæ£€æŸ¥ComfyUIè¿æ¥çŠ¶æ€
    if not runner.check_comfyui_status():
        return jsonify({
            'success': False, 
            'error': 'ComfyUIæœåŠ¡æœªè¿è¡Œæˆ–æ— æ³•è¿æ¥ï¼Œè¯·ç¡®ä¿ComfyUIåç«¯å·²å¯åŠ¨'
        }), 503
    
    # ä»parametersä¸­æå–selected_imagesï¼Œå¦‚æœæ²¡æœ‰åˆ™ä»é¡¶çº§å­—æ®µè·å–
    selected_images = parameters.get('selected_images', {})
    if not selected_images:
        selected_images = data.get('selected_images', {})
    
    # è®°å½•å·¥ä½œæµä½¿ç”¨ç»Ÿè®¡
    record_workflow_usage(filename)
    
    # ç”Ÿæˆä»»åŠ¡ID
    task_id = f"task_{int(time.time())}_{len(running_tasks)}"
    
    # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
    running_tasks[task_id] = {
        'status': 'initializing',
        'filename': filename,
        'workflow_filename': filename,
        'parameters': parameters,
        'start_time': datetime.now().isoformat(),
        'progress': 0,
        'message': 'æ­£åœ¨åˆå§‹åŒ–ä»»åŠ¡...',
        'prompt_id': None
    }
    
    # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œ
    def run_in_background():
        try:
            result = runner.run_workflow_with_parameters_and_images(filename, task_id, parameters, selected_images)
            if not result.get('success', False):
                # å¦‚æœä»»åŠ¡å¯åŠ¨å¤±è´¥ï¼Œæ›´æ–°ä»»åŠ¡çŠ¶æ€
                if task_id in running_tasks:
                    running_tasks[task_id].update({
                        'status': 'failed',
                        'end_time': datetime.now().isoformat(),
                        'error': result.get('error', 'ä»»åŠ¡å¯åŠ¨å¤±è´¥'),
                        'message': 'ä»»åŠ¡å¯åŠ¨å¤±è´¥'
                    })
        except Exception as e:
            logger.error(f"åå°ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
            if task_id in running_tasks:
                running_tasks[task_id].update({
                    'status': 'failed',
                    'end_time': datetime.now().isoformat(),
                    'error': f'ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}',
                    'message': 'ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸'
                })
    
    thread = threading.Thread(target=run_in_background)
    thread.daemon = True
    thread.start()
    
    return jsonify({'success': True, 'task_id': task_id})

@app.route('/api/status/<task_id>')
def get_task_status(task_id):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    if task_id in running_tasks:
        return jsonify({'success': True, 'task': running_tasks[task_id]})
    else:
        return jsonify({'success': False, 'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404

@app.route('/api/tasks')
def get_all_tasks():
    """è·å–æ‰€æœ‰ä»»åŠ¡çŠ¶æ€"""
    return jsonify({'success': True, 'tasks': running_tasks})

@app.route('/api/comfyui/status')
def check_comfyui():
    """æ£€æŸ¥ComfyUIè¿æ¥çŠ¶æ€"""
    try:
        is_running = runner.check_comfyui_status()
        if is_running:
            # è·å–ç³»ç»Ÿä¿¡æ¯
            response = requests.get(f"{COMFYUI_API_URL}/system_stats", timeout=5)
            if response.status_code == 200:
                system_info = response.json()
                return jsonify({
                    'success': True, 
                    'connected': True,
                    'url': COMFYUI_API_URL,
                    'system_info': system_info.get('system', {})
                })
        
        return jsonify({
            'success': True, 
            'connected': False,
            'url': COMFYUI_API_URL,
            'error': 'ComfyUIæœåŠ¡æœªè¿è¡Œæˆ–æ— æ³•è¿æ¥'
        })
    except Exception as e:
        return jsonify({
            'success': False, 
            'connected': False,
            'url': COMFYUI_API_URL,
            'error': str(e)
        })

@app.route('/api/system-resources')
def system_resources():
    """è¿”å›ç³»ç»Ÿèµ„æºå ç”¨ï¼ˆCPU/å†…å­˜/GPU/VRAMï¼‰ï¼Œå°½é‡è½»é‡"""
    try:
        result = {
            'success': True,
            'cpu_percent': None,
            'memory_percent': None,
            'memory_total_mb': None,
            'memory_used_mb': None,
            'gpus': []
        }
        # CPU/å†…å­˜
        if psutil:
            try:
                result['cpu_percent'] = psutil.cpu_percent(interval=0.1)
                vm = psutil.virtual_memory()
                result['memory_percent'] = vm.percent
                result['memory_total_mb'] = round(vm.total / (1024 * 1024))
                # used é‡‡ç”¨ total - available æ›´ç¬¦åˆç³»ç»Ÿè§‚æ„Ÿ
                result['memory_used_mb'] = max(0, round((vm.total - vm.available) / (1024 * 1024)))
            except Exception as e:
                logger.warning(f"psutil è¯»å–å¤±è´¥: {e}")
        else:
            # æ—  psutil çš„å›é€€ï¼šè¯»å– /proc/meminfo ä¸ /proc/stat
            try:
                # å†…å­˜ï¼š/proc/meminfo (kB)
                meminfo = {}
                with open('/proc/meminfo', 'r') as f:
                    for line in f:
                        parts = line.split(':')
                        if len(parts) == 2:
                            key = parts[0].strip()
                            val = parts[1].strip().split()[0]
                            meminfo[key] = int(val)
                mem_total_kb = meminfo.get('MemTotal', 0)
                mem_available_kb = meminfo.get('MemAvailable', 0)
                mem_used_kb = max(0, mem_total_kb - mem_available_kb)
                result['memory_total_mb'] = round(mem_total_kb / 1024)
                result['memory_used_mb'] = round(mem_used_kb / 1024)
                result['memory_percent'] = round((mem_used_kb / mem_total_kb * 100), 1) if mem_total_kb else 0
            except Exception as e:
                logger.debug(f"/proc/meminfo è¯»å–å¤±è´¥: {e}")
            try:
                # CPUï¼š/proc/stat ä¸¤æ¬¡é‡‡æ ·
                def read_cpu_times():
                    with open('/proc/stat', 'r') as f:
                        for line in f:
                            if line.startswith('cpu '):
                                parts = [int(x) for x in line.split()[1:]]
                                user, nice, system, idle, iowait, irq, softirq, steal, *_ = parts + [0]*(10-len(parts))
                                idle_all = idle + iowait
                                non_idle = user + nice + system + irq + softirq + steal
                                total = idle_all + non_idle
                                return total, idle_all
                    return None, None
                t1, i1 = read_cpu_times()
                time.sleep(0.05)
                t2, i2 = read_cpu_times()
                if t1 is not None and t2 is not None and (t2 - t1) > 0:
                    cpu_percent = (1 - (i2 - i1) / (t2 - t1)) * 100
                    result['cpu_percent'] = max(0, min(100, round(cpu_percent, 1)))
            except Exception as e:
                logger.debug(f"/proc/stat è¯»å–å¤±è´¥: {e}")
        # GPU/VRAM - é€šè¿‡ nvidia-smi
        try:
            smi = subprocess.run(
                ['nvidia-smi', '--query-gpu=index,name,memory.total,memory.used,utilization.gpu', '--format=csv,noheader,nounits'],
                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, timeout=1.5
            )
            if smi.returncode == 0:
                lines = [l.strip() for l in smi.stdout.split('\n') if l.strip()]
                for line in lines:
                    parts = [p.strip() for p in line.split(',')]
                    if len(parts) >= 5:
                        idx, name, mem_total, mem_used, util = parts[:5]
                        try:
                            mem_total = float(mem_total)
                            mem_used = float(mem_used)
                            util = float(util)
                            vram_percent = (mem_used / mem_total * 100) if mem_total > 0 else 0
                        except Exception:
                            vram_percent = None
                        result['gpus'].append({
                            'index': idx,
                            'name': name,
                            'vram_used_mb': mem_used,
                            'vram_total_mb': mem_total,
                            'vram_percent': vram_percent,
                            'util_percent': util
                        })
        except Exception as e:
            logger.debug(f"nvidia-smi ä¸å¯ç”¨: {e}")
        return jsonify(result)
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/clean-vram', methods=['POST'])
def clean_vram():
    """å°è¯•æ¸…ç†VRAMï¼ˆè°ƒç”¨ComfyUI unload æˆ– torch.cuda.empty_cache çš„ä»£ç†ï¼‰"""
    try:
        # ä¼˜å…ˆå°è¯•ComfyUI æä¾›çš„å¸è½½æ¥å£ï¼ˆå¦‚æœæœ‰ï¼‰
        try:
            resp = requests.post(f"{COMFYUI_API_URL}/unload", timeout=3)
            if resp.status_code == 200:
                return jsonify({'success': True, 'message': 'å·²è¯·æ±‚ComfyUIå¸è½½æ¨¡å‹/æ¸…ç†VRAM'})
        except Exception:
            pass
        # å…œåº•ï¼šè°ƒç”¨nvidia-smiå»ºè®®çš„æ¸…ç†æ–¹å¼ä¸å¯è¡Œï¼›è¿™é‡Œä»…è¿”å›æç¤º
        return jsonify({'success': True, 'message': 'å·²è§¦å‘æ¸…ç†è¯·æ±‚ï¼ˆå¦‚æœªç”Ÿæ•ˆï¼Œè¯·åœ¨åç«¯æ‰‹åŠ¨é‡Šæ”¾/é‡å¯ç›¸å…³è¿›ç¨‹ï¼‰'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500
    except Exception as e:
        return jsonify({
            'success': False, 
            'connected': False,
            'url': COMFYUI_API_URL,
            'error': str(e)
        })

@app.route('/static/<path:filename>')
def static_files(filename):
    """é™æ€æ–‡ä»¶æœåŠ¡"""
    return send_from_directory('static', filename)

@app.route('/outputs/<path:filename>')
def output_files(filename):
    """è¾“å‡ºæ–‡ä»¶æœåŠ¡"""
    output_dir = os.path.join(os.path.dirname(__file__), 'outputs')
    return send_from_directory(output_dir, filename)

@app.route('/api/images')
def get_available_images():
    """è·å–å¯ç”¨çš„å›¾åƒåˆ—è¡¨"""
    try:
        output_dir = os.path.join(os.path.dirname(__file__), 'outputs')
        uploaded_dir = os.path.join(output_dir, 'uploaded')
        generated_dir = os.path.join(output_dir, 'generated')
        
        images = {
            'uploaded': [],
            'generated': []
        }
        
        # æ‰«æå·²ä¸Šä¼ çš„å›¾åƒ
        if os.path.exists(uploaded_dir):
            uploaded_files = []
            for filename in os.listdir(uploaded_dir):
                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):
                    file_path = os.path.join(uploaded_dir, filename)
                    uploaded_files.append({
                        'name': filename,
                        'path': f'uploaded/{filename}',
                        'size': os.path.getsize(file_path),
                        'mtime': os.path.getmtime(file_path)
                    })
            # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
            uploaded_files.sort(key=lambda x: x['mtime'], reverse=True)
            # ç§»é™¤mtimeå­—æ®µï¼Œåªä¿ç•™éœ€è¦çš„æ•°æ®
            for file_info in uploaded_files:
                del file_info['mtime']
                images['uploaded'].append(file_info)
        
        # æ‰«æå·²ç”Ÿæˆçš„å›¾åƒï¼ˆåŒ…æ‹¬å­ç›®å½•å’Œæ ¹ç›®å½•ï¼‰
        generated_files = []
        
        if os.path.exists(generated_dir):
            for filename in os.listdir(generated_dir):
                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):
                    file_path = os.path.join(generated_dir, filename)
                    generated_files.append({
                        'name': filename,
                        'path': f'generated/{filename}',
                        'size': os.path.getsize(file_path),
                        'mtime': os.path.getmtime(file_path)
                    })
        
        # æ‰«æoutputsæ ¹ç›®å½•ä¸­çš„ç”Ÿæˆå›¾åƒï¼ˆæ”¯æŒæ–°æ—§æ ¼å¼ï¼‰
        if os.path.exists(output_dir):
            for filename in os.listdir(output_dir):
                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):
                    # æ’é™¤å­ç›®å½•ä¸­çš„æ–‡ä»¶å’Œéå›¾ç‰‡æ–‡ä»¶
                    file_path = os.path.join(output_dir, filename)
                    if os.path.isfile(file_path):
                        # æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
                        # 1. æ—§æ ¼å¼ï¼šresult_xxx_xxx.png
                        # 2. æ–°æ ¼å¼ï¼šworkflow_2025-08-07_14-30-25_001.png
                        is_generated = (
                            filename.startswith('result_') or  # æ—§æ ¼å¼
                            ('_2' in filename and len(filename.split('_')) >= 4)  # æ–°æ ¼å¼ï¼ˆåŒ…å«æ—¥æœŸæ—¶é—´ï¼‰
                        )
                        
                        if is_generated:
                            generated_files.append({
                                'name': filename,
                                'path': filename,  # æ ¹ç›®å½•ä¸­çš„æ–‡ä»¶ï¼Œè·¯å¾„å°±æ˜¯æ–‡ä»¶å
                                'size': os.path.getsize(file_path),
                                'mtime': os.path.getmtime(file_path)
                            })
        
        # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
        generated_files.sort(key=lambda x: x['mtime'], reverse=True)
        # ç§»é™¤mtimeå­—æ®µï¼Œåªä¿ç•™éœ€è¦çš„æ•°æ®
        for file_info in generated_files:
            del file_info['mtime']
            images['generated'].append(file_info)
        
        return jsonify({'success': True, 'images': images})
    except Exception as e:
        logger.error(f"è·å–å›¾åƒåˆ—è¡¨å¤±è´¥: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/delete-image', methods=['POST'])
def delete_image():
    """åˆ é™¤å•ä¸ªå›¾ç‰‡"""
    try:
        data = request.get_json()
        if not data or 'filename' not in data:
            return jsonify({'success': False, 'error': 'ç¼ºå°‘æ–‡ä»¶åå‚æ•°'}), 400
        
        filename = data['filename']
        output_dir = os.path.join(os.path.dirname(__file__), 'outputs')
        
        # æŸ¥æ‰¾æ–‡ä»¶è·¯å¾„
        file_paths = []
        
        # æ£€æŸ¥æ ¹ç›®å½•
        root_path = os.path.join(output_dir, filename)
        if os.path.exists(root_path):
            file_paths.append(root_path)
        
        # æ£€æŸ¥uploadedå­ç›®å½•
        uploaded_path = os.path.join(output_dir, 'uploaded', filename)
        if os.path.exists(uploaded_path):
            file_paths.append(uploaded_path)
        
        # æ£€æŸ¥generatedå­ç›®å½•
        generated_path = os.path.join(output_dir, 'generated', filename)
        if os.path.exists(generated_path):
            file_paths.append(generated_path)
        
        if not file_paths:
            return jsonify({'success': False, 'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        # åˆ é™¤æ–‡ä»¶
        deleted_count = 0
        for file_path in file_paths:
            try:
                os.remove(file_path)
                deleted_count += 1
                logger.info(f"å·²åˆ é™¤å›¾ç‰‡: {file_path}")
            except Exception as e:
                logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        # åˆ é™¤å¯¹åº”çš„å…ƒæ•°æ®æ–‡ä»¶ï¼ˆæ–°æ ¼å¼ï¼šå›¾ç‰‡æ–‡ä»¶å.jsonï¼‰
        name_part, ext = os.path.splitext(filename)
        metadata_filename = f"{name_part}.json"
        metadata_path = os.path.join(output_dir, metadata_filename)
        if os.path.exists(metadata_path):
            try:
                os.remove(metadata_path)
                logger.info(f"å·²åˆ é™¤å…ƒæ•°æ®: {metadata_path}")
            except Exception as e:
                logger.error(f"åˆ é™¤å…ƒæ•°æ®å¤±è´¥ {metadata_path}: {e}")
        else:
            # å°è¯•æ—§æ ¼å¼çš„å…ƒæ•°æ®æ–‡ä»¶ï¼ˆå‘åå…¼å®¹ï¼‰
            if 'result_' in filename and '_' in filename:
                old_id = filename.split('_')[1]
                old_metadata_filename = f"metadata_{old_id}.json"
                old_metadata_path = os.path.join(output_dir, old_metadata_filename)
                if os.path.exists(old_metadata_path):
                    try:
                        os.remove(old_metadata_path)
                        logger.info(f"å·²åˆ é™¤æ—§æ ¼å¼å…ƒæ•°æ®: {old_metadata_path}")
                    except Exception as e:
                        logger.error(f"åˆ é™¤æ—§æ ¼å¼å…ƒæ•°æ®å¤±è´¥ {old_metadata_path}: {e}")
        
        return jsonify({'success': True, 'deleted_count': deleted_count})
    
    except Exception as e:
        logger.error(f"åˆ é™¤å›¾ç‰‡å¤±è´¥: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/delete-images', methods=['POST'])
def delete_images():
    """æ‰¹é‡åˆ é™¤å›¾ç‰‡"""
    try:
        data = request.get_json()
        if not data or 'filenames' not in data:
            return jsonify({'success': False, 'error': 'ç¼ºå°‘æ–‡ä»¶ååˆ—è¡¨å‚æ•°'}), 400
        
        filenames = data['filenames']
        if not isinstance(filenames, list):
            return jsonify({'success': False, 'error': 'æ–‡ä»¶ååˆ—è¡¨æ ¼å¼é”™è¯¯'}), 400
        
        output_dir = os.path.join(os.path.dirname(__file__), 'outputs')
        deleted_count = 0
        
        for filename in filenames:
            # æŸ¥æ‰¾æ–‡ä»¶è·¯å¾„
            file_paths = []
            
            # æ£€æŸ¥æ ¹ç›®å½•
            root_path = os.path.join(output_dir, filename)
            if os.path.exists(root_path):
                file_paths.append(root_path)
            
            # æ£€æŸ¥uploadedå­ç›®å½•
            uploaded_path = os.path.join(output_dir, 'uploaded', filename)
            if os.path.exists(uploaded_path):
                file_paths.append(uploaded_path)
            
            # æ£€æŸ¥generatedå­ç›®å½•
            generated_path = os.path.join(output_dir, 'generated', filename)
            if os.path.exists(generated_path):
                file_paths.append(generated_path)
            
            # åˆ é™¤æ–‡ä»¶
            for file_path in file_paths:
                try:
                    os.remove(file_path)
                    deleted_count += 1
                    logger.info(f"å·²åˆ é™¤å›¾ç‰‡: {file_path}")
                except Exception as e:
                    logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            
            # åˆ é™¤å¯¹åº”çš„å…ƒæ•°æ®æ–‡ä»¶ï¼ˆæ–°æ ¼å¼ï¼šå›¾ç‰‡æ–‡ä»¶å.jsonï¼‰
            name_part, ext = os.path.splitext(filename)
            metadata_filename = f"{name_part}.json"
            metadata_path = os.path.join(output_dir, metadata_filename)
            if os.path.exists(metadata_path):
                try:
                    os.remove(metadata_path)
                    logger.info(f"å·²åˆ é™¤å…ƒæ•°æ®: {metadata_path}")
                except Exception as e:
                    logger.error(f"åˆ é™¤å…ƒæ•°æ®å¤±è´¥ {metadata_path}: {e}")
            else:
                # å°è¯•æ—§æ ¼å¼çš„å…ƒæ•°æ®æ–‡ä»¶ï¼ˆå‘åå…¼å®¹ï¼‰
                if 'result_' in filename and '_' in filename:
                    old_id = filename.split('_')[1]
                    old_metadata_filename = f"metadata_{old_id}.json"
                    old_metadata_path = os.path.join(output_dir, old_metadata_filename)
                    if os.path.exists(old_metadata_path):
                        try:
                            os.remove(old_metadata_path)
                            logger.info(f"å·²åˆ é™¤æ—§æ ¼å¼å…ƒæ•°æ®: {old_metadata_path}")
                        except Exception as e:
                            logger.error(f"åˆ é™¤æ—§æ ¼å¼å…ƒæ•°æ®å¤±è´¥ {old_metadata_path}: {e}")
        
        return jsonify({'success': True, 'deleted_count': deleted_count})
    
    except Exception as e:
        logger.error(f"æ‰¹é‡åˆ é™¤å›¾ç‰‡å¤±è´¥: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/upload', methods=['POST'])
def upload_images():
    """ä¸Šä¼ å›¾åƒæ–‡ä»¶"""
    try:
        if 'images' not in request.files:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400
        
        files = request.files.getlist('images')
        if not files or all(file.filename == '' for file in files):
            return jsonify({'success': False, 'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400
        
        uploaded_dir = os.path.join(os.path.dirname(__file__), 'outputs', 'uploaded')
        os.makedirs(uploaded_dir, exist_ok=True)
        
        uploaded_files = []
        for file in files:
            if file and file.filename:
                # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
                filename = secure_filename(file.filename)
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                name, ext = os.path.splitext(filename)
                safe_filename = f"{name}_{timestamp}{ext}"
                
                # è‹¥æ˜¯é®ç½©æ–‡ä»¶ï¼ˆæ¥è‡ªé®ç½©ç¼–è¾‘å™¨ï¼‰ï¼Œå•ç‹¬æ”¾åˆ° masks ç›®å½•ï¼Œå¹¶åœ¨è¿”å›å€¼ä¸­æ ‡è®° is_mask
                is_mask_upload = name.startswith('mask_editor') or name.startswith('mask')
                target_dir = os.path.join(os.path.dirname(__file__), 'outputs', 'masks') if is_mask_upload else uploaded_dir
                os.makedirs(target_dir, exist_ok=True)
                filepath = os.path.join(target_dir, safe_filename)
                file.save(filepath)
                
                uploaded_files.append({
                    'original_name': file.filename,
                    'saved_name': safe_filename,
                    'path': (f'masks/{safe_filename}' if is_mask_upload else f'uploaded/{safe_filename}'),
                    'is_mask': is_mask_upload
                })
        
        return jsonify({
            'success': True, 
            'message': f'æˆåŠŸä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶',
            'files': uploaded_files
        })
    except Exception as e:
        logger.error(f"ä¸Šä¼ å›¾åƒå¤±è´¥: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/analyze-workflow/<path:filename>')
def analyze_workflow(filename):
    """åˆ†æå·¥ä½œæµç»“æ„å¹¶è¿”å›å‚æ•°ä¿¡æ¯"""
    try:
        filepath = os.path.join(WORKFLOW_DIR, filename)
        if not os.path.exists(filepath):
            return jsonify({'success': False, 'error': 'å·¥ä½œæµæ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        with open(filepath, 'r', encoding='utf-8') as f:
            workflow_data = json.load(f)
        
        # åˆ†æå·¥ä½œæµç»“æ„
        analysis = analyze_workflow_structure(workflow_data)
        
        return jsonify({'success': True, 'analysis': analysis})
    except Exception as e:
        logger.error(f"åˆ†æå·¥ä½œæµå¤±è´¥: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/generated-images')
def get_generated_images():
    """è·å–æ‰€æœ‰ç”Ÿæˆçš„å›¾ç‰‡åˆ—è¡¨"""
    try:
        output_dir = os.path.join(os.path.dirname(__file__), 'outputs')
        images = []
        
        if os.path.exists(output_dir):
            for filename in os.listdir(output_dir):
                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):
                    filepath = os.path.join(output_dir, filename)
                    if os.path.isfile(filepath):
                        # æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
                        # 1. æ—§æ ¼å¼ï¼šresult_xxx_xxx.png
                        # 2. æ–°æ ¼å¼ï¼šworkflow_2025-08-07_14-30-25_001.png
                        is_generated = (
                            filename.startswith('result_') or  # æ—§æ ¼å¼
                            ('_2' in filename and len(filename.split('_')) >= 4)  # æ–°æ ¼å¼ï¼ˆåŒ…å«æ—¥æœŸæ—¶é—´ï¼‰
                        )
                        
                        if not is_generated:
                            continue
                            
                        stat = os.stat(filepath)
                        
                        # å°è¯•è¯»å–å¯¹åº”çš„å…ƒæ•°æ®æ–‡ä»¶
                        metadata = {}
                        
                        # æ–°æ ¼å¼ï¼šç›´æ¥ç”¨æ–‡ä»¶åæŸ¥æ‰¾å¯¹åº”çš„.jsonæ–‡ä»¶
                        name_part, ext = os.path.splitext(filename)
                        metadata_filename = f"{name_part}.json"
                        metadata_path = os.path.join(output_dir, metadata_filename)
                        
                        if os.path.exists(metadata_path):
                            try:
                                with open(metadata_path, 'r', encoding='utf-8') as f:
                                    metadata = json.load(f)
                            except Exception as e:
                                logger.warning(f"è¯»å–å…ƒæ•°æ®æ–‡ä»¶å¤±è´¥ {metadata_filename}: {e}")
                        else:
                            # å‘åå…¼å®¹ï¼šå°è¯•æ—§æ ¼å¼çš„å…ƒæ•°æ®æ–‡ä»¶
                            if filename.startswith('result_') and '_' in filename:
                                unique_id = filename.split('_')[1]
                                old_metadata_filename = f"metadata_{unique_id}.json"
                                old_metadata_path = os.path.join(output_dir, old_metadata_filename)
                                if os.path.exists(old_metadata_path):
                                    try:
                                        with open(old_metadata_path, 'r', encoding='utf-8') as f:
                                            metadata = json.load(f)
                                    except Exception as e:
                                        logger.warning(f"è¯»å–æ—§æ ¼å¼å…ƒæ•°æ®æ–‡ä»¶å¤±è´¥ {old_metadata_filename}: {e}")
                    
                    image_info = {
                        'filename': filename,
                        'url': f'/outputs/{filename}',
                        'size': stat.st_size,
                        'created_time': datetime.fromtimestamp(stat.st_ctime).isoformat(),
                        'modified_time': datetime.fromtimestamp(stat.st_mtime).isoformat(),
                        'metadata': metadata,
                        'has_metadata': bool(metadata)
                    }
                    
                    # å¦‚æœæœ‰å…ƒæ•°æ®ï¼Œæ·»åŠ ä¸€äº›å…³é”®ä¿¡æ¯åˆ°ä¸»å¯¹è±¡ä¸­ä¾¿äºæ˜¾ç¤º
                    if metadata:
                        parameters = metadata.get('parameters', {})
                        image_info.update({
                            'workflow': metadata.get('workflow_filename', 'unknown'),
                            'prompt': parameters.get('positive_prompt', ''),
                            'negative_prompt': parameters.get('negative_prompt', ''),
                            'steps': parameters.get('steps', ''),
                            'cfg': parameters.get('cfg', ''),
                            'seed': parameters.get('seed', ''),
                            'sampler': parameters.get('sampler', ''),
                            'width': parameters.get('width', ''),
                            'height': parameters.get('height', '')
                        })
                    
                    images.append(image_info)
        
        # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åˆ—
        images.sort(key=lambda x: x['modified_time'], reverse=True)
        
        return jsonify({
            'success': True,
            'images': images,
            'total': len(images)
        })
    except Exception as e:
        logger.error(f"è·å–ç”Ÿæˆå›¾ç‰‡åˆ—è¡¨å¤±è´¥: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/image-metadata/<path:filename>')
def get_image_metadata(filename):
    """è·å–å•ä¸ªå›¾ç‰‡çš„è¯¦ç»†å…ƒæ•°æ®ï¼ˆå…¼å®¹æ–°æ—§ä¸¤ç§å…ƒæ•°æ®å‘½åï¼‰"""
    try:
        output_dir = os.path.join(os.path.dirname(__file__), 'outputs')

        # 1) æ–°æ ¼å¼ï¼š<output_filename>.jsonï¼ˆä¸å›¾ç‰‡åŒåï¼‰
        name_part, ext = os.path.splitext(filename)
        new_metadata_filename = f"{name_part}.json"
        new_metadata_path = os.path.join(output_dir, new_metadata_filename)
        if os.path.exists(new_metadata_path):
            try:
                with open(new_metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                return jsonify({'success': True, 'metadata': metadata})
            except Exception as e:
                logger.warning(f"è¯»å–æ–°æ ¼å¼å…ƒæ•°æ®å¤±è´¥ {new_metadata_filename}: {e}")

        # 2) æ—§æ ¼å¼å›é€€ï¼šmetadata_<unique_id>.jsonï¼ˆä»æ–‡ä»¶åä¸­æå–ç¬¬äºŒæ®µIDï¼‰
        unique_id = filename.split('_')[1] if '_' in filename else None
        if unique_id:
            old_metadata_filename = f"metadata_{unique_id}.json"
            old_metadata_path = os.path.join(output_dir, old_metadata_filename)
            if os.path.exists(old_metadata_path):
                try:
                    with open(old_metadata_path, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                    return jsonify({'success': True, 'metadata': metadata})
                except Exception as e:
                    logger.warning(f"è¯»å–æ—§æ ¼å¼å…ƒæ•°æ®å¤±è´¥ {old_metadata_filename}: {e}")

        return jsonify({'success': False, 'error': 'å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨'}), 404
    except Exception as e:
        logger.error(f"è·å–å›¾ç‰‡å…ƒæ•°æ®å¤±è´¥: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

def analyze_workflow_structure(workflow_data):
    """åˆ†æå·¥ä½œæµç»“æ„ï¼Œæå–å‚æ•°ä¿¡æ¯ï¼ˆUIæ ¼å¼ï¼‰"""
    nodes = workflow_data.get('nodes', [])
    analysis = {
        'type': 'unknown',
        'has_text_to_image': False,
        'has_image_to_image': False,
        'has_controlnet': False,
        'has_inpaint': False,
        'has_upscaler': False,
        'image_inputs': [],
        'resize_nodes': [],
        'default_values': {
            'width': 1024,    # é»˜è®¤å€¼ï¼Œä¼šè¢«JSONæ–‡ä»¶ä¸­çš„å®é™…å€¼è¦†ç›–
            'height': 1024,   # é»˜è®¤å€¼ï¼Œä¼šè¢«JSONæ–‡ä»¶ä¸­çš„å®é™…å€¼è¦†ç›–
            'steps': 20,      # é»˜è®¤å€¼ï¼Œä¼šè¢«JSONæ–‡ä»¶ä¸­çš„å®é™…å€¼è¦†ç›–
            'cfg': 1.0,       # é»˜è®¤å€¼ï¼Œä¼šè¢«JSONæ–‡ä»¶ä¸­çš„å®é™…å€¼è¦†ç›–
            'seed': -1,       # é»˜è®¤å€¼ï¼Œä¼šè¢«JSONæ–‡ä»¶ä¸­çš„å®é™…å€¼è¦†ç›–
            'sampler': 'euler',   # é»˜è®¤å€¼ï¼Œä¼šè¢«JSONæ–‡ä»¶ä¸­çš„å®é™…å€¼è¦†ç›–
            'scheduler': 'normal', # é»˜è®¤å€¼ï¼Œä¼šè¢«JSONæ–‡ä»¶ä¸­çš„å®é™…å€¼è¦†ç›–
            'denoise': 1.0,       # é»˜è®¤å€¼ï¼Œä¼šè¢«JSONæ–‡ä»¶ä¸­çš„å®é™…å€¼è¦†ç›–
            'positive_prompt': '',
            'negative_prompt': ''
        },
        'required_inputs': [],
        'optional_inputs': [],
        'model_loaders': [],
        'controlnet_configs': [],  # æ–°å¢ï¼šControlNeté…ç½®
        'has_negative_prompt': False,
        # LoRA ç›¸å…³ä¿¡æ¯ï¼ˆæ–°å¢ï¼‰
        'lora': {
            'has_lora': False,
            'lora_nodes': [],
            'detected_lora_names': [],
            'triggers': []  # å½¢å¦‚ [{ 'lora_name': 'xxx.safetensors', 'triggers': ['word1','word2'] }]
        },
        # æ–°å¢ï¼šæŒ‰èŠ‚ç‚¹åˆ†ç»„çš„é€šç”¨å‚æ•°è§†å›¾ï¼Œç¡®ä¿æ— é—æ¼
        'node_groups': [],  # å½¢å¦‚ [{ id, type, title, params: [{name,label,kind,default,node_id,widget_index}], order }]
        
        # æ–°å¢ï¼šè¾“å‡ºæ§åˆ¶è®¾ç½®
        'output_settings': {
            'has_output_control': False,
            'output_dimensions': {'width': 1024, 'height': 1024},
            'size_control_mode': 'fixed',
            'batch_settings': {'batch_size': 1},
            'connected_primitive_nodes': []  # è¿æ¥çš„PrimitiveNodeä¿¡æ¯
        }
    }
    
    for node in nodes:
        # UIæ ¼å¼ä½¿ç”¨typeå­—æ®µ
        node_type = node.get('type', '')
        node_id = node.get('id')
        
        # âš ï¸ å…ˆè¿›è¡Œè¾“å‡ºæ§åˆ¶æ£€æµ‹ï¼Œé¿å…è¢«åç»­çš„è¿‡æ»¤é€»è¾‘è·³è¿‡
        if node_type == 'PrimitiveNode':
            title = node.get('title', '').lower()
            widgets_values = node.get('widgets_values', [])
            # æ£€æµ‹width/heightçš„PrimitiveNodeç”¨äºè¾“å‡ºæ§åˆ¶
            if title in ['width', 'height'] and len(widgets_values) >= 1:
                analysis['output_settings']['has_output_control'] = True
                analysis['output_settings']['connected_primitive_nodes'].append({
                    'id': node_id,
                    'type': title,
                    'value': widgets_values[0] if len(widgets_values) > 0 else 1024,
                    'mode': widgets_values[1] if len(widgets_values) > 1 else 'fixed'
                })
                # æ›´æ–°è¾“å‡ºå°ºå¯¸
                if title == 'width':
                    analysis['output_settings']['output_dimensions']['width'] = widgets_values[0]
                elif title == 'height':
                    analysis['output_settings']['output_dimensions']['height'] = widgets_values[0]
                # æ›´æ–°æ§åˆ¶æ¨¡å¼
                if len(widgets_values) > 1 and widgets_values[1]:
                    analysis['output_settings']['size_control_mode'] = widgets_values[1]
        
        # è¿‡æ»¤æ‰åº”è¯¥åœ¨ä¸“é—¨åŒºåŸŸæ˜¾ç¤ºçš„èŠ‚ç‚¹ç±»å‹ï¼Œé¿å…åœ¨node_groupsä¸­é‡å¤
        excluded_node_types = {
            # åŸºç¡€å‚æ•°åŒºçš„èŠ‚ç‚¹
            'BasicScheduler', 'FluxGuidance', 'RandomNoise', 'EmptySD3LatentImage',
            # æ¨¡å‹åŠ è½½å™¨ç›¸å…³èŠ‚ç‚¹
            'ModelSamplingFlux', 'CLIPVisionEncode', 'StyleModelApply',
            'NunchakuFluxDiTLoader', 'DualCLIPLoader', 'VAELoader', 'CLIPVisionLoader', 
            'StyleModelLoader', 'NunchakuFluxLoraLoader',
            # ä¸“ç”¨å¡ç‰‡æ¸²æŸ“çš„èŠ‚ç‚¹
            'ImageAndMaskResizeNode', 'ImagePadForOutpaint',
            # ä¸éœ€è¦ç”¨æˆ·é…ç½®çš„èŠ‚ç‚¹
            'Note', 'BasicGuider', 'SamplerCustomAdvanced', 'VAEDecode', 'SaveImage', 'LoadImage'
        }
        
        # é€šç”¨å‚æ•°é‡‡é›†ï¼šå°†æ¯ä¸ªèŠ‚ç‚¹å¯ç¼–è¾‘çš„ widgets æ˜ å°„ä¸ºé€šç”¨å‚æ•°
        try:
            widgets_values = node.get('widgets_values', [])
            inputs = node.get('inputs', []) or []
            # ä» inputs å†…çš„ widget name é¡ºåºæ¨æ–­å‚æ•°å«ä¹‰ï¼›æ— åˆ™ç”¨ p0,p1...
            param_names = []
            # é’ˆå¯¹éƒ¨åˆ†èŠ‚ç‚¹åšç²¾ç¡®å‘½åï¼Œé¿å…æŠŠè¾“å…¥è¿çº¿åï¼ˆimage/maskç­‰ï¼‰é”™å½“å‚æ•°å
            if 'ImageAndMaskResizeNode' in node_type:
                param_names = ['width', 'height', 'resize_method', 'crop', 'mask_blur_radius']
            elif 'ImagePadForOutpaint' in node_type:
                # ComfyUI åŸç”Ÿå‚æ•°é¡ºåºï¼šleft, top, right, bottom, feathering
                param_names = ['left', 'top', 'right', 'bottom', 'feathering']
            else:
                for inp in inputs:
                    if isinstance(inp, dict):
                        w = inp.get('widget') or {}
                        pname = w.get('name') or inp.get('name')
                        if isinstance(pname, str) and pname:
                            param_names.append(pname)
            # å…œåº•ç”Ÿæˆå‚æ•°å
            if not param_names and isinstance(widgets_values, list):
                param_names = [f"p{i}" for i in range(len(widgets_values))]

            # ç‰¹æ®Šå¤„ç†ï¼šwidth/heightçš„PrimitiveNodeç”±è¾“å‡ºè®¾ç½®åŒºåŸŸå¤„ç†ï¼Œå®Œå…¨æ’é™¤
            if node_type == 'PrimitiveNode':
                title = node.get('title', '').lower()
                if title in ['width', 'height']:
                    continue  # è·³è¿‡ï¼Œç”±è¾“å‡ºè®¾ç½®åŒºåŸŸå¤„ç†

            # ä»…å½“è¯¥èŠ‚ç‚¹ç¡®æœ‰ widgets_values ä¸”ä¸ºåˆ—è¡¨æ—¶çº³å…¥ï¼Œå¹¶ä¸”ä¸åœ¨æ’é™¤åˆ—è¡¨ä¸­
            if isinstance(widgets_values, list) and len(widgets_values) > 0 and node_type not in excluded_node_types:
                params = []
                for idx, default_val in enumerate(widgets_values):
                    # è¿‡æ»¤æ˜æ˜¾æ˜¯ç³»ç»Ÿ/å ä½å‚æ•°çš„ None ä½†ä¿ç•™ä»¥å…é—æ¼
                    name = param_names[idx] if idx < len(param_names) else f"p{idx}"
                    
                    # è¿‡æ»¤æ‰é€šå¸¸æ˜¯è¿æ¥è¾“å…¥è€Œéç”¨æˆ·å¯ç¼–è¾‘å‚æ•°çš„å­—æ®µ
                    connection_inputs = {'model', 'conditioning', 'clip_vision', 'style_model', 'image', 'latent_image', 
                                       'samples', 'vae', 'clip', 'guider', 'sampler', 'sigmas', 'noise', 
                                       'style_model_apply', 'clip_vision_output'}
                    if name in connection_inputs:
                        continue
                    
                    # ç‰¹æ®Šå¤„ç†ï¼šå¯¹äºwidth/height PrimitiveNodeï¼Œåªæ˜¾ç¤ºæ§åˆ¶æ¨¡å¼ï¼ˆç¬¬äºŒä¸ªå‚æ•°ï¼‰ï¼Œå› ä¸ºæ•°å€¼å·²åœ¨åŸºç¡€å‚æ•°åŒº
                    if node_type == 'PrimitiveNode':
                        node_title = node.get('title', '').lower()
                        if node_title in ['width', 'height'] and idx == 0:
                            # è·³è¿‡ç¬¬ä¸€ä¸ªå‚æ•°ï¼ˆæ•°å€¼ï¼‰ï¼Œå› ä¸ºå·²åœ¨åŸºç¡€å‚æ•°åŒºæ˜¾ç¤º
                            continue
                    
                    # ä¸ºå¸¸è§å‚æ•°åæä¾›å‹å¥½çš„ä¸­æ–‡æ˜¾ç¤º
                    param_labels = {
                        'model': 'æ¨¡å‹',
                        'conditioning': 'æ¡ä»¶',
                        'clip_vision': 'è§†è§‰CLIP',
                        'style_model': 'é£æ ¼æ¨¡å‹',
                        'text': 'æ–‡æœ¬',
                        'image': 'å›¾åƒ',
                        'sampler_name': 'é‡‡æ ·å™¨',
                        'scheduler': 'è°ƒåº¦å™¨',
                        'steps': 'æ­¥æ•°',
                        'cfg': 'CFGå¼•å¯¼å¼ºåº¦',
                        'denoise': 'å»å™ªå¼ºåº¦',
                        'guidance': 'å¼•å¯¼å¼ºåº¦',
                        'seed': 'éšæœºç§å­',
                        'width': 'å®½åº¦',
                        'height': 'é«˜åº¦',
                        'batch_size': 'æ‰¹é‡å¤§å°',
                        'filename_prefix': 'æ–‡ä»¶åå‰ç¼€',
                        'value': 'æ•°å€¼',
                        'p1': 'æ§åˆ¶æ¨¡å¼'  # PrimitiveNodeçš„ç¬¬äºŒä¸ªå‚æ•°é€šå¸¸æ˜¯æ§åˆ¶æ¨¡å¼
                    }
                    
                    # ä¸ºPrimitiveNodeæä¾›æ›´ç²¾ç¡®çš„æ ‡ç­¾
                    if node_type == 'PrimitiveNode':
                        node_title = node.get('title', '').lower()
                        if node_title in ['width', 'height']:
                            if idx == 1:  # æ§åˆ¶æ¨¡å¼å‚æ•°
                                title_map = {'width': 'å®½åº¦', 'height': 'é«˜åº¦'}
                                chinese_title = title_map.get(node_title, node_title.title())
                                label = f"{chinese_title}æ§åˆ¶æ¨¡å¼"
                            else:
                                label = param_labels.get(name, name)
                        else:
                            label = param_labels.get(name, name)
                    else:
                        label = param_labels.get(name, name)
                    
                    # æ¨æ–­ç±»å‹ï¼šnumber / boolean / text / select
                    kind = 'text'
                    if isinstance(default_val, bool):
                        kind = 'boolean'
                    elif isinstance(default_val, (int, float)):
                        kind = 'number'
                    elif isinstance(default_val, str):
                        # å¸¸è§é€‰æ‹©ç±»å€¼ä¿æŒä¸º textï¼Œç”±å‰ç«¯ä¸å¼ºçº¦æŸ
                        kind = 'text'
                    params.append({
                        'name': name,
                        'label': label,
                        'kind': kind,
                        'default': default_val,
                        'node_id': node_id,
                        'widget_index': idx
                    })
                # å‹å¥½çš„èŠ‚ç‚¹æ ‡é¢˜
                title = node.get('title') or node_type
                analysis['node_groups'].append({
                    'id': node_id,
                    'type': node_type,
                    'title': title,
                    'order': node.get('order', 9999),
                    'params': params
                })
        except Exception as _e:
            try:
                logger.debug(f"é‡‡é›†èŠ‚ç‚¹é€šç”¨å‚æ•°å¤±è´¥ node#{node_id} {node_type}: {_e}")
            except Exception:
                pass
        
        # æ£€æŸ¥æ–‡ç”Ÿå›¾
        if 'KSampler' in node_type:
            analysis['has_text_to_image'] = True
            analysis['type'] = 'text-to-image'
        
        # è¾“å‡ºæ§åˆ¶æ£€æµ‹å·²åœ¨å¾ªç¯å¼€å§‹æ—¶å®Œæˆ
        
        # æ£€æµ‹æ‰¹é‡è®¾ç½®
        if 'batch_size' in str(node.get('widgets_values', [])):
            widgets_values = node.get('widgets_values', [])
            # å¯»æ‰¾batch_sizeå‚æ•°çš„ä½ç½®
            if node_type in WIDGET_INDEX_MAP and 'batch_size' in WIDGET_INDEX_MAP[node_type]:
                batch_idx = WIDGET_INDEX_MAP[node_type]['batch_size']
                if len(widgets_values) > batch_idx:
                    analysis['output_settings']['batch_settings']['batch_size'] = widgets_values[batch_idx]
            
            # æå–é»˜è®¤å‚æ•° - UIæ ¼å¼ä¸­å‚æ•°åœ¨widgets_valuesä¸­
            # UIæ ¼å¼KSampler: [seed, seed_mode, steps, cfg, sampler, scheduler, denoise]
            widgets_values = node.get('widgets_values', [])
            if widgets_values and len(widgets_values) >= 7:
                # å®‰å…¨è½¬æ¢æ•°å€¼
                try:
                    analysis['default_values']['seed'] = int(widgets_values[0]) if widgets_values[0] is not None and str(widgets_values[0]).replace('-', '').isdigit() else -1
                except (ValueError, TypeError):
                    analysis['default_values']['seed'] = -1
                
                try:
                    analysis['default_values']['steps'] = int(widgets_values[2]) if widgets_values[2] is not None and str(widgets_values[2]).isdigit() else 20
                except (ValueError, TypeError):
                    analysis['default_values']['steps'] = 20
                
                try:
                    analysis['default_values']['cfg'] = float(widgets_values[3]) if widgets_values[3] is not None and str(widgets_values[3]).replace('.', '').replace('-', '').isdigit() else 1.0
                except (ValueError, TypeError):
                    analysis['default_values']['cfg'] = 1.0
                
                analysis['default_values']['sampler'] = str(widgets_values[4]) if widgets_values[4] is not None else 'euler'
                analysis['default_values']['scheduler'] = str(widgets_values[5]) if widgets_values[5] is not None else 'normal'
        
        # æ£€æŸ¥KSamplerSelectï¼ˆNunchaku Flux.1ä½¿ç”¨ï¼‰
        elif 'KSamplerSelect' in node_type:
            analysis['has_text_to_image'] = True
            analysis['type'] = 'text-to-image'
            
            # KSamplerSelectåªæœ‰sampler_nameå‚æ•°
            widgets_values = node.get('widgets_values', [])
            if widgets_values and len(widgets_values) >= 1:
                analysis['default_values']['sampler'] = str(widgets_values[0]) if widgets_values[0] is not None else 'euler'
        
        # æ£€æŸ¥CheckpointLoader
        elif 'CheckpointLoader' in node_type:
            analysis['has_text_to_image'] = True
            analysis['type'] = 'text-to-image'
        
        # æ£€æŸ¥å›¾ç”Ÿå›¾ï¼ˆä½†ä¸åŒ…æ‹¬LoadImageOutputï¼Œå®ƒæœ‰ä¸“é—¨çš„å¤„ç†é€»è¾‘ï¼‰
        elif ('LoadImage' in node_type or 'ImageLoader' in node_type) and 'LoadImageOutput' not in node_type:
            analysis['has_image_to_image'] = True
            # ä¼˜å…ˆåˆ¤å®šä¸ºå›¾ç”Ÿå›¾ï¼ˆKontext ç­‰ç¼–è¾‘ç±»å·¥ä½œæµå¸¸åŒæ—¶åŒ…å«KSamplerï¼‰
            analysis['type'] = 'image-to-image'
            
            analysis['image_inputs'].append({
                'node_id': node_id,
                'type': 'image',
                'required': True,
                'name': 'è¾“å…¥å›¾åƒ',
                'description': 'é€‰æ‹©è¦å¤„ç†çš„å›¾åƒ'
            })
        
        # æ£€æŸ¥LoadImageOutputï¼ˆKontextå·¥ä½œæµä¸­çš„å›¾åƒè¾“å…¥ï¼‰
        elif 'LoadImageOutput' in node_type:
            analysis['has_image_to_image'] = True
            # ä¼˜å…ˆåˆ¤å®šä¸ºå›¾ç”Ÿå›¾
            analysis['type'] = 'image-to-image'
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é»˜è®¤å›¾åƒå€¼
            widgets_values = node.get('widgets_values', [])
            has_default_image = False
            if widgets_values and len(widgets_values) > 0:
                default_image = widgets_values[0]
                # è°ƒè¯•ä¿¡æ¯
                logger.info(f"LoadImageOutput èŠ‚ç‚¹ {node_id} é»˜è®¤å›¾åƒå€¼: '{default_image}'")
                # å¦‚æœé»˜è®¤å›¾åƒä¸æ˜¯ç©ºçš„ï¼Œä¸”ä¸æ˜¯å ä½ç¬¦ï¼Œåˆ™è®¤ä¸ºè¿™ä¸ªè¾“å…¥æ˜¯å¯é€‰çš„
                if (isinstance(default_image, str) and 
                    default_image.strip() and 
                    not default_image.startswith('Choose') and
                    not default_image.startswith('Select') and
                    not default_image.startswith('No image') and
                    default_image != '' and
                    '[' in default_image):  # åŒ…å«æ–¹æ‹¬å·çš„é€šå¸¸æ˜¯é»˜è®¤å›¾åƒæ–‡ä»¶å
                    has_default_image = True
                    logger.info(f"LoadImageOutput èŠ‚ç‚¹ {node_id} è¯†åˆ«ä¸ºå¯é€‰è¾“å…¥")
            
            # å¯¹äºKontextå·¥ä½œæµï¼Œæ ¹æ®orderå­—æ®µç¡®å®šå“ªä¸ªæ˜¯ä¸»è¦çš„å›¾åƒè¾“å…¥
            # orderè¾ƒå°çš„èŠ‚ç‚¹æ˜¯ä¸»è¦çš„å›¾åƒè¾“å…¥ï¼ˆå¿…é¡»çš„ï¼‰ï¼Œorderè¾ƒå¤§çš„èŠ‚ç‚¹æ˜¯è¾…åŠ©çš„å›¾åƒè¾“å…¥ï¼ˆå¯é€‰çš„ï¼‰
            existing_image_inputs = [n for n in analysis['image_inputs'] if n.get('type') == 'image']
            node_order = node.get('order', 999)  # å¦‚æœæ²¡æœ‰orderå­—æ®µï¼Œé»˜è®¤ä¸º999
            
            # æ£€æŸ¥é»˜è®¤å›¾åƒæ˜¯å¦æ˜¯ç¤ºä¾‹å›¾åƒ
            is_example_image = False
            if has_default_image and widgets_values and len(widgets_values) > 0:
                default_image = widgets_values[0]
                # å¦‚æœé»˜è®¤å›¾åƒæ–‡ä»¶ååŒ…å«ç¤ºä¾‹ç›¸å…³çš„å…³é”®è¯ï¼Œè®¤ä¸ºæ˜¯ç¤ºä¾‹å›¾åƒ
                if any(keyword in default_image.lower() for keyword in ['example', 'demo', 'sample', 'test', 'pikachu', 'yarn']):
                    is_example_image = True
                    logger.info(f"LoadImageOutput èŠ‚ç‚¹ {node_id} è¯†åˆ«ä¸ºç¤ºä¾‹å›¾åƒ")
            
            # åˆ†æImageStitchèŠ‚ç‚¹çš„è¿æ¥å…³ç³»æ¥ç¡®å®šå¿…é€‰æ€§
            # è¿æ¥åˆ°ImageStitchçš„image1è¾“å…¥çš„æ˜¯ä¸»å›¾åƒï¼ˆå¿…éœ€ï¼‰ï¼Œè¿æ¥åˆ°image2çš„æ˜¯è¾…åŠ©å›¾åƒï¼ˆå¯é€‰ï¼‰
            is_optional = False
            links = workflow_data.get('links', [])
            
            for link in links:
                # æ”¯æŒæ–°æ ¼å¼ï¼šlinks = [link_id, src_node_id, src_slot, dst_node_id, dst_slot, type]
                if len(link) >= 6:
                    link_id, src_id, src_slot, dst_id, dst_slot, link_type = link
                    # æ£€æŸ¥è¿™ä¸ªLoadImageOutputèŠ‚ç‚¹æ˜¯å¦è¿æ¥åˆ°ImageStitch
                    if str(src_id) == str(node_id):
                        # æ‰¾åˆ°ç›®æ ‡èŠ‚ç‚¹
                        dst_node = next((n for n in nodes if str(n.get('id')) == str(dst_id)), None)
                        if dst_node and 'ImageStitch' in dst_node.get('type', ''):
                            # æ£€æŸ¥è¿æ¥åˆ°ImageStitchçš„å“ªä¸ªè¾“å…¥
                            if dst_slot == 0:  # image1 - ä¸»å›¾åƒï¼Œå¿…éœ€
                                is_optional = False
                                logger.info(f"LoadImageOutput èŠ‚ç‚¹ {node_id} è¿æ¥åˆ°ImageStitchçš„image1 (é“¾æ¥ {link_id})")
                                logger.info(f"LoadImageOutput èŠ‚ç‚¹ {node_id} è¿æ¥åˆ°ImageStitchçš„image1ï¼Œæ ‡è®°ä¸ºä¸»å›¾åƒ")
                                break
                            elif dst_slot == 1:  # image2 - è¾…åŠ©å›¾åƒï¼Œå¯é€‰
                                is_optional = True
                                logger.info(f"LoadImageOutput èŠ‚ç‚¹ {node_id} è¿æ¥åˆ°ImageStitchçš„image2 (é“¾æ¥ {link_id})")
                                logger.info(f"LoadImageOutput èŠ‚ç‚¹ {node_id} è¿æ¥åˆ°ImageStitchçš„image2ï¼Œæ ‡è®°ä¸ºè¾…åŠ©å›¾åƒ")
                                break
            
            if is_optional:
                logger.info(f"LoadImageOutput èŠ‚ç‚¹ {node_id} æ ‡è®°ä¸ºå¯é€‰çš„è¾“å…¥")
            else:
                logger.info(f"LoadImageOutput èŠ‚ç‚¹ {node_id} æ ‡è®°ä¸ºå¿…é¡»çš„è¾“å…¥")
            
            analysis['image_inputs'].append({
                'node_id': node_id,
                'type': 'image',
                'required': not is_optional,  # å¦‚æœæœ‰é»˜è®¤å›¾åƒæˆ–æ˜¯ç¬¬äºŒä¸ªå›¾åƒï¼Œåˆ™ä¸æ˜¯å¿…éœ€çš„
                'name': f'è¾“å…¥å›¾åƒ {len(existing_image_inputs) + 1}',
                'description': f'é€‰æ‹©è¦å¤„ç†çš„å›¾åƒ{" (å¯é€‰)" if is_optional else " (å¿…éœ€)"}'
            })
        
        # è¯†åˆ« ImageAndMaskResizeNodeï¼ˆå›¾åƒä¸æ©ç ç¼©æ”¾ï¼‰
        elif 'ImageAndMaskResizeNode' in node_type:
            widgets_values = node.get('widgets_values', [])
            analysis['resize_nodes'].append({
                'node_id': node_id,
                'type': 'ImageAndMaskResizeNode',
                'name': 'å›¾åƒä¸æ©ç ç¼©æ”¾',
                'parameters': {
                    'width': widgets_values[0] if len(widgets_values) > 0 else 1024,
                    'height': widgets_values[1] if len(widgets_values) > 1 else 1024,
                    'resize_method': widgets_values[2] if len(widgets_values) > 2 else 'nearest-exact',
                    'crop': widgets_values[3] if len(widgets_values) > 3 else 'center',
                    'mask_blur_radius': widgets_values[4] if len(widgets_values) > 4 else 10
                }
            })
            # è¯¥å·¥ä½œæµå…·æœ‰åˆ†è¾¨ç‡è¾“å…¥
            analysis['has_resolution'] = True

        # è¯†åˆ« Outpaint æ‰©å›¾èŠ‚ç‚¹
        elif 'ImagePadForOutpaint' in node_type:
            widgets_values = node.get('widgets_values', [])
            # é¡ºåºæŒ‰åŸç”ŸèŠ‚ç‚¹ï¼šå·¦ã€ä¸Šã€å³ã€ä¸‹ã€ç¾½åŒ–
            analysis.setdefault('outpaint_nodes', []).append({
                'node_id': node_id,
                'type': 'ImagePadForOutpaint',
                'name': 'æ‰©å›¾è¾¹è·',
                'parameters': {
                    'pad_left': widgets_values[0] if len(widgets_values) > 0 else 0,
                    'pad_up': widgets_values[1] if len(widgets_values) > 1 else 0,
                    'pad_right': widgets_values[2] if len(widgets_values) > 2 else 0,
                    'pad_down': widgets_values[3] if len(widgets_values) > 3 else 0,
                    'feather': widgets_values[4] if len(widgets_values) > 4 else 24
                }
            })

        # æ£€æŸ¥ControlNetç›¸å…³èŠ‚ç‚¹ï¼ˆä½†ä¸ä½œä¸ºå›¾åƒè¾“å…¥ï¼‰
        elif 'ControlNet' in node_type:
            analysis['has_controlnet'] = True
            analysis['type'] = 'controlnet'
            
            # å¦‚æœæ˜¯ControlNetLoaderï¼Œæ·»åŠ åˆ°controlnet_configs
            if 'ControlNetLoader' in node_type:
                widgets_values = node.get('widgets_values', [])
                controlnet_config = {
                    'node_id': node_id,
                    'type': 'ControlNetLoader',
                    'name': 'ControlNetæ¨¡å‹åŠ è½½å™¨',
                    'parameters': {}
                }
                
                if len(widgets_values) >= 1:
                    controlnet_config['parameters'] = {
                        'control_net_name': widgets_values[0] if widgets_values[0] is not None else ''
                    }
                
                analysis['controlnet_configs'].append(controlnet_config)
            
            # å¦‚æœæ˜¯ControlNetApplyAdvancedï¼Œæ·»åŠ åˆ°controlnet_configs
            elif 'ControlNetApplyAdvanced' in node_type:
                widgets_values = node.get('widgets_values', [])
                controlnet_config = {
                    'node_id': node_id,
                    'type': 'ControlNetApplyAdvanced',
                    'name': 'ControlNetåº”ç”¨å™¨',
                    'parameters': {}
                }
                
                if len(widgets_values) >= 3:
                    controlnet_config['parameters'] = {
                        'strength': widgets_values[0] if widgets_values[0] is not None else 1.0,
                        'start_percent': widgets_values[1] if widgets_values[1] is not None else 0.0,
                        'end_percent': widgets_values[2] if widgets_values[2] is not None else 1.0
                    }
                
                analysis['controlnet_configs'].append(controlnet_config)
            
            # å¦‚æœæ˜¯SetUnionControlNetTypeï¼Œæ·»åŠ åˆ°controlnet_configs
            elif 'SetUnionControlNetType' in node_type:
                widgets_values = node.get('widgets_values', [])
                controlnet_config = {
                    'node_id': node_id,
                    'type': 'SetUnionControlNetType',
                    'name': 'ControlNetè”åˆç±»å‹è®¾ç½®',
                    'parameters': {}
                }
                
                if len(widgets_values) >= 1:
                    controlnet_config['parameters'] = {
                        'union_type': widgets_values[0] if widgets_values[0] is not None else 'union'
                    }
                
                analysis['controlnet_configs'].append(controlnet_config)
            
            # æ³¨æ„ï¼šControlNetç›¸å…³èŠ‚ç‚¹ä¸æ·»åŠ åˆ°image_inputsï¼Œå› ä¸ºå®ƒä»¬ä¸æ˜¯çœŸæ­£çš„å›¾åƒè¾“å…¥èŠ‚ç‚¹
        
        # æ£€æŸ¥ä¿®å¤ï¼ˆä»…æ ‡è®°ç±»å‹ï¼Œä¸æ–°å¢å›¾åƒè¾“å…¥ï¼Œé¿å…ä¸ LoadImage é‡å¤ï¼‰
        elif 'Inpaint' in node_type:
            analysis['has_inpaint'] = True
            analysis['type'] = 'inpaint'
        
        # æ£€æŸ¥è¶…åˆ†è¾¨ç‡
        elif 'Upscale' in node_type or 'Upscaler' in node_type:
            analysis['has_upscaler'] = True
        
        # æ£€æŸ¥BasicSchedulerèŠ‚ç‚¹è·å–stepså’Œschedulerï¼ˆRedux Dev ç­‰ Flux å·¥ä½œæµï¼‰
        elif 'BasicScheduler' in node_type:
            # æ ‡è®°ä¸ºæ–‡ç”Ÿå›¾å·¥ä½œæµï¼Œä»¥ä¾¿å‰ç«¯åŸºç¡€å‚æ•°åŒºæ¸²æŸ“è°ƒåº¦å™¨ç­‰æ§ä»¶
            analysis['has_text_to_image'] = True
            analysis['type'] = 'text-to-image'
            widgets_values = node.get('widgets_values', [])
            if len(widgets_values) >= 3:
                # scheduler
                try:
                    analysis['default_values']['scheduler'] = str(widgets_values[0]) if widgets_values[0] is not None else 'simple'
                except Exception:
                    analysis['default_values']['scheduler'] = 'simple'
                # steps
                try:
                    analysis['default_values']['steps'] = int(widgets_values[1]) if widgets_values[1] is not None else 20
                except Exception:
                    analysis['default_values']['steps'] = 20
                # denoiseï¼ˆéƒ¨åˆ†å·¥ä½œæµé»˜è®¤å€¼ä¸º1.0ï¼‰
                try:
                    analysis['default_values']['denoise'] = float(widgets_values[2]) if widgets_values[2] is not None else 1.0
                except Exception:
                    analysis['default_values']['denoise'] = 1.0
            else:
                analysis['default_values'].setdefault('scheduler', 'simple')
                analysis['default_values'].setdefault('steps', 20)
                analysis['default_values'].setdefault('denoise', 1.0)
        
        # æ£€æŸ¥FluxGuidanceèŠ‚ç‚¹è·å– guidanceï¼ˆä¸å†æ˜ å°„åˆ° cfgï¼‰
        elif 'FluxGuidance' in node_type:
            widgets_values = node.get('widgets_values', [])
            if len(widgets_values) >= 1:
                try:
                    analysis['default_values']['guidance'] = float(widgets_values[0]) if widgets_values[0] is not None and str(widgets_values[0]).replace('.', '').replace('-', '').isdigit() else 7.0
                except (ValueError, TypeError):
                    analysis['default_values']['guidance'] = 7.0

        # è®°å½• InpaintModelConditioning çš„ noise_mask é»˜è®¤å€¼
        elif 'InpaintModelConditioning' in node_type:
            widgets_values = node.get('widgets_values', [])
            if len(widgets_values) >= 1:
                try:
                    analysis['default_values']['noise_mask'] = bool(widgets_values[0])
                except Exception:
                    analysis['default_values']['noise_mask'] = False
        
        # æ£€æŸ¥NunchakuTextEncoderLoaderèŠ‚ç‚¹
        elif 'NunchakuTextEncoderLoader' in node_type:
            widgets_values = node.get('widgets_values', [])
            model_loader_info = {
                'node_id': node_id,
                'type': 'NunchakuTextEncoderLoader',
                'name': 'æ–‡æœ¬ç¼–ç å™¨åŠ è½½å™¨',
                'parameters': {}
            }
            
            if len(widgets_values) >= 6:
                model_loader_info['parameters'] = {
                    'model_type': widgets_values[0] if len(widgets_values) > 0 else 'flux',
                    'text_encoder1': widgets_values[1] if len(widgets_values) > 1 else 't5xxl_fp16.safetensors',
                    'text_encoder2': widgets_values[2] if len(widgets_values) > 2 else 'clip_l.safetensors',
                    't5_min_length': widgets_values[3] if len(widgets_values) > 3 else 512,
                    'use_4bit_t5': widgets_values[4] if len(widgets_values) > 4 else 'disable',
                    'int4_model': widgets_values[5] if len(widgets_values) > 5 else 'none'
                }
            
            analysis['model_loaders'].append(model_loader_info)
        
        # æ£€æŸ¥NunchakuFluxDiTLoaderèŠ‚ç‚¹
        elif 'NunchakuFluxDiTLoader' in node_type:
            widgets_values = node.get('widgets_values', [])
            model_loader_info = {
                'node_id': node_id,
                'type': 'NunchakuFluxDiTLoader',
                'name': 'Flux DiTæ¨¡å‹åŠ è½½å™¨',
                'parameters': {}
            }
            
            if len(widgets_values) >= 7:
                model_loader_info['parameters'] = {
                    'model_path': widgets_values[0] if len(widgets_values) > 0 else 'svdq-int4-flux.1-dev',
                    'cache_threshold': widgets_values[1] if len(widgets_values) > 1 else 0,
                    'attention': widgets_values[2] if len(widgets_values) > 2 else 'nunchaku-fp16',
                    'cpu_offload': widgets_values[3] if len(widgets_values) > 3 else 'auto',
                    'device_id': widgets_values[4] if len(widgets_values) > 4 else 0,
                    'data_type': widgets_values[5] if len(widgets_values) > 5 else 'bfloat16',
                    'i_2_f_mode': widgets_values[6] if len(widgets_values) > 6 else 'enabled'
                }
            
            analysis['model_loaders'].append(model_loader_info)
        
        # æ£€æŸ¥NunchakuFluxLoraLoaderèŠ‚ç‚¹
        elif 'NunchakuFluxLoraLoader' in node_type:
            widgets_values = node.get('widgets_values', [])
            model_loader_info = {
                'node_id': node_id,
                'type': 'NunchakuFluxLoraLoader',
                'name': 'Flux LoRAåŠ è½½å™¨',
                'parameters': {}
            }
            
            if len(widgets_values) >= 2:
                model_loader_info['parameters'] = {
                    'lora_name': widgets_values[0] if len(widgets_values) > 0 else '',
                    'lora_strength': widgets_values[1] if len(widgets_values) > 1 else 1.0
                }
            
            analysis['model_loaders'].append(model_loader_info)
            # LoRA æ ‡è®°ä¸æ”¶é›†
            analysis['lora']['has_lora'] = True
            analysis['lora']['lora_nodes'].append({
                'node_id': node_id,
                'type': 'NunchakuFluxLoraLoader',
                'lora_name': model_loader_info['parameters'].get('lora_name') or ''
            })

        # æ£€æŸ¥é€šç”¨ LoraLoader èŠ‚ç‚¹
        elif 'LoraLoader' in node_type:
            widgets_values = node.get('widgets_values', [])
            model_loader_info = {
                'node_id': node_id,
                'type': 'LoraLoader',
                'name': 'LoRAåŠ è½½å™¨',
                'parameters': {}
            }
            if len(widgets_values) >= 2:
                model_loader_info['parameters'] = {
                    'lora_name': widgets_values[0] if len(widgets_values) > 0 else '',
                    'strength_model': widgets_values[1] if len(widgets_values) > 1 else 1.0
                }
            analysis['model_loaders'].append(model_loader_info)
            # LoRA æ ‡è®°ä¸æ”¶é›†
            analysis['lora']['has_lora'] = True
            analysis['lora']['lora_nodes'].append({
                'node_id': node_id,
                'type': 'LoraLoader',
                'lora_name': model_loader_info['parameters'].get('lora_name') or ''
            })

        # æ£€æŸ¥é€šç”¨ CheckpointLoaderSimple èŠ‚ç‚¹
        elif 'CheckpointLoaderSimple' in node_type:
            widgets_values = node.get('widgets_values', [])
            model_loader_info = {
                'node_id': node_id,
                'type': 'CheckpointLoaderSimple',
                'name': 'CheckpointåŠ è½½å™¨',
                'parameters': {}
            }
            if len(widgets_values) >= 1:
                model_loader_info['parameters'] = {
                    'ckpt_name': widgets_values[0] if len(widgets_values) > 0 else ''
                }
            analysis['model_loaders'].append(model_loader_info)
        
        # æ£€æŸ¥VAELoaderèŠ‚ç‚¹
        elif 'VAELoader' in node_type:
            widgets_values = node.get('widgets_values', [])
            model_loader_info = {
                'node_id': node_id,
                'type': 'VAELoader',
                'name': 'VAEåŠ è½½å™¨',
                'parameters': {}
            }
            
            if len(widgets_values) >= 1:
                model_loader_info['parameters'] = {
                    'vae_name': widgets_values[0] if len(widgets_values) > 0 else 'ae.safetensors'
                }
            
            analysis['model_loaders'].append(model_loader_info)
        
        # æ£€æŸ¥DualCLIPLoaderèŠ‚ç‚¹
        elif 'DualCLIPLoader' in node_type:
            widgets_values = node.get('widgets_values', [])
            model_loader_info = {
                'node_id': node_id,
                'type': 'DualCLIPLoader',
                'name': 'åŒCLIPåŠ è½½å™¨',
                'parameters': {}
            }
            
            if len(widgets_values) >= 3:
                model_loader_info['parameters'] = {
                    'clip_name1': widgets_values[0] if len(widgets_values) > 0 else '',
                    'clip_name2': widgets_values[1] if len(widgets_values) > 1 else '',
                    'type': widgets_values[2] if len(widgets_values) > 2 else 'normal'
                }
            
            analysis['model_loaders'].append(model_loader_info)

        # é€šç”¨å…œåº•ï¼šä»»æ„åŒ…å« Loader çš„èŠ‚ç‚¹ä½œä¸ºæ½œåœ¨æ¨¡å‹åŠ è½½å™¨
        elif 'Loader' in node_type:
            widgets_values = node.get('widgets_values', [])
            widget_inputs = [
                (inp.get('widget', {}) or {}).get('name')
                for inp in node.get('inputs', [])
                if isinstance(inp, dict) and 'widget' in inp and isinstance(inp.get('widget'), dict)
            ]
            if widget_inputs and isinstance(widgets_values, list):
                parameters = {}
                param_order = []
                for idx, pname in enumerate(widget_inputs):
                    if not pname:
                        continue
                    param_order.append(pname)
                    parameters[pname] = widgets_values[idx] if idx < len(widgets_values) else None
                model_loader_info = {
                    'node_id': node_id,
                    'type': node_type,
                    'name': f'{node_type}ï¼ˆæ¨¡å‹åŠ è½½å™¨ï¼‰',
                    'parameters': parameters,
                    'param_order': param_order
                }
                analysis['model_loaders'].append(model_loader_info)

        # è¯†åˆ« CLIPVisionLoaderï¼ˆè§†è§‰CLIPæ¨¡å‹åŠ è½½ï¼‰
        elif 'CLIPVisionLoader' in node_type:
            widgets_values = node.get('widgets_values', [])
            model_loader_info = {
                'node_id': node_id,
                'type': 'CLIPVisionLoader',
                'name': 'CLIPè§†è§‰æ¨¡å‹åŠ è½½å™¨',
                'parameters': {}
            }
            if len(widgets_values) >= 1:
                model_loader_info['parameters'] = {
                    'clip_name': widgets_values[0] if len(widgets_values) > 0 else ''
                }
            analysis['model_loaders'].append(model_loader_info)

        # è¯†åˆ« StyleModelLoaderï¼ˆé£æ ¼æ¨¡å‹åŠ è½½ï¼‰
        elif 'StyleModelLoader' in node_type:
            widgets_values = node.get('widgets_values', [])
            model_loader_info = {
                'node_id': node_id,
                'type': 'StyleModelLoader',
                'name': 'é£æ ¼æ¨¡å‹åŠ è½½å™¨',
                'parameters': {}
            }
            if len(widgets_values) >= 1:
                model_loader_info['parameters'] = {
                    'style_model_name': widgets_values[0] if len(widgets_values) > 0 else ''
                }
            analysis['model_loaders'].append(model_loader_info)
        
        # æ£€æŸ¥EmptyLatentImageèŠ‚ç‚¹è·å–é»˜è®¤å°ºå¯¸
        elif 'EmptyLatentImage' in node_type:
            widgets_values = node.get('widgets_values', [])
            if len(widgets_values) >= 2:
                try:
                    analysis['default_values']['width'] = int(widgets_values[0]) if widgets_values[0] is not None and str(widgets_values[0]).isdigit() else widgets_values[0] if widgets_values[0] is not None else 1024
                except (ValueError, TypeError):
                    analysis['default_values']['width'] = widgets_values[0] if widgets_values[0] is not None else 1024
                
                try:
                    analysis['default_values']['height'] = int(widgets_values[1]) if widgets_values[1] is not None and str(widgets_values[1]).isdigit() else widgets_values[1] if widgets_values[1] is not None else 1024
                except (ValueError, TypeError):
                    analysis['default_values']['height'] = widgets_values[1] if widgets_values[1] is not None else 1024
        
        # æ£€æŸ¥EmptySD3LatentImageèŠ‚ç‚¹è·å–é»˜è®¤å°ºå¯¸ï¼ˆNunchaku Flux.1ä½¿ç”¨ï¼‰
        elif 'EmptySD3LatentImage' in node_type:
            widgets_values = node.get('widgets_values', [])
            if len(widgets_values) >= 2:
                try:
                    analysis['default_values']['width'] = int(widgets_values[0]) if widgets_values[0] is not None and str(widgets_values[0]).isdigit() else widgets_values[0] if widgets_values[0] is not None else 1024
                except (ValueError, TypeError):
                    analysis['default_values']['width'] = widgets_values[0] if widgets_values[0] is not None else 1024
                
                try:
                    analysis['default_values']['height'] = int(widgets_values[1]) if widgets_values[1] is not None and str(widgets_values[1]).isdigit() else widgets_values[1] if widgets_values[1] is not None else 1024
                except (ValueError, TypeError):
                    analysis['default_values']['height'] = widgets_values[1] if widgets_values[1] is not None else 1024
        
        # æ£€æŸ¥PrimitiveNodeèŠ‚ç‚¹è·å–å°ºå¯¸ï¼ˆNunchaku Flux.1ä½¿ç”¨ï¼‰
        elif 'PrimitiveNode' in node_type:
            node_title = node.get('title', '').lower()
            widgets_values = node.get('widgets_values', [])
            
            if node_title == 'width' and len(widgets_values) >= 1:
                try:
                    analysis['default_values']['width'] = int(widgets_values[0]) if widgets_values[0] is not None and str(widgets_values[0]).isdigit() else widgets_values[0] if widgets_values[0] is not None else 1024
                except (ValueError, TypeError):
                    analysis['default_values']['width'] = widgets_values[0] if widgets_values[0] is not None else 1024
            
            elif node_title == 'height' and len(widgets_values) >= 1:
                try:
                    analysis['default_values']['height'] = int(widgets_values[0]) if widgets_values[0] is not None and str(widgets_values[0]).isdigit() else widgets_values[0] if widgets_values[0] is not None else 1024
                except (ValueError, TypeError):
                    analysis['default_values']['height'] = widgets_values[0] if widgets_values[0] is not None else 1024
        
        # æ£€æŸ¥CLIPTextEncodeèŠ‚ç‚¹è·å–é»˜è®¤æç¤ºè¯
        elif 'CLIPTextEncode' in node_type:
            # æ£€æŸ¥æ˜¯å¦æœ‰é»˜è®¤æ–‡æœ¬ - UIæ ¼å¼ä¸­æ–‡æœ¬åœ¨widgets_valuesä¸­
            widgets_values = node.get('widgets_values', [])
            if widgets_values and len(widgets_values) > 0:
                text_value = widgets_values[0]
                if isinstance(text_value, str) and text_value.strip():
                    # æ ¹æ®èŠ‚ç‚¹æ ‡é¢˜åˆ¤æ–­æ˜¯æ­£é¢è¿˜æ˜¯è´Ÿé¢æç¤ºè¯
                    node_title = node.get('title', '').lower()
                    if 'negative' in node_title or 'neg' in node_title:
                        analysis['default_values']['negative_prompt'] = text_value
                        analysis['has_negative_prompt'] = True
                    else:
                        analysis['default_values']['positive_prompt'] = text_value
    
    # æ ¹æ®åˆ†æç»“æœç¡®å®šéœ€è¦çš„å‚æ•°
    if analysis['has_text_to_image']:
        analysis['required_inputs'].append('positive_prompt')
        analysis['optional_inputs'].extend(['negative_prompt', 'width', 'height', 'steps', 'cfg', 'seed', 'sampler'])
    
    # æ±‡æ€»å·¥ä½œæµå†…çš„ LoRA åç§°å¹¶å°è¯•åŒ¹é…è§¦å‘è¯ï¼ˆæ¥è‡ªæ¨¡å‹ç›®å½• .civitai.info æˆ– .jsonï¼‰
    try:
        if analysis.get('lora', {}).get('has_lora'):
            lora_names = []
            for ln in analysis['lora']['lora_nodes']:
                name = (ln.get('lora_name') or '').strip()
                if name:
                    lora_names.append(name)
            # å»é‡
            lora_names = sorted(set(lora_names))
            analysis['lora']['detected_lora_names'] = lora_names
            if lora_names:
                triggers = _scan_lora_triggers_from_models(lora_names)
                # è½¬ä¸ºåˆ—è¡¨å½¢å¼ä»¥ä¾¿å‰ç«¯æ¸²æŸ“
                trigger_items = []
                for name in lora_names:
                    words = triggers.get(name) or []
                    if words:
                        trigger_items.append({'lora_name': name, 'triggers': words})
                analysis['lora']['triggers'] = trigger_items
    except Exception as e:
        try:
            logger.warning(f"æ‰«æLoRAè§¦å‘è¯æ—¶å‡ºé”™: {e}")
        except Exception:
            pass
    
    return analysis


def _scan_lora_triggers_from_models(lora_names):
    """åœ¨ ComfyUI/models/loras(æˆ–lora) ç›®å½•ä¸‹ï¼Œå°è¯•è¯»å–ä¸ LoRA æ–‡ä»¶åŒåçš„ .civitai.info æˆ– .json æ–‡ä»¶ï¼Œ
    æå–å…¶ä¸­çš„è§¦å‘è¯ï¼ˆtrainedWords / triggerWordsï¼‰ã€‚
    è¿”å›: { lora_filename: [trigger1, trigger2, ...] }
    """
    result = {}
    if not lora_names:
        return result
    try:
        base_dir = '/home/wjx/ComfyUI/models'
        search_dirs = []
        for d in ['loras', 'lora']:
            p = os.path.join(base_dir, d)
            if os.path.isdir(p):
                search_dirs.append(p)
        if not search_dirs:
            return result

        # ä¸ºæ‰€æœ‰ LoRA æ–‡ä»¶å»ºç«‹ç´¢å¼•ï¼šæ–‡ä»¶å -> æ‰€åœ¨ç›®å½•ç»å¯¹è·¯å¾„åˆ—è¡¨
        from collections import defaultdict
        name_to_dirs = defaultdict(list)
        for root_dir in search_dirs:
            for root, _, files in os.walk(root_dir):
                for fn in files:
                    # åªç´¢å¼•å¯èƒ½çš„æƒé‡æ–‡ä»¶
                    if fn.lower().endswith(('.safetensors', '.pt', '.bin')):
                        name_to_dirs[fn].append(root)

        for lora_name in lora_names:
            dirs = name_to_dirs.get(lora_name) or []
            if not dirs:
                continue
            # é€ä¸ªç›®å½•å°è¯•è¯»å– sidecar ä¿¡æ¯æ–‡ä»¶
            base_without_ext, _ = os.path.splitext(lora_name)
            candidates = [
                f"{base_without_ext}.civitai.info",
                f"{base_without_ext}.json",
            ]
            found_words = []
            for d in dirs:
                for cand in candidates:
                    meta_path = os.path.join(d, cand)
                    if not os.path.exists(meta_path):
                        continue
                    try:
                        with open(meta_path, 'r', encoding='utf-8') as f:
                            meta = json.load(f)
                        # å¸¸è§å­—æ®µï¼štrainedWords / triggerWords
                        words = []
                        if isinstance(meta, dict):
                            if isinstance(meta.get('trainedWords'), list):
                                words = [str(x).strip() for x in meta.get('trainedWords') if isinstance(x, (str,int,float))]
                            elif isinstance(meta.get('triggerWords'), list):
                                words = [str(x).strip() for x in meta.get('triggerWords') if isinstance(x, (str,int,float))]
                            # æŸäº› .json åŒ…åœ¨ versions[0].trainedWords
                            elif isinstance(meta.get('versions'), list) and meta['versions']:
                                v0 = meta['versions'][0]
                                if isinstance(v0, dict) and isinstance(v0.get('trainedWords'), list):
                                    words = [str(x).strip() for x in v0.get('trainedWords') if isinstance(x, (str,int,float))]
                        if words:
                            found_words.extend(words)
                    except Exception as _e:
                        try:
                            logger.debug(f"è¯»å–LoRAä¾§ä¿¡æ¯å¤±è´¥ {meta_path}: {_e}")
                        except Exception:
                            pass
            # å»é‡å¹¶è¿‡æ»¤ç©ºè¯
            found_words = [w for w in {w for w in found_words if w}]
            if found_words:
                result[lora_name] = found_words
    except Exception as e:
        try:
            logger.debug(f"æ‰«æLoRAè§¦å‘è¯å¤±è´¥: {e}")
        except Exception:
            pass
    return result


@app.route('/api/lora-info')
def get_lora_info():
    """æŒ‰åç§°è¿”å› LoRA çš„è§¦å‘è¯ä¸æç¤ºä¿¡æ¯ã€‚
    è¯·æ±‚ç¤ºä¾‹ï¼š/api/lora-info?name=foo.safetensors&name=bar.safetensors æˆ– name=foo,bar
    è¿”å›ï¼š{ success: true, items: { "foo.safetensors": {"triggers": [...], "tips": [..] }, ... } }
    """
    try:
        names_param = request.args.getlist('name') or []
        if len(names_param) == 1 and ',' in names_param[0]:
            names_param = [x.strip() for x in names_param[0].split(',') if x.strip()]
        lora_names = [n for n in names_param if n]
        if not lora_names:
            return jsonify({'success': False, 'error': 'ç¼ºå°‘ name å‚æ•°'}), 400

        info_map = _scan_lora_info_from_models(lora_names)
        return jsonify({'success': True, 'items': info_map})
    except Exception as e:
        logger.error(f"è·å–LoRAä¿¡æ¯å¤±è´¥: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500


def _scan_lora_info_from_models(lora_names):
    """æ‰«æ LoRA ä¾§ä¿¡æ¯æ–‡ä»¶ï¼Œè¿”å› { name: { triggers: [...], tips: [...] } }"""
    result: Dict[str, Dict[str, Any]] = {}
    if not lora_names:
        return result
    try:
        base_dir = '/home/wjx/ComfyUI/models'
        search_dirs = []
        for d in ['loras', 'lora']:
            p = os.path.join(base_dir, d)
            if os.path.isdir(p):
                search_dirs.append(p)
        if not search_dirs:
            return result

        # å»ºç«‹æ–‡ä»¶ååˆ°æ‰€åœ¨ç›®å½•æ˜ å°„ï¼ˆå«æ— æ‰©å±•åç´¢å¼•ï¼‰
        from collections import defaultdict
        name_to_dirs = defaultdict(list)
        stem_to_fullnames = defaultdict(list)
        for root_dir in search_dirs:
            for root, _, files in os.walk(root_dir):
                for fn in files:
                    if fn.lower().endswith(('.safetensors', '.pt', '.bin')):
                        name_to_dirs[fn].append(root)
                        stem, _ext = os.path.splitext(fn)
                        stem_to_fullnames[stem].append(fn)

        for raw in lora_names:
            lora_name = os.path.basename(str(raw or ''))
            lora_name_ci = lora_name.lower()
            # 1) ç²¾ç¡®åŒ¹é…ï¼ˆå¤§å°å†™åŸæ ·æˆ–å°å†™ï¼‰
            dirs = name_to_dirs.get(lora_name) or name_to_dirs.get(lora_name_ci) or []
            matched_fullname = lora_name if dirs else None
            # 2) æ— æ‰©å±•ååŒ¹é…
            if not dirs:
                stem = os.path.splitext(lora_name)[0]
                cands = stem_to_fullnames.get(stem) or stem_to_fullnames.get(stem.lower()) or []
                if cands:
                    matched_fullname = cands[0]
                    dirs = name_to_dirs.get(matched_fullname) or []
            # 3) æ¨¡ç³ŠåŒ…å«ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
            if not dirs and lora_name_ci:
                for fn, dlist in name_to_dirs.items():
                    if lora_name_ci in fn.lower():
                        matched_fullname = fn
                        dirs = dlist
                        break
            if not dirs:
                result[raw] = {'triggers': [], 'tips': []}
                continue
            use_name = matched_fullname or lora_name
            base_without_ext, _ = os.path.splitext(use_name)
            candidates = [f"{base_without_ext}.civitai.info", f"{base_without_ext}.json"]
            triggers: List[str] = []
            tips: List[str] = []
            for d in dirs:
                for cand in candidates:
                    meta_path = os.path.join(d, cand)
                    if not os.path.exists(meta_path):
                        continue
                    try:
                        with open(meta_path, 'r', encoding='utf-8') as f:
                            meta = json.load(f)
                        # è§¦å‘è¯
                        w = _extract_lora_triggers_from_meta(meta)
                        if w:
                            triggers.extend(w)
                        # æç¤ºä¿¡æ¯
                        t = _extract_lora_tips_from_meta(meta)
                        if t:
                            tips.extend(t)
                    except Exception as _e:
                        try:
                            logger.debug(f"è¯»å–LoRAå…ƒä¿¡æ¯å¤±è´¥ {meta_path}: {_e}")
                        except Exception:
                            pass
            # å»é‡
            triggers = [w for w in {w.strip() for w in triggers if isinstance(w, str) and w.strip()}]
            tips = [w for w in {w.strip() for w in tips if isinstance(w, str) and w.strip()}]
            result[raw] = {'triggers': triggers, 'tips': tips}
    except Exception as e:
        try:
            logger.debug(f"æ‰«æLoRAä¿¡æ¯å¤±è´¥: {e}")
        except Exception:
            pass
    return result


def _extract_lora_triggers_from_meta(meta: Dict[str, Any]) -> List[str]:
    try:
        if not isinstance(meta, dict):
            return []
        if isinstance(meta.get('trainedWords'), list):
            return [str(x) for x in meta['trainedWords'] if isinstance(x, (str, int, float))]
        if isinstance(meta.get('triggerWords'), list):
            return [str(x) for x in meta['triggerWords'] if isinstance(x, (str, int, float))]
        if isinstance(meta.get('versions'), list) and meta['versions']:
            v0 = meta['versions'][0]
            if isinstance(v0, dict) and isinstance(v0.get('trainedWords'), list):
                return [str(x) for x in v0['trainedWords'] if isinstance(x, (str, int, float))]
        return []
    except Exception:
        return []


def _extract_lora_tips_from_meta(meta: Dict[str, Any]) -> List[str]:
    """ä»å…ƒæ•°æ®æå– tips/usage ä¿¡æ¯ï¼Œè¿”å›å­—ç¬¦ä¸²åˆ—è¡¨ã€‚"""
    try:
        if not isinstance(meta, dict):
            return []
        candidates: List[str] = []
        # å¸¸è§å­—æ®µ
        for key in ['tips', 'usage_tips', 'usageTips', 'how_to_use', 'usage', 'notes']:
            v = meta.get(key)
            if isinstance(v, str):
                candidates.append(v)
            elif isinstance(v, list):
                candidates.extend([str(x) for x in v])
        # é€€åŒ–åˆ°æè¿°
        desc = meta.get('description')
        if isinstance(desc, str):
            candidates.append(desc)
        # ç‰ˆæœ¬çº§åˆ«
        if isinstance(meta.get('versions'), list) and meta['versions']:
            v0 = meta['versions'][0]
            if isinstance(v0, dict):
                for key in ['tips', 'usage_tips', 'usageTips', 'notes', 'description']:
                    v = v0.get(key)
                    if isinstance(v, str):
                        candidates.append(v)
                    elif isinstance(v, list):
                        candidates.extend([str(x) for x in v])
        # è§„èŒƒåŒ–ï¼šæ‹†è¡Œï¼Œå»ç©ºç™½ï¼Œé™åˆ¶é•¿åº¦
        lines: List[str] = []
        for c in candidates:
            if not isinstance(c, str):
                continue
            parts = [p.strip('-â€¢ \t') for p in str(c).split('\n')]
            for p in parts:
                if p:
                    lines.append(p)
        # é™åˆ¶æœ€å¤š 12 æ¡
        return lines[:12]
    except Exception:
        return []


@app.route('/api/model-files')
def get_model_files():
    """åˆ—å‡º ComfyUI/models ä¸‹å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶ï¼ŒæŒ‰å­ç›®å½•åˆ†ç±»ã€‚
    ä»…è¿”å›æ–‡ä»¶åï¼Œä¸å«è·¯å¾„ï¼Œä¾¿äºå‰ç«¯ä¸‹æ‹‰é€‰æ‹©ã€‚
    """
    try:
        base_dir = '/home/wjx/ComfyUI/models'
        exts = {'.safetensors', '.ckpt', '.pt', '.bin'}
        categories: Dict[str, List[str]] = {}
        if os.path.exists(base_dir):
            for entry in os.listdir(base_dir):
                subdir = os.path.join(base_dir, entry)
                if not os.path.isdir(subdir):
                    continue
                files: List[str] = []
                for root, _, filenames in os.walk(subdir):
                    for fn in filenames:
                        _, ext = os.path.splitext(fn)
                        if ext.lower() in exts:
                            files.append(fn)
                # å»é‡å¹¶æ’åº
                if files:
                    categories[entry] = sorted(sorted(set(files)))

        # ç›®å½•åˆ«åä¸åˆå¹¶ï¼Œå…¼å®¹ ComfyUI å¸¸è§ç›®å½•ç»“æ„
        def merged(*keys: str) -> List[str]:
            seen = set()
            out: List[str] = []
            for k in keys:
                for v in categories.get(k, []) or []:
                    if v not in seen:
                        seen.add(v)
                        out.append(v)
            return sorted(out)

        # ç”Ÿæˆè§„èŒƒé”®ï¼ˆå…¼å®¹æ›´å¤šå¸¸è§ç›®å½•ï¼‰
        norm: Dict[str, List[str]] = {}
        norm['clip'] = merged('clip', 'text_encoders')
        norm['clip_vision'] = merged('clip_vision')
        norm['vae'] = merged('vae')
        # ä¸»æ¨¡å‹/æ£€æŸ¥ç‚¹ï¼šå°½å¯èƒ½äº’ç›¸å…¼å®¹
        norm['unet'] = merged('unet', 'diffusion_models', 'checkpoints')
        norm['checkpoints'] = merged('checkpoints', 'unet', 'diffusion_models')
        # LoRA ç›®å½•å…¼å®¹å•å¤æ•°
        norm['loras'] = merged('loras', 'lora')
        norm['lora'] = merged('lora', 'loras')
        # ControlNet å¸¸è§ç›®å½•
        norm['controlnet'] = merged('controlnet', 'controlnet_models', 'controlnets')
        # é£æ ¼æ¨¡å‹ï¼ˆè‹¥æ— ä¸“ç”¨ç›®å½•åˆ™ä¸ºç©ºï¼‰
        norm['style_models'] = merged('style_models')

        # ç”¨è§„èŒƒé”®è¦†ç›–/è¡¥å……
        for k, v in norm.items():
            categories[k] = v

        # å¸¸è§ç±»åˆ«å…œåº•é”®åï¼Œç¡®ä¿å‰ç«¯æœ‰ç¨³å®šé”®
        for key in ['clip', 'clip_vision', 'vae', 'unet', 'checkpoints', 'loras', 'lora', 'style_models', 'controlnet']:
            categories.setdefault(key, [])

        return jsonify({'success': True, 'categories': categories})
    except Exception as e:
        logger.error(f"æ‰«ææ¨¡å‹æ–‡ä»¶å¤±è´¥: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

if __name__ == '__main__':
    logger.info(f"å¯åŠ¨ComfyUI WebæœåŠ¡...")
    logger.info(f"Workflowç›®å½•: {WORKFLOW_DIR}")
    logger.info(f"æœåŠ¡åœ°å€: http://{HOST}:{PORT}")
    
    # æ£€æŸ¥workflowç›®å½•
    if not os.path.exists(WORKFLOW_DIR):
        logger.warning(f"åˆ›å»ºworkflowç›®å½•: {WORKFLOW_DIR}")
        os.makedirs(WORKFLOW_DIR, exist_ok=True)
    
    app.run(host=HOST, port=PORT, debug=True, threaded=True)